{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gluo88/misc/blob/main/notebook/finance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ0uom-vWQsI"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlRXBAdso2MX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtN3Q_swWRZT"
      },
      "source": [
        "\n",
        "**hosted web page at Hugging Face**\n",
        "\n",
        "* https://huggingface.co/spaces/gluo88/stock_performance\n",
        "\n",
        "\n",
        "**Core references**\n",
        "* yfinance https://pypi.org/project/yfinance/,\n",
        " * tutorial: https://aroussi.com/post/python-yahoo-finance\n",
        "* pandas tutorial https://www.w3schools.com/python/pandas/default.asp\n",
        "\n",
        "**an unofficial Yahoo Finance API - yahooquery**\n",
        "* https://yahooquery.dpguthrie.com/\n",
        "* https://github.com/dpguthrie/yahooquery\n",
        "\n",
        "**Retired Yahoo! Query Language (YQL)**\n",
        "* https://en.wikipedia.org/wiki/Yahoo!_Query_Language\n",
        "\n",
        "**Misc**\n",
        "* https://sourceforge.net/software/stock-analysis/free-version/\n",
        "* https://wallethacks.com/free-stock-analysis-software-tools/\n",
        "* How to Use Python and Pandas with Yahoo Finance API https://saturncloud.io/blog/how-to-use-python-and-pandas-with-yahoo-finance-api/\n",
        "* PyPortfolioOpt https://pyportfolioopt.readthedocs.io/en/latest/UserGuide.html\n",
        "* https://nyc3.digitaloceanspaces.com/roboticview/media/jupyter/Yahoo_Finance_Stock_Analysis_1.html?AWSAccessKeyId=DO00FWAZBR62EWAWDFYF&Signature=dBz8W5movGymEYR5kw5gggByzL8%3D&Expires=1705115798\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N6b-v17kZ8R"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ioaa1xHRkhrj",
        "outputId": "fea71caa-36d5-487e-9ac0-b0aac45fb17e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.19.2-py3-none-any.whl (16.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.10.1 (from gradio)\n",
            "  Downloading gradio_client-0.10.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.9/307.9 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.6.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.3.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.10.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.27.1-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.10.1->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.10.1->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.16.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n",
            "Collecting starlette<0.37.0,>=0.36.3 (from fastapi->gradio)\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=de998edce178f6a9da4d52a7cbc62fdc77743d2ae2ee328e5cf2b69484bbc825\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, tomlkit, shellingham, semantic-version, ruff, python-multipart, orjson, h11, colorama, aiofiles, uvicorn, starlette, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "Successfully installed aiofiles-23.2.1 colorama-0.4.6 fastapi-0.110.0 ffmpy-0.3.2 gradio-4.19.2 gradio-client-0.10.1 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 orjson-3.9.15 pydub-0.25.1 python-multipart-0.0.9 ruff-0.3.0 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.36.3 tomlkit-0.12.0 uvicorn-0.27.1 websockets-11.0.3\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.37)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.25.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.31.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.4)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2023.4)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.4.0)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.17.1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2024.2.2)\n",
            "Collecting datetime\n",
            "  Downloading DateTime-5.4-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m988.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zope.interface (from datetime)\n",
            "  Downloading zope.interface-6.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.3/247.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from datetime) (2023.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from zope.interface->datetime) (67.7.2)\n",
            "Installing collected packages: zope.interface, datetime\n",
            "Successfully installed datetime-5.4 zope.interface-6.2\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (2023.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio\n",
        "#!pip install --upgrade gradio\n",
        "#!pip install gradio==3.50\n",
        "!pip install yfinance\n",
        "!pip install datetime\n",
        "!pip install pytz\n",
        "!pip install pandas\n",
        "#!pip install --upgrade pandas\n",
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnOlA3NiYoHn"
      },
      "source": [
        "# gradio deploy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_wm9gLUUgjb",
        "outputId": "db63081b-85d3-4b18-d970-a4ef67bba305"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Need \u001b[32m'write'\u001b[0m access token to create a Spaces repo.\n",
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid (permission: write).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n",
            "Creating new Spaces Repo in \u001b[32m'/content'\u001b[0m. Collecting metadata, press Enter to accept default value.\n",
            "Enter Spaces app title [content]: stock_plot\n",
            "Enter Gradio app file : space_stock_plot.py\n",
            "Enter Spaces hardware (cpu-basic, cpu-upgrade, t4-small, t4-medium, zero-a10g, a10g-small, a10g-large, a10g-largex2, a10g-largex4, a100-large) [cpu-basic]: \n",
            "Any Spaces secrets (y/n) [n]: \n",
            "Create Github Action to automatically update Space on 'git push'? [n]: \n",
            "mnist_test.csv:   0% 0.00/18.3M [00:00<?, ?B/s]\n",
            "Upload 2 LFS files:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "mnist_test.csv:   0% 16.4k/18.3M [00:00<02:17, 133kB/s]\n",
            "\n",
            "mnist_test.csv:  33% 6.01M/18.3M [00:00<00:00, 31.7MB/s]\n",
            "\n",
            "mnist_test.csv:  62% 11.3M/18.3M [00:00<00:00, 35.7MB/s]\n",
            "\n",
            "mnist_train_small.csv:  19% 7.05M/36.5M [00:00<00:01, 20.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "mnist_test.csv:  88% 16.0M/18.3M [00:00<00:00, 19.1MB/s]\n",
            "\n",
            "mnist_test.csv: 100% 18.3M/18.3M [00:00<00:00, 19.1MB/s]\n",
            "\n",
            "\n",
            "mnist_train_small.csv:  86% 31.3M/36.5M [00:00<00:00, 42.5MB/s]\u001b[A\u001b[A\n",
            "mnist_train_small.csv: 100% 36.5M/36.5M [00:01<00:00, 18.5MB/s]\n",
            "\n",
            "Upload 2 LFS files: 100% 2/2 [00:02<00:00,  1.14s/it]\n",
            "Space available at \u001b[4;94mhttps://huggingface.co/spaces/gluo88/stock_plot\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#!pip install gradio\n",
        "!gradio deploy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 9  annual,  trailing, cumumlative, and CAGR  returns  (restructured from Example 8)"
      ],
      "metadata": {
        "id": "5OIgh2qNQIzh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zo7mcfMoQSi-"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Example 9 for using yfinance\n",
        "\n",
        "Calculate annual, trailing, cumumlative, and CAGR returns for multiple stocks.\n",
        "* The start date can be an arbitrary date.  The default is the current date.\n",
        "* annual return is displayed from the default current day, or an arbitrary given\n",
        "  day (except for Feb 29 for leap year)\n",
        "  For leap years, use Feb 28 to replace Feb 29 as simplification & approximation\n",
        "* trailing, cumumlative returns are currently displayed from the month boundary (last day of Month)\n",
        "  prior to the given date.\n",
        "* However, trailing, cumumlative returns can be displayed\n",
        "  from any date, which can be not at the month boundary (last day of Month),\n",
        "  by minor change of setting calculation_end_date_for_others_str = calculation_end_date_str.\n",
        "  prior to the given date in the function \"calculation_response(message, history)\"\n",
        "\n",
        "Author: Gang Luo\n",
        "'''\n",
        "script_version = '(2024-03-04.2)'\n",
        "import gradio as gr\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import pytz\n",
        "DEBUG_ENABLED = True\n",
        "#==============================================================================\n",
        "\n",
        "print_yearly_total_return = True\n",
        "num_years_calculation=52   # total years for calculation\n",
        "\n",
        "# Define a list of years to calculate the trailing returns, cumulative returns, and so on\n",
        "# remove the row of current year row since it is not a full year.\n",
        "years_list = [1, 2, 3, 5, 10, 15, 20, 25, 30, 40, 50, 60]\n",
        "\n",
        "# Set the stock tickers list\n",
        "tickers_lists = [[\"qqq\",\"hxq.to\",\"spy\", \"vfv.to\",\"xiu.to\", \"xbb.to\",\"xcb.to\",\"xhb.to\"], #0  checking ETF\n",
        "    [\"qqq\",\"spy\", \"vfv.to\", \"vgg.to\", \"zlu.to\", \"xiu.to\", \"vdy.to\", \"xfn.to\", \"ry.to\", \"td.to\", \"na.to\",\n",
        "      \"slf.to\", \"gwo.to\", \"bce.to\", \"t.to\", \"rci-b.to\", \"enb.to\", \"trp.to\", \"zlb.to\", \"cp.to\"], #1 main monitoring list\n",
        "    [\"qqq\",\"spy\",\"vfv.to\", \"xiu.to\", \"zeb.to\", \"xfn.to\", \"na.to\",\"ry.to\", \"bmo.to\",\"bns.to\", \"td.to\", \"cm.to\", \"cwb.to\",\n",
        "      \"slf.to\", \"gwo.to\", \"bce.to\", \"t.to\", \"rci-b.to\", \"enb.to\", \"trp.to\", \"xdv.to\",\"cdz.to\",\"vdy.to\", \"xdiv.to\"],  #2   financial  ETF & stocks\n",
        "    [\"^ndx\",\"qqq\",\"^GSPC\",\"spy\", \"vfv.to\", \"vgg.to\",\"zlu.to\",\"msft\",\"AAPL\",\"goog\",\"AMZN\",\"NVDA\",\"meta\",\"tsla\",\"BRK-A\",\"shop.to\",\"hxq.to\"],   #3  US mega stocks + risky shopfy\n",
        "    [\"^DJI\",\"dia\",\"^GSPC\",\"spy\",\"voo\",\"ivv\", \"tpu-u.to\",\"vfv.to\", \"zsp.to\",\"hxs.to\",\"tpu.to\",\"xus.to\", \"xsp.to\",\n",
        "      \"^IXIC\",\"^ndx\", \"qqq\",\"hxq.to\",\"^GSPTSE\",\"xic.to\",\"xiu.to\", \"HXT.TO\", \"TTP.TO\",\"ZCN.TO\", \"xfn.to\", \"xit.to\"], #4   indexes and index ETFs\n",
        "    [\"dia\",\"^DJI\",\"^GSPC\",\"spy\",\"vfv.to\", \"zsp.to\",\"hxs.to\",\"xus.to\", \"xsp.to\",\n",
        "      \"^IXIC\",\"qqq\",\"hxq.to\",\"^GSPTSE\",\"xic.to\",\"xiu.to\", \"HXT.TO\", \"xfn.to\"], #5   indexes and typical index ETFs\n",
        "    [\"^IXIC\",\"^ndx\",\"ONEQ\",\"CIBR\",\"QQJG\", \"qqq\", \"tqqq\", \"spy\", \"vfv.to\", \"HXQ.to\", \"ZQQ.to\", \"XQQ.to\", \"QQC.to\", \"ZNQ.TO\",\n",
        "         \"xiu.to\", \"xit.to\"],  #6   Nasdaq ETF and TSX IT ETF\n",
        "    [\"qqq\",\"tqqq\",\"sqqq\", \"QLD\", \"spy\", \"spxu\", \"upro\", \"sso\", \"spxl\",\"tecl\"], #7 leveraged ETFs\n",
        "    [\"^IXIC\",\"^DJI\",\"^GSPC\",\"^GSPTSE\"], #8 testing\n",
        "    [\"vfv.to\",\"spy\"] #9 testing\n",
        "]\n",
        "\n",
        "#==============================================================================\n",
        "# Part 1:\n",
        "#  retrieve daily adjusted close prices of a list of tickers from yahoo finance\n",
        "#  Generate the year-end adjusted close prices\n",
        "#  return year-end adjusted close prices, and  daily adjusted close prices\n",
        "def stock_prices_df(tickers_list, end_date_str):\n",
        "    tickers_list_upper = [ticker.upper() for ticker in tickers_list]\n",
        "    tickers_str = \", \".join(tickers_list_upper)\n",
        "    try:\n",
        "        '''\n",
        "        'try' statement for handlingy the exception error  for yf.download\n",
        "        '''\n",
        "        # Download the historical data\n",
        "        data = yf.download(tickers_str, period=\"max\")\n",
        "    except:\n",
        "        return  pd.DataFrame()\n",
        "    else:\n",
        "        data_adj_close = data['Adj Close']\n",
        "\n",
        "    # Filter out rows with dates newer than calculation_end_date\n",
        "    data_adj_close = data_adj_close[data_adj_close.index <= end_date_str]\n",
        "    #print(\"\\nDebug- stock_prices_df\\n\", data_adj_close)\n",
        "\n",
        "    # Rearrange columns based on the order in tickers_list_upper\n",
        "    if len(tickers_list)>1:\n",
        "        data_adj_close = data_adj_close.reindex(columns=tickers_list_upper)\n",
        "\n",
        "    # needed this when having only a single ticker in the ticker list\n",
        "    if len(tickers_list_upper)==1:\n",
        "        data_adj_close = pd.DataFrame(data_adj_close)\n",
        "        data_adj_close.rename(columns={'Adj Close': tickers_list_upper[0]}, inplace=True)\n",
        "\n",
        "    data_adj_close.columns = map(str.lower, data_adj_close.columns) # must after  pd.DataFrame(data_adj_close)\n",
        "    data_adj_close_year_end = data_adj_close.resample('A').ffill().round(2) # must before index changed to date\n",
        "\n",
        "    data_adj_close.index=data_adj_close.index.date\n",
        "    data_adj_close_year_end.index=data_adj_close_year_end.index.date\n",
        "\n",
        "    last_date = data_adj_close.index[-1]\n",
        "    data_adj_close_year_end = data_adj_close_year_end.rename(index={last_date: end_date_str})\n",
        "\n",
        "    return data_adj_close_year_end, data_adj_close\n",
        "\n",
        "#==============================================================================\n",
        "# Part 2:  Calculate annual returns at year end, and at any given day (by calculation_end_date_str)\n",
        "#\n",
        "# annual return calculation can start at any given day\n",
        "def get_annual_returns_anyday_df(daily_adj_close_df, calculation_end_date_str):\n",
        "\n",
        "    calculation_end_date=pd.to_datetime(calculation_end_date_str).tz_localize('America/New_York')\n",
        "\n",
        "    # Create a DataFrame with a complete date range\n",
        "    date_range = pd.date_range(start=daily_adj_close_df.index.min(), end=daily_adj_close_df.index.max(), freq='D')\n",
        "\n",
        "    complete_stock_history = pd.DataFrame(index=date_range)\n",
        "    # Merge the complete DataFrame with the original stock_history\n",
        "    complete_stock_history = complete_stock_history.merge(daily_adj_close_df, how='left', left_index=True, right_index=True)\n",
        "    complete_stock_history = complete_stock_history.ffill()  # fill the newy added rows with previous day value\n",
        "    '''\n",
        "    Filter out the rows that matches the month and date of calculation_end_date, which are the ends of\n",
        "    annual periods from the calculation_end_date.\n",
        "    '''\n",
        "    # Filter out rows with dates newer than calculation_end_date\n",
        "    #filtered_stock_history = complete_stock_history[complete_stock_history.index <= calculation_end_date]\n",
        "    # note\" daily_adj_close_df satisfys daily_adj_close_df.index <= calculation_end_date\n",
        "    filtered_stock_history = complete_stock_history\n",
        "    #print(filtered_stock_history)\n",
        "    target_month=filtered_stock_history.index.max().month\n",
        "    target_day=filtered_stock_history.index.max().day\n",
        "    #print(\"target_month\", target_month, \"target_day\",target_day, \"start_year\", filtered_stock_history.index.max().year)\n",
        "    annual_returns = filtered_stock_history[(filtered_stock_history.index.month == target_month)\n",
        "           & (filtered_stock_history.index.day ==target_day)]\n",
        "    annual_returns_percent = annual_returns.pct_change().dropna(how='all')\n",
        "\n",
        "    annual_returns_df = pd.DataFrame(annual_returns_percent)\n",
        "    #print(\"\\ndebug-annual_returns_df\\n\", annual_returns_df)\n",
        "    return annual_returns_df\n",
        "\n",
        "# annual return calculation can start at year end\n",
        "def get_annual_returns_year_end_df(data_adj_close_df, calculation_end_date_str):\n",
        "    annual_returns_percent = data_adj_close_df.pct_change().dropna(how='all')\n",
        "    return annual_returns_percent\n",
        "\n",
        "#==============================================================================\n",
        "# Part 3: calculate the annualized trailing total return from the data generated in step 1 & display\n",
        "# Define a function to calculate the annualized trailing total return for a given number of years\n",
        "def get_trailing_return(ticker, data, years):\n",
        "    # Get the total return values for the last n years\n",
        "    trailing_data = data[ticker].tail(years)\n",
        "    # Check if there are empty values within years\n",
        "    if trailing_data.isna().any():\n",
        "        return np.nan\n",
        "    # Check if there are valid total return values for all years\n",
        "    if len(trailing_data) == years:\n",
        "        # Convert the percentage strings to numeric values\n",
        "        trailing_data = trailing_data.astype(str).str.replace('%', '').astype(float)\n",
        "        \"\"\" Calculate the annualized trailing total return using the formula from Investopedia[^1^][1]:\n",
        "            Annualized Return = [(1 + r1) * (1 + r2) * ... * (1 + rn)]^(1/n) - 1\n",
        "            Where r1, r2, ..., rn are the total return values for each year                    \"\"\"\n",
        "        annualized_trailing_return = (trailing_data + 1).prod() ** (1 / years) - 1\n",
        "\n",
        "        # Format the result as a percentage with two decimal places\n",
        "        annualized_trailing_return = annualized_trailing_return * 100\n",
        "        annualized_trailing_return = annualized_trailing_return.round(2)\n",
        "        return annualized_trailing_return\n",
        "    else:\n",
        "        return np.nan\n",
        "\n",
        "# Define a function to Loop through the list and print the trailing returns for each num_years\n",
        "def get_trailing_return_column(ticker, annual_returns_df):\n",
        "    trailing_return_column = {}\n",
        "    for num_years in years_list:\n",
        "        # Check if the ticker data is available in all_tickers_returns_df\n",
        "        if ticker in annual_returns_df.columns:\n",
        "            # using data from step 1, avoiding get_annual_returns_df(ticker) for less traffic from yahoo server\n",
        "            data = annual_returns_df[[ticker]]\n",
        "            trailing_return = get_trailing_return(ticker, data, num_years)\n",
        "            trailing_return_column[f\"{num_years}-Year\"] = trailing_return\n",
        "        else:\n",
        "            print(f\"Data not available for {ticker}. Skipping.\")\n",
        "            trailing_return_column[f\"{num_years}-Year\"] = np.nan\n",
        "    return trailing_return_column\n",
        "\n",
        "# Create an empty DataFrame to store all tickers' trailing returns\n",
        "def get_trailing_return_all(annual_returns_df):\n",
        "    all_tickers_trailing_returns_df = pd.DataFrame(index=years_list)\n",
        "    tickers=annual_returns_df.columns.tolist()\n",
        "    # Loop through each ticker in the list\n",
        "    for ticker in tickers:\n",
        "        trailing_returns = get_trailing_return_column(ticker, annual_returns_df)\n",
        "        # Add the trailing returns to the DataFrame\n",
        "        all_tickers_trailing_returns_df[ticker] = pd.Series(trailing_returns).values\n",
        "    return all_tickers_trailing_returns_df\n",
        "\n",
        "#==============================================================================\n",
        "# Part 4: calculate the cumulative return from the data (all_tickers_returns_df) generated in part 1 & display\n",
        "#  Define a function to calculate the cumulative return for a given number of years from a ticker\n",
        "def get_cumulative_return(ticker, data, years):\n",
        "    # Calculate the cumulative return\n",
        "    cumulative_return = (1 + data[ticker]).rolling(window=years).apply(lambda x: x.prod(), raw=True) - 1\n",
        "    return cumulative_return\n",
        "\n",
        "# Define a function to Loop through the list and return the cumulative returns for each num_years\n",
        "def get_cumulative_return_column(ticker, annual_returns_df):\n",
        "    cumulative_returns = {}\n",
        "    for years in years_list:\n",
        "        # Calculate the cumulative return for the given number of years\n",
        "        cumulative_return = get_cumulative_return(ticker, annual_returns_df, years)\n",
        "        # Get the last value, which is the cumulative return up to the current year\n",
        "        cumulative_returns[years] = cumulative_return.iloc[-1]\n",
        "    return cumulative_returns\n",
        "\n",
        "def get_cumulative_return_all(annual_returns_df):\n",
        "    # Create an empty DataFrame with years_list as the index for cumulative  returns\n",
        "    all_tickers_cumulative_returns_df = pd.DataFrame(index=years_list)\n",
        "    tickers=annual_returns_df.columns.tolist()\n",
        "    # Loop through each ticker in the list\n",
        "    for ticker in tickers:\n",
        "        cumulative_returns = get_cumulative_return_column(ticker, annual_returns_df)\n",
        "        # Add the trailing returns to the DataFrame\n",
        "        all_tickers_cumulative_returns_df[ticker] = pd.Series(cumulative_returns).values\n",
        "    return all_tickers_cumulative_returns_df\n",
        "\n",
        "#==============================================================================\n",
        "# Part 5: calculate the  CAGR (Compound Annual Growth Rate) from the data\n",
        "# in all_tickers_cumulative_returns_df generated earlier & display\n",
        "# Define a function to calculate the CAGR from the cumulative value and the years\n",
        "def calculate_cagr(value, years):\n",
        "    # Otherwise, calculate the CAGR using the formula\n",
        "    cagr = (value + 1) ** (1 / np.array(years)) - 1\n",
        "    #print(\"debug-cagr\\n\", cagr, \"end\")\n",
        "    return cagr\n",
        "\n",
        "# Define a function to format the Float64Index values into percentage strings\n",
        "def format_to_percentage(value):\n",
        "    # If any element in the value array is not null, format it as a percentage string with two decimal places\n",
        "    if np.any(pd.notnull(value)):\n",
        "        return f\"{value:.2f}%\"\n",
        "    # Otherwise, return None\n",
        "    return None\n",
        "\n",
        "def get_cagr_return_all(all_tickers_cumulative_returns_df):\n",
        "    # Apply the calculate_cagr function to each column of the DataFrame\n",
        "    all_tickers_cagrs_df = all_tickers_cumulative_returns_df.apply(lambda x: calculate_cagr(x, x.index), axis=0)\n",
        "    return all_tickers_cagrs_df\n",
        "\n",
        "#==============================================================================\n",
        "# Part 6:\n",
        "# single ticker's Prices, Returns,Dividends, good for verifying whether \"Adj Close\" is correct.\n",
        "'''\n",
        "    Calculate and display: yearly dividendSum, 'Close' & 'Adj Close' prices,\n",
        "    Return(by 'Close' price), total return(by 'Adj Close' price),\n",
        "    CalReturn(total return by 'Close' price and \"dividendSum).\n",
        "    Note: CalReturn from  is expected to be nearly same as  total return,\n",
        "           when the 'Adj Close' price is correct.\n",
        "'''\n",
        "def get_yearly_single_stock_data(ticker):\n",
        "    stock = yf.Ticker(ticker)\n",
        "    #-------- mainly for downloading 'Dividends'\n",
        "    history = stock.history(period=\"max\")\n",
        "    dividend_history=history['Dividends']\n",
        "    dividend_history.index=dividend_history.index.date\n",
        "\n",
        "    #-------- mainly for downloading 'Close','Adj Close'\n",
        "    dld_history=yf.download(ticker, period=\"max\")\n",
        "    dld_history=dld_history[['Close','Adj Close']]\n",
        "    dld_history.rename(columns={'Adj Close': 'AdjClose'}, inplace=True)\n",
        "    date_range = pd.date_range(start=dld_history.index.min(), end=dld_history.index.max(), freq='D')\n",
        "    complete_history = pd.DataFrame(index=date_range)\n",
        "\n",
        "    # Merge the complete DataFrame with the original stock_history\n",
        "    complete_history = complete_history.merge(dld_history, how='left', left_index=True, right_index=True)\n",
        "    complete_history[['Close','AdjClose']] = complete_history[['Close','AdjClose']].ffill().round(3)\n",
        "\n",
        "    # Merge dividend into complete_history\n",
        "    complete_history = complete_history.merge(dividend_history, how='left', left_index=True, right_index=True)\n",
        "    # replace all NaN values in the 'Dividends' column with 0.0\n",
        "    complete_history['Dividends'] = complete_history['Dividends'].fillna(0.0).round(3)\n",
        "\n",
        "    complete_history['Year']=complete_history.index.year\n",
        "    complete_history['Date']=complete_history.index\n",
        "    yearly_data = complete_history.groupby('Year').agg({'Date': 'last', 'Close': 'last', 'AdjClose': 'last','Dividends': 'sum'})\n",
        "    yearly_data.rename(columns={'Dividends': 'DivSum'}, inplace=True)\n",
        "\n",
        "    # calculating 'Return' and 'TotalReturn'\n",
        "    yearly_data['DivRatio']=yearly_data['DivSum'] / yearly_data['Close']\n",
        "    yearly_data['Return']=yearly_data['Close'].pct_change()\n",
        "    yearly_data['TotalReturn']=yearly_data['AdjClose'].pct_change()\n",
        "\n",
        "    '''\n",
        "    The CalReturn column is the yearly total return calculated from un-adjusted \"Close\" prices and yearly \"dividend sum\",\n",
        "    which is expected to be equal to the total return that is calculated from \"AdjClose\" prices\n",
        "    '''\n",
        "    yearly_data['CalReturn'] = (yearly_data['Close'] + yearly_data['DivSum']) / yearly_data['Close'].shift(1) - 1\n",
        "    # set the display format\n",
        "    yearly_data[['DivRatio','Return','TotalReturn','CalReturn']] = yearly_data[['DivRatio','Return','TotalReturn','CalReturn']].mul(100).round(2)\n",
        "    '''\n",
        "    #yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']] = yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']].applymap(\"{:.2f}%\".format)\n",
        "    yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']]= \\\n",
        "     yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']].applymap(lambda x: f\"{x:.2f}%\" if not pd.isna(x) else \"NaN\")\n",
        "    '''\n",
        "    # Use .applymap() and lambda to format the values as percentage strings only if they are not NaN\n",
        "    yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']]= \\\n",
        "         yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']].applymap(lambda x: f\"{x:.2f}%\" if not pd.isna(x) else x)\n",
        "\n",
        "    # 'Date' column is no longer required\n",
        "    yearly_data.drop('Date', axis=1, inplace=True)\n",
        "    return yearly_data\n",
        "\n",
        "#==============================================================================\n",
        "# Part 7: utility functions\n",
        "# get the last trading day of S&P 500 in string format\n",
        "def get_last_trading_day():\n",
        "    # Get today's date, use .strftime(\"%Y-%m-%d\") to convert to a string\n",
        "    today_date_str=datetime.now(pytz.timezone('America/New_York')).date().strftime(\"%Y-%m-%d\")\n",
        "    stock = yf.Ticker(\"^GSPC\") # S&P 500 (^GSPC) ticker\n",
        "    #  search and see yfinance_BUG_1 NOTE in this file\n",
        "    history_df=stock.history(period=\"max\", end=today_date_str)[\"Close\"]\n",
        "    last_trading_day_str = history_df.index.max().date().strftime(\"%Y-%m-%d\")\n",
        "    return last_trading_day_str\n",
        "\n",
        "def str_to_integer(integer_str):\n",
        "    try:\n",
        "        integer_number = int(integer_str)\n",
        "        return integer_number\n",
        "    except ValueError:\n",
        "        return -1\n",
        "\n",
        "# validate the date string\n",
        "def is_valid_date(date_string):\n",
        "    try:\n",
        "        # Attempt to parse the date string\n",
        "        datetime.strptime(date_string, \"%Y-%m-%d\")\n",
        "        return True\n",
        "    except ValueError:\n",
        "        # Raised when the date string is not in the expected format\n",
        "        return False\n",
        "\n",
        "def date_label_conversion_strip_time(all_tickers_returns_df, calculation_end_date_str):\n",
        "    all_tickers_returns_df.index=all_tickers_returns_df.index.date\n",
        "    all_tickers_returns_df.index.name='date'\n",
        "    # print(\"debug get_annual_returns_tickers_df\", all_tickers_returns_df)\n",
        "    # Convert calculation_end_date_str to a datetime object, replace the index's mon/day portion of date\n",
        "    end_date_datetime_obj = datetime.strptime(calculation_end_date_str, \"%Y-%m-%d\")\n",
        "    all_tickers_returns_df.index = all_tickers_returns_df.index.map(\n",
        "      lambda x: x.replace(month=end_date_datetime_obj.month,\n",
        "      day=end_date_datetime_obj.day))\n",
        "    return all_tickers_returns_df\n",
        "\n",
        "#==============================================================================\n",
        "# Part 8: gradio handling - Input command handling and display in web page\n",
        "\n",
        "help_info_str=\"Input Formats:\\n  \\\n",
        "            1. ticker list....................Example:  spy vfv.to xiu.to xic.to xfn.to ry.to \\n \\\n",
        "            2. One of default ticker list, a number between 1 and 7....Example:   0, or 1, ...,7 \\n \\\n",
        "            3. CalculationEndDate as prefix.  Example:   2020-12-31 2 \\n \\\n",
        "            .........................................2020-12-31 spy vfv.to xiu.to xic.to xfn.to ry.to \\n \\\n",
        "            4. single ticker: Dividend/Close/AdjClose/Return/TotalReturn/CalReturn(by Close/Dividends).  @1 spy \\n \\\n",
        "            note: daily adjusted close data are from Yahoo Finance. \"\n",
        "\n",
        "# Main Handling Process\n",
        "def calculation_response(message):\n",
        "    # if there is no input, display help information\n",
        "    if message==\"\":\n",
        "        return help_info_str\n",
        "\n",
        "    tickers=message.split()\n",
        "\n",
        "    # ******************************************************************************\n",
        "    #  processing web input parameters\n",
        "    #  set calculation_end_date_str, and tickers\n",
        "\n",
        "    #---------------------------------------------------------\n",
        "    # single stock ticker - detailed information\n",
        "    if (tickers[0] == \"@1\"):\n",
        "        tickers.pop(0) # remove the first string which is \"@1\"\n",
        "        if len(tickers)==0:\n",
        "            ticker = 'spy' # default ticker = spy\n",
        "        else:\n",
        "            ticker=tickers[0]\n",
        "        output_string=f\"\\n {ticker}\\n\"\n",
        "        output_dataframe0=get_yearly_single_stock_data(ticker)\n",
        "        output_html=output_string + output_dataframe0.to_html()\n",
        "        return output_html\n",
        "\n",
        "    #----------------------------------------------------------\n",
        "    # Get today's date, use .strftime(\"%Y-%m-%d\") to convert to a string\n",
        "    #calculation_end_date_str=datetime.now(pytz.timezone('America/New_York')).date().strftime(\"%Y-%m-%d\")\n",
        "    calculation_end_date_str = get_last_trading_day()\n",
        "    # Check whether the first str is date for calculation end date\n",
        "    if is_valid_date(tickers[0]):\n",
        "        calculation_end_date_str = tickers[0] # reset calculation_end_date_str\n",
        "        tickers.pop(0) # remove the first string which is the date\n",
        "\n",
        "    #............ For display trailing and cumulative returns at month_boundary_date\n",
        "    # Assuming calculation_end_date_str contains the date string '2024-01-03'\n",
        "    calculation_end_date = datetime.strptime(calculation_end_date_str, '%Y-%m-%d')\n",
        "    # Calculate the first day of the current month\n",
        "    first_day_of_month = calculation_end_date.replace(day=1)\n",
        "    # Calculate the last day of the month\n",
        "    last_day_of_month = (calculation_end_date.replace(day=1) + timedelta(days=32)).replace(day=1) - timedelta(days=1)\n",
        "    # Calculate the last day of the previous month\n",
        "    last_day_of_previous_month = first_day_of_month - timedelta(days=1)\n",
        "    # Check if the original date is the last day of the month\n",
        "    if (calculation_end_date == last_day_of_month):\n",
        "        calculation_end_date_month_boundary_date_str=calculation_end_date_str\n",
        "    else:\n",
        "        calculation_end_date_month_boundary_date_str=last_day_of_previous_month.strftime('%Y-%m-%d')\n",
        "    # calculation_end_date_for_others are for trailing and cumulative returns\n",
        "    calculation_end_date_for_others_str=calculation_end_date_month_boundary_date_str\n",
        "\n",
        "    '''  Handling Feb 29 of leap years.\n",
        "    For leap years, to simiplify the calculation,  Feb 28 will be used to replace Feb 29 for\n",
        "    for calculating returns.\n",
        "    Therefore, if calculation_end_date_for_others_str is Feb 29, then replace 29 to 28 of calculation_end_date_for_others_str\n",
        "    '''\n",
        "    leap_year=False\n",
        "    if (\n",
        "        calculation_end_date_for_others_str[-5:] == '02-29'\n",
        "    ):\n",
        "        calculation_end_date_for_others_str = calculation_end_date_for_others_str[:-2] + '28'\n",
        "        leap_year=True\n",
        "    #................End\n",
        "\n",
        "    # Check whether numebr 0, 1, 2, .. is selected for using a default ticker list\n",
        "    integer_value=str_to_integer(tickers[0])\n",
        "    if (integer_value >= 0 and integer_value <len(tickers_lists)):\n",
        "        tickers=tickers_lists[integer_value]\n",
        "\n",
        "    # if no tickers were set, display help information\n",
        "    if len(tickers)==0:\n",
        "        return help_info_str\n",
        "    tmp_ticker_list=tickers\n",
        "    tickers = [ticker.lower() for ticker in tmp_ticker_list]\n",
        "\n",
        "    #*********************************************************************************\n",
        "    # Calculating year-end prices, Annual, Trailing, Cumulative, and CAGR returns & generating html for display\n",
        "    #\n",
        "    # list of year-end prices of stocks\n",
        "    output_string1= f\"\\nAdj Close Prices ($)\\n\"\n",
        "    data_adj_close_year_end_df, data_adj_close_df = stock_prices_df(tickers, calculation_end_date_str)\n",
        "    output_dataframe= data_adj_close_year_end_df\n",
        "    output_html1=output_string1 + output_dataframe.to_html()\n",
        "\n",
        "    #  Annual Total Return\n",
        "    output_string = f\"\\nAnnual Total Return (%) as {calculation_end_date_str}\\n\"\n",
        "    #output_dataframe = get_annual_returns_tickers_year_boundary_df(tickers, calculation_end_date_str)\n",
        "    output_dataframe = get_annual_returns_year_end_df(data_adj_close_year_end_df, calculation_end_date_str)\n",
        "    output_dataframe = output_dataframe.dropna(how='all')\n",
        "    output_dataframe = output_dataframe.round(4)*100\n",
        "    #output_dataframe.index=output_dataframe.index.date\n",
        "    # Assuming your DataFrame is named output_dataframe\n",
        "    last_date = output_dataframe.index[-1]\n",
        "    output_dataframe = output_dataframe.rename(index={last_date: calculation_end_date_str})\n",
        "    # Convert the DataFrame to HTML, Combine the expected string outputs\n",
        "    output_html2 = output_string + output_dataframe.to_html()\n",
        "    print(\"\\ndebug2  output_dataframe\\n\", output_dataframe)\n",
        "\n",
        "    # annual_returns  - at any given day, for calculating trailing and cumulative returns, not to be displayed\n",
        "    #annual_returns_dataframe=get_annual_returns_tickers_df(tickers, calculation_end_date_for_others_str)\n",
        "    annual_returns_dataframe=get_annual_returns_anyday_df(data_adj_close_df, calculation_end_date_str)\n",
        "    print(\"\\ndebug2-T  annual_returns_dataframe\\n\", annual_returns_dataframe)\n",
        "\n",
        "    # Trailing Return\n",
        "    if (leap_year):\n",
        "        output_string3 = f\"\\nTrailing Total Return (%) as {calculation_end_date_for_others_str} (leap year: Feb 29 replaced by Feb 28 for approximation)\\n\"\n",
        "    else:\n",
        "        output_string3 = f\"\\nTrailing Total Return (%) as {calculation_end_date_for_others_str}\\n\"\n",
        "    output_dataframe3=get_trailing_return_all(annual_returns_dataframe)\n",
        "    output_dataframe3 = output_dataframe3.dropna(how='all')\n",
        "    # Insert an empty to align the ticker symbols with annual return display\n",
        "    output_dataframe3.insert(0, \"--------\", \"      \")\n",
        "    output_dataframe3.index.name=\"years\"\n",
        "    output_html3=output_string3 + output_dataframe3.to_html()\n",
        "    #print(\"\\ndebug3\\n\", output_string3, output_dataframe3)\n",
        "    # Cumulative Return\n",
        "    output_string4 = f\"\\nCumulative Return (%) as {calculation_end_date_for_others_str}\\n\"\n",
        "    cumulative_return_all_dataframe=get_cumulative_return_all(annual_returns_dataframe)\n",
        "    cumulative_return_all_dataframe = cumulative_return_all_dataframe.dropna(how='all')\n",
        "    output_dataframe4=cumulative_return_all_dataframe.round(4)*100\n",
        "    output_dataframe4.index.name=\"years\"\n",
        "    output_html4=output_string4 + output_dataframe4.to_html()\n",
        "\n",
        "    # CAGR Return\n",
        "    output_string5 = f\"\\nCompound Annual Growth Rate (CAGR) (%) as {calculation_end_date_for_others_str}\\n\"\n",
        "    output_dataframe5=get_cagr_return_all (cumulative_return_all_dataframe)\n",
        "    output_dataframe5=output_dataframe5.round(4)*100\n",
        "    output_html5=output_string5 + output_dataframe5.to_html()\n",
        "    output_html = output_html1 + output_html2 + output_html3 + output_html4\n",
        "    return  output_html\n",
        "\n",
        "# Gradio Web interface\n",
        "with gr.Blocks() as web_block:\n",
        "\n",
        "    chatbot = gr.Chatbot(height=\"500px\")\n",
        "    # Create a row element for the Textbox and Clear button\n",
        "    with gr.Row():\n",
        "        #msg = gr.Textbox(label=\"stock tickers input\", scale=2, min_width=380)\n",
        "        msg = gr.Textbox(show_label=False, scale=2, min_width=380)\n",
        "        clear = gr.ClearButton([msg, chatbot], scale=0, min_width=50)\n",
        "\n",
        "    def respond(message, chat_history):\n",
        "        bot_message = calculation_response(message)\n",
        "        chat_history.append((message, bot_message))\n",
        "        return \"\", chat_history\n",
        "\n",
        "    msg.submit(respond, # function\n",
        "     [msg, chatbot],  # inputs of the function\n",
        "     [msg, chatbot]   # outputs of the function\n",
        "               )\n",
        "web_block.launch()\n",
        "#web_block.launch(debug=True)\n",
        "\n",
        "# test cases:\n",
        "# calculation_response(\"4\")\n",
        "#calculation_response(\"SPY\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## backup -example 9"
      ],
      "metadata": {
        "id": "RGjhh9Cb2ovo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wx0H96719E1r"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Example 9 for using yfinance\n",
        "\n",
        "Calculate annual, trailing, cumumlative, and CAGR returns for multiple stocks.\n",
        "* The start date can be an arbitrary date.  The default is the current date.\n",
        "* annual return is displayed from the default current day, or an arbitrary given\n",
        "  day (except for Feb 29 for leap year)\n",
        "  For leap years, use Feb 28 to replace Feb 29 as simplification & approximation\n",
        "* trailing, cumumlative returns are currently displayed from the month boundary (last day of Month)\n",
        "  prior to the given date.\n",
        "* However, trailing, cumumlative returns can be displayed\n",
        "  from any date, which can be not at the month boundary (last day of Month),\n",
        "  by minor change of setting calculation_end_date_for_others_str = calculation_end_date_str.\n",
        "  prior to the given date in the function \"calculation_response(message, history)\"\n",
        "\n",
        "Author: Gang Luo\n",
        "'''\n",
        "script_version = '(2024-03-04.2)'\n",
        "import gradio as gr\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import pytz\n",
        "DEBUG_ENABLED = True\n",
        "#==============================================================================\n",
        "\n",
        "print_yearly_total_return = True\n",
        "num_years_calculation=52   # total years for calculation\n",
        "\n",
        "# Define a list of years to calculate the trailing returns, cumulative returns, and so on\n",
        "# remove the row of current year row since it is not a full year.\n",
        "years_list = [1, 2, 3, 5, 10, 15, 20, 25, 30, 40, 50, 60]\n",
        "\n",
        "# Set the stock tickers list\n",
        "tickers_lists = [[\"qqq\",\"hxq.to\",\"spy\", \"vfv.to\",\"xiu.to\", \"xbb.to\",\"xcb.to\",\"xhb.to\"], #0  checking ETF\n",
        "    [\"qqq\",\"spy\", \"vfv.to\", \"vgg.to\", \"zlu.to\", \"xiu.to\", \"vdy.to\", \"xfn.to\", \"ry.to\", \"td.to\", \"na.to\",\n",
        "      \"slf.to\", \"gwo.to\", \"bce.to\", \"t.to\", \"rci-b.to\", \"enb.to\", \"trp.to\", \"zlb.to\", \"cp.to\"], #1 main monitoring list\n",
        "    [\"qqq\",\"spy\",\"vfv.to\", \"xiu.to\", \"zeb.to\", \"xfn.to\", \"na.to\",\"ry.to\", \"bmo.to\",\"bns.to\", \"td.to\", \"cm.to\", \"cwb.to\",\n",
        "      \"slf.to\", \"gwo.to\", \"bce.to\", \"t.to\", \"rci-b.to\", \"enb.to\", \"trp.to\", \"xdv.to\",\"cdz.to\",\"vdy.to\", \"xdiv.to\"],  #2   financial  ETF & stocks\n",
        "    [\"^ndx\",\"qqq\",\"^GSPC\",\"spy\", \"vfv.to\", \"vgg.to\",\"zlu.to\",\"msft\",\"AAPL\",\"goog\",\"AMZN\",\"NVDA\",\"meta\",\"tsla\",\"BRK-A\",\"shop.to\",\"hxq.to\"],   #3  US mega stocks + risky shopfy\n",
        "    [\"^DJI\",\"dia\",\"^GSPC\",\"spy\",\"voo\",\"ivv\", \"tpu-u.to\",\"vfv.to\", \"zsp.to\",\"hxs.to\",\"tpu.to\",\"xus.to\", \"xsp.to\",\n",
        "      \"^IXIC\",\"^ndx\", \"qqq\",\"hxq.to\",\"^GSPTSE\",\"xic.to\",\"xiu.to\", \"HXT.TO\", \"TTP.TO\",\"ZCN.TO\", \"xfn.to\", \"xit.to\"], #4   indexes and index ETFs\n",
        "    [\"dia\",\"^DJI\",\"^GSPC\",\"spy\",\"vfv.to\", \"zsp.to\",\"hxs.to\",\"xus.to\", \"xsp.to\",\n",
        "      \"^IXIC\",\"qqq\",\"hxq.to\",\"^GSPTSE\",\"xic.to\",\"xiu.to\", \"HXT.TO\", \"xfn.to\"], #5   indexes and typical index ETFs\n",
        "    [\"^IXIC\",\"^ndx\",\"ONEQ\",\"CIBR\",\"QQJG\", \"qqq\", \"tqqq\", \"spy\", \"vfv.to\", \"HXQ.to\", \"ZQQ.to\", \"XQQ.to\", \"QQC.to\", \"ZNQ.TO\",\n",
        "         \"xiu.to\", \"xit.to\"],  #6   Nasdaq ETF and TSX IT ETF\n",
        "    [\"qqq\",\"tqqq\",\"sqqq\", \"QLD\", \"spy\", \"spxu\", \"upro\", \"sso\", \"spxl\",\"tecl\"], #7 leveraged ETFs\n",
        "    [\"^IXIC\",\"^DJI\",\"^GSPC\",\"^GSPTSE\"], #8 testing\n",
        "    [\"vfv.to\",\"spy\"] #9 testing\n",
        "]\n",
        "\n",
        "#==============================================================================\n",
        "# Part 1:\n",
        "#  retrieve daily adjusted close prices of a list of tickers from yahoo finance\n",
        "#  Generate the year-end adjusted close prices\n",
        "#  return year-end adjusted close prices, and  daily adjusted close prices\n",
        "def stock_prices_df(tickers_list, end_date_str):\n",
        "    tickers_list_upper = [ticker.upper() for ticker in tickers_list]\n",
        "    tickers_str = \", \".join(tickers_list_upper)\n",
        "    try:\n",
        "        '''\n",
        "        'try' statement for handlingy the exception error  for yf.download\n",
        "        '''\n",
        "        # Download the historical data\n",
        "        data = yf.download(tickers_str, period=\"max\")\n",
        "    except:\n",
        "        return  pd.DataFrame()\n",
        "    else:\n",
        "        data_adj_close = data['Adj Close']\n",
        "\n",
        "    # Filter out rows with dates newer than calculation_end_date\n",
        "    data_adj_close = data_adj_close[data_adj_close.index <= end_date_str]\n",
        "    #print(\"\\nDebug- stock_prices_df\\n\", data_adj_close)\n",
        "\n",
        "    # Rearrange columns based on the order in tickers_list_upper\n",
        "    if len(tickers_list)>1:\n",
        "        data_adj_close = data_adj_close.reindex(columns=tickers_list_upper)\n",
        "\n",
        "    # needed this when having only a single ticker in the ticker list\n",
        "    if len(tickers_list_upper)==1:\n",
        "        data_adj_close = pd.DataFrame(data_adj_close)\n",
        "        data_adj_close.rename(columns={'Adj Close': tickers_list_upper[0]}, inplace=True)\n",
        "\n",
        "    data_adj_close.columns = map(str.lower, data_adj_close.columns) # must after  pd.DataFrame(data_adj_close)\n",
        "    data_adj_close_year_end = data_adj_close.resample('A').ffill().round(2) # must before index changed to date\n",
        "\n",
        "    data_adj_close.index=data_adj_close.index.date\n",
        "    data_adj_close_year_end.index=data_adj_close_year_end.index.date\n",
        "\n",
        "    last_date = data_adj_close.index[-1]\n",
        "    data_adj_close_year_end = data_adj_close_year_end.rename(index={last_date: end_date_str})\n",
        "\n",
        "    return data_adj_close_year_end, data_adj_close\n",
        "\n",
        "#==============================================================================\n",
        "# Part 2:  Calculate annual returns at year end, and at any given day (by calculation_end_date_str)\n",
        "#\n",
        "# annual return calculation can start at any given day\n",
        "def get_annual_returns_anyday_df(daily_adj_close_df, calculation_end_date_str):\n",
        "\n",
        "    calculation_end_date=pd.to_datetime(calculation_end_date_str).tz_localize('America/New_York')\n",
        "\n",
        "    # Create a DataFrame with a complete date range\n",
        "    date_range = pd.date_range(start=daily_adj_close_df.index.min(), end=daily_adj_close_df.index.max(), freq='D')\n",
        "\n",
        "    complete_stock_history = pd.DataFrame(index=date_range)\n",
        "    # Merge the complete DataFrame with the original stock_history\n",
        "    complete_stock_history = complete_stock_history.merge(daily_adj_close_df, how='left', left_index=True, right_index=True)\n",
        "    complete_stock_history = complete_stock_history.ffill()  # fill the newy added rows with previous day value\n",
        "    '''\n",
        "    Filter out the rows that matches the month and date of calculation_end_date, which are the ends of\n",
        "    annual periods from the calculation_end_date.\n",
        "    '''\n",
        "    # Filter out rows with dates newer than calculation_end_date\n",
        "    #filtered_stock_history = complete_stock_history[complete_stock_history.index <= calculation_end_date]\n",
        "    # note\" daily_adj_close_df satisfys daily_adj_close_df.index <= calculation_end_date\n",
        "    filtered_stock_history = complete_stock_history\n",
        "    #print(filtered_stock_history)\n",
        "    target_month=filtered_stock_history.index.max().month\n",
        "    target_day=filtered_stock_history.index.max().day\n",
        "    #print(\"target_month\", target_month, \"target_day\",target_day, \"start_year\", filtered_stock_history.index.max().year)\n",
        "    annual_returns = filtered_stock_history[(filtered_stock_history.index.month == target_month)\n",
        "           & (filtered_stock_history.index.day ==target_day)]\n",
        "    annual_returns_percent = annual_returns.pct_change().dropna(how='all')\n",
        "\n",
        "    annual_returns_df = pd.DataFrame(annual_returns_percent)\n",
        "    #print(\"\\ndebug-annual_returns_df\\n\", annual_returns_df)\n",
        "    return annual_returns_df\n",
        "\n",
        "# annual return calculation can start at year end\n",
        "def get_annual_returns_year_end_df(data_adj_close_df, calculation_end_date_str):\n",
        "    annual_returns_percent = data_adj_close_df.pct_change().dropna(how='all')\n",
        "    return annual_returns_percent\n",
        "\n",
        "#==============================================================================\n",
        "# Part 3: calculate the annualized trailing total return from the data generated in step 1 & display\n",
        "# Define a function to calculate the annualized trailing total return for a given number of years\n",
        "def get_trailing_return(ticker, data, years):\n",
        "    # Get the total return values for the last n years\n",
        "    trailing_data = data[ticker].tail(years)\n",
        "    # Check if there are empty values within years\n",
        "    if trailing_data.isna().any():\n",
        "        return np.nan\n",
        "    # Check if there are valid total return values for all years\n",
        "    if len(trailing_data) == years:\n",
        "        # Convert the percentage strings to numeric values\n",
        "        trailing_data = trailing_data.astype(str).str.replace('%', '').astype(float)\n",
        "        \"\"\" Calculate the annualized trailing total return using the formula from Investopedia[^1^][1]:\n",
        "            Annualized Return = [(1 + r1) * (1 + r2) * ... * (1 + rn)]^(1/n) - 1\n",
        "            Where r1, r2, ..., rn are the total return values for each year                    \"\"\"\n",
        "        annualized_trailing_return = (trailing_data + 1).prod() ** (1 / years) - 1\n",
        "\n",
        "        # Format the result as a percentage with two decimal places\n",
        "        annualized_trailing_return = annualized_trailing_return * 100\n",
        "        annualized_trailing_return = annualized_trailing_return.round(2)\n",
        "        return annualized_trailing_return\n",
        "    else:\n",
        "        return np.nan\n",
        "\n",
        "# Define a function to Loop through the list and print the trailing returns for each num_years\n",
        "def get_trailing_return_column(ticker, annual_returns_df):\n",
        "    trailing_return_column = {}\n",
        "    for num_years in years_list:\n",
        "        # Check if the ticker data is available in all_tickers_returns_df\n",
        "        if ticker in annual_returns_df.columns:\n",
        "            # using data from step 1, avoiding get_annual_returns_df(ticker) for less traffic from yahoo server\n",
        "            data = annual_returns_df[[ticker]]\n",
        "            trailing_return = get_trailing_return(ticker, data, num_years)\n",
        "            trailing_return_column[f\"{num_years}-Year\"] = trailing_return\n",
        "        else:\n",
        "            print(f\"Data not available for {ticker}. Skipping.\")\n",
        "            trailing_return_column[f\"{num_years}-Year\"] = np.nan\n",
        "    return trailing_return_column\n",
        "\n",
        "# Create an empty DataFrame to store all tickers' trailing returns\n",
        "def get_trailing_return_all(annual_returns_df):\n",
        "    all_tickers_trailing_returns_df = pd.DataFrame(index=years_list)\n",
        "    tickers=annual_returns_df.columns.tolist()\n",
        "    # Loop through each ticker in the list\n",
        "    for ticker in tickers:\n",
        "        trailing_returns = get_trailing_return_column(ticker, annual_returns_df)\n",
        "        # Add the trailing returns to the DataFrame\n",
        "        all_tickers_trailing_returns_df[ticker] = pd.Series(trailing_returns).values\n",
        "    return all_tickers_trailing_returns_df\n",
        "\n",
        "#==============================================================================\n",
        "# Part 4: calculate the cumulative return from the data (all_tickers_returns_df) generated in part 1 & display\n",
        "#  Define a function to calculate the cumulative return for a given number of years from a ticker\n",
        "def get_cumulative_return(ticker, data, years):\n",
        "    # Calculate the cumulative return\n",
        "    cumulative_return = (1 + data[ticker]).rolling(window=years).apply(lambda x: x.prod(), raw=True) - 1\n",
        "    return cumulative_return\n",
        "\n",
        "# Define a function to Loop through the list and return the cumulative returns for each num_years\n",
        "def get_cumulative_return_column(ticker, annual_returns_df):\n",
        "    cumulative_returns = {}\n",
        "    for years in years_list:\n",
        "        # Calculate the cumulative return for the given number of years\n",
        "        cumulative_return = get_cumulative_return(ticker, annual_returns_df, years)\n",
        "        # Get the last value, which is the cumulative return up to the current year\n",
        "        cumulative_returns[years] = cumulative_return.iloc[-1]\n",
        "    return cumulative_returns\n",
        "\n",
        "def get_cumulative_return_all(annual_returns_df):\n",
        "    # Create an empty DataFrame with years_list as the index for cumulative  returns\n",
        "    all_tickers_cumulative_returns_df = pd.DataFrame(index=years_list)\n",
        "    tickers=annual_returns_df.columns.tolist()\n",
        "    # Loop through each ticker in the list\n",
        "    for ticker in tickers:\n",
        "        cumulative_returns = get_cumulative_return_column(ticker, annual_returns_df)\n",
        "        # Add the trailing returns to the DataFrame\n",
        "        all_tickers_cumulative_returns_df[ticker] = pd.Series(cumulative_returns).values\n",
        "    return all_tickers_cumulative_returns_df\n",
        "\n",
        "#==============================================================================\n",
        "# Part 5: calculate the  CAGR (Compound Annual Growth Rate) from the data\n",
        "# in all_tickers_cumulative_returns_df generated earlier & display\n",
        "# Define a function to calculate the CAGR from the cumulative value and the years\n",
        "def calculate_cagr(value, years):\n",
        "    # Otherwise, calculate the CAGR using the formula\n",
        "    cagr = (value + 1) ** (1 / np.array(years)) - 1\n",
        "    #print(\"debug-cagr\\n\", cagr, \"end\")\n",
        "    return cagr\n",
        "\n",
        "# Define a function to format the Float64Index values into percentage strings\n",
        "def format_to_percentage(value):\n",
        "    # If any element in the value array is not null, format it as a percentage string with two decimal places\n",
        "    if np.any(pd.notnull(value)):\n",
        "        return f\"{value:.2f}%\"\n",
        "    # Otherwise, return None\n",
        "    return None\n",
        "\n",
        "def get_cagr_return_all(all_tickers_cumulative_returns_df):\n",
        "    # Apply the calculate_cagr function to each column of the DataFrame\n",
        "    all_tickers_cagrs_df = all_tickers_cumulative_returns_df.apply(lambda x: calculate_cagr(x, x.index), axis=0)\n",
        "    return all_tickers_cagrs_df\n",
        "\n",
        "#==============================================================================\n",
        "# Part 6:\n",
        "# single ticker's Prices, Returns,Dividends, good for verifying whether \"Adj Close\" is correct.\n",
        "'''\n",
        "    Calculate and display: yearly dividendSum, 'Close' & 'Adj Close' prices,\n",
        "    Return(by 'Close' price), total return(by 'Adj Close' price),\n",
        "    CalReturn(total return by 'Close' price and \"dividendSum).\n",
        "    Note: CalReturn from  is expected to be nearly same as  total return,\n",
        "           when the 'Adj Close' price is correct.\n",
        "'''\n",
        "def get_yearly_single_stock_data(ticker):\n",
        "    stock = yf.Ticker(ticker)\n",
        "    #-------- mainly for downloading 'Dividends'\n",
        "    history = stock.history(period=\"max\")\n",
        "    dividend_history=history['Dividends']\n",
        "    dividend_history.index=dividend_history.index.date\n",
        "\n",
        "    #-------- mainly for downloading 'Close','Adj Close'\n",
        "    dld_history=yf.download(ticker, period=\"max\")\n",
        "    dld_history=dld_history[['Close','Adj Close']]\n",
        "    dld_history.rename(columns={'Adj Close': 'AdjClose'}, inplace=True)\n",
        "    date_range = pd.date_range(start=dld_history.index.min(), end=dld_history.index.max(), freq='D')\n",
        "    complete_history = pd.DataFrame(index=date_range)\n",
        "\n",
        "    # Merge the complete DataFrame with the original stock_history\n",
        "    complete_history = complete_history.merge(dld_history, how='left', left_index=True, right_index=True)\n",
        "    complete_history[['Close','AdjClose']] = complete_history[['Close','AdjClose']].ffill().round(3)\n",
        "\n",
        "    # Merge dividend into complete_history\n",
        "    complete_history = complete_history.merge(dividend_history, how='left', left_index=True, right_index=True)\n",
        "    # replace all NaN values in the 'Dividends' column with 0.0\n",
        "    complete_history['Dividends'] = complete_history['Dividends'].fillna(0.0).round(3)\n",
        "\n",
        "    complete_history['Year']=complete_history.index.year\n",
        "    complete_history['Date']=complete_history.index\n",
        "    yearly_data = complete_history.groupby('Year').agg({'Date': 'last', 'Close': 'last', 'AdjClose': 'last','Dividends': 'sum'})\n",
        "    yearly_data.rename(columns={'Dividends': 'DivSum'}, inplace=True)\n",
        "\n",
        "    # calculating 'Return' and 'TotalReturn'\n",
        "    yearly_data['DivRatio']=yearly_data['DivSum'] / yearly_data['Close']\n",
        "    yearly_data['Return']=yearly_data['Close'].pct_change()\n",
        "    yearly_data['TotalReturn']=yearly_data['AdjClose'].pct_change()\n",
        "\n",
        "    '''\n",
        "    The CalReturn column is the yearly total return calculated from un-adjusted \"Close\" prices and yearly \"dividend sum\",\n",
        "    which is expected to be equal to the total return that is calculated from \"AdjClose\" prices\n",
        "    '''\n",
        "    yearly_data['CalReturn'] = (yearly_data['Close'] + yearly_data['DivSum']) / yearly_data['Close'].shift(1) - 1\n",
        "    # set the display format\n",
        "    yearly_data[['DivRatio','Return','TotalReturn','CalReturn']] = yearly_data[['DivRatio','Return','TotalReturn','CalReturn']].mul(100).round(2)\n",
        "    '''\n",
        "    #yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']] = yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']].applymap(\"{:.2f}%\".format)\n",
        "    yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']]= \\\n",
        "     yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']].applymap(lambda x: f\"{x:.2f}%\" if not pd.isna(x) else \"NaN\")\n",
        "    '''\n",
        "    # Use .applymap() and lambda to format the values as percentage strings only if they are not NaN\n",
        "    yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']]= \\\n",
        "         yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']].applymap(lambda x: f\"{x:.2f}%\" if not pd.isna(x) else x)\n",
        "\n",
        "    # 'Date' column is no longer required\n",
        "    yearly_data.drop('Date', axis=1, inplace=True)\n",
        "    return yearly_data\n",
        "\n",
        "#==============================================================================\n",
        "# Part 7: utility functions\n",
        "# get the last trading day of S&P 500 in string format\n",
        "def get_last_trading_day():\n",
        "    # Get today's date, use .strftime(\"%Y-%m-%d\") to convert to a string\n",
        "    today_date_str=datetime.now(pytz.timezone('America/New_York')).date().strftime(\"%Y-%m-%d\")\n",
        "    stock = yf.Ticker(\"^GSPC\") # S&P 500 (^GSPC) ticker\n",
        "    #  search and see yfinance_BUG_1 NOTE in this file\n",
        "    history_df=stock.history(period=\"max\", end=today_date_str)[\"Close\"]\n",
        "    last_trading_day_str = history_df.index.max().date().strftime(\"%Y-%m-%d\")\n",
        "    return last_trading_day_str\n",
        "\n",
        "def str_to_integer(integer_str):\n",
        "    try:\n",
        "        integer_number = int(integer_str)\n",
        "        return integer_number\n",
        "    except ValueError:\n",
        "        return -1\n",
        "\n",
        "# validate the date string\n",
        "def is_valid_date(date_string):\n",
        "    try:\n",
        "        # Attempt to parse the date string\n",
        "        datetime.strptime(date_string, \"%Y-%m-%d\")\n",
        "        return True\n",
        "    except ValueError:\n",
        "        # Raised when the date string is not in the expected format\n",
        "        return False\n",
        "\n",
        "def date_label_conversion_strip_time(all_tickers_returns_df, calculation_end_date_str):\n",
        "    all_tickers_returns_df.index=all_tickers_returns_df.index.date\n",
        "    all_tickers_returns_df.index.name='date'\n",
        "    # print(\"debug get_annual_returns_tickers_df\", all_tickers_returns_df)\n",
        "    # Convert calculation_end_date_str to a datetime object, replace the index's mon/day portion of date\n",
        "    end_date_datetime_obj = datetime.strptime(calculation_end_date_str, \"%Y-%m-%d\")\n",
        "    all_tickers_returns_df.index = all_tickers_returns_df.index.map(\n",
        "      lambda x: x.replace(month=end_date_datetime_obj.month,\n",
        "      day=end_date_datetime_obj.day))\n",
        "    return all_tickers_returns_df\n",
        "\n",
        "#==============================================================================\n",
        "# Part 8: gradio handling - Input command handling and display in web page\n",
        "\n",
        "help_info_str=\"Input Formats:\\n  \\\n",
        "            1. ticker list....................Example:  spy vfv.to xiu.to xic.to xfn.to ry.to \\n \\\n",
        "            2. One of default ticker list, a number between 1 and 7....Example:   0, or 1, ...,7 \\n \\\n",
        "            3. CalculationEndDate as prefix.  Example:   2020-12-31 2 \\n \\\n",
        "            .........................................2020-12-31 spy vfv.to xiu.to xic.to xfn.to ry.to \\n \\\n",
        "            4. single ticker: Dividend/Close/AdjClose/Return/TotalReturn/CalReturn(by Close/Dividends).  @1 spy \\n \\\n",
        "            note: daily adjusted close data are from Yahoo Finance. \"\n",
        "\n",
        "# Main Handling Process\n",
        "def calculation_response(message):\n",
        "    # if there is no input, display help information\n",
        "    if message==\"\":\n",
        "        return help_info_str\n",
        "\n",
        "    tickers=message.split()\n",
        "\n",
        "    # ******************************************************************************\n",
        "    #  processing web input parameters\n",
        "    #  set calculation_end_date_str, and tickers\n",
        "\n",
        "    #---------------------------------------------------------\n",
        "    # single stock ticker - detailed information\n",
        "    if (tickers[0] == \"@1\"):\n",
        "        tickers.pop(0) # remove the first string which is \"@1\"\n",
        "        if len(tickers)==0:\n",
        "            ticker = 'spy' # default ticker = spy\n",
        "        else:\n",
        "            ticker=tickers[0]\n",
        "        output_string=f\"\\n {ticker}\\n\"\n",
        "        output_dataframe0=get_yearly_single_stock_data(ticker)\n",
        "        output_html=output_string + output_dataframe0.to_html()\n",
        "        return output_html\n",
        "\n",
        "    #----------------------------------------------------------\n",
        "    # Get today's date, use .strftime(\"%Y-%m-%d\") to convert to a string\n",
        "    #calculation_end_date_str=datetime.now(pytz.timezone('America/New_York')).date().strftime(\"%Y-%m-%d\")\n",
        "    calculation_end_date_str = get_last_trading_day()\n",
        "    # Check whether the first str is date for calculation end date\n",
        "    if is_valid_date(tickers[0]):\n",
        "        calculation_end_date_str = tickers[0] # reset calculation_end_date_str\n",
        "        tickers.pop(0) # remove the first string which is the date\n",
        "\n",
        "    #............ For display trailing and cumulative returns at month_boundary_date\n",
        "    # Assuming calculation_end_date_str contains the date string '2024-01-03'\n",
        "    calculation_end_date = datetime.strptime(calculation_end_date_str, '%Y-%m-%d')\n",
        "    # Calculate the first day of the current month\n",
        "    first_day_of_month = calculation_end_date.replace(day=1)\n",
        "    # Calculate the last day of the month\n",
        "    last_day_of_month = (calculation_end_date.replace(day=1) + timedelta(days=32)).replace(day=1) - timedelta(days=1)\n",
        "    # Calculate the last day of the previous month\n",
        "    last_day_of_previous_month = first_day_of_month - timedelta(days=1)\n",
        "    # Check if the original date is the last day of the month\n",
        "    if (calculation_end_date == last_day_of_month):\n",
        "        calculation_end_date_month_boundary_date_str=calculation_end_date_str\n",
        "    else:\n",
        "        calculation_end_date_month_boundary_date_str=last_day_of_previous_month.strftime('%Y-%m-%d')\n",
        "    # calculation_end_date_for_others are for trailing and cumulative returns\n",
        "    calculation_end_date_for_others_str=calculation_end_date_month_boundary_date_str\n",
        "\n",
        "    '''  Handling Feb 29 of leap years.\n",
        "    For leap years, to simiplify the calculation,  Feb 28 will be used to replace Feb 29 for\n",
        "    for calculating returns.\n",
        "    Therefore, if calculation_end_date_for_others_str is Feb 29, then replace 29 to 28 of calculation_end_date_for_others_str\n",
        "    '''\n",
        "    leap_year=False\n",
        "    if (\n",
        "        calculation_end_date_for_others_str[-5:] == '02-29'\n",
        "    ):\n",
        "        calculation_end_date_for_others_str = calculation_end_date_for_others_str[:-2] + '28'\n",
        "        leap_year=True\n",
        "    #................End\n",
        "\n",
        "    # Check whether numebr 0, 1, 2, .. is selected for using a default ticker list\n",
        "    integer_value=str_to_integer(tickers[0])\n",
        "    if (integer_value >= 0 and integer_value <len(tickers_lists)):\n",
        "        tickers=tickers_lists[integer_value]\n",
        "\n",
        "    # if no tickers were set, display help information\n",
        "    if len(tickers)==0:\n",
        "        return help_info_str\n",
        "    tmp_ticker_list=tickers\n",
        "    tickers = [ticker.lower() for ticker in tmp_ticker_list]\n",
        "\n",
        "    #*********************************************************************************\n",
        "    # Calculating year-end prices, Annual, Trailing, Cumulative, and CAGR returns & generating html for display\n",
        "    #\n",
        "    # list of year-end prices of stocks\n",
        "    output_string1= f\"\\nAdj Close Prices ($)\\n\"\n",
        "    data_adj_close_year_end_df, data_adj_close_df = stock_prices_df(tickers, calculation_end_date_str)\n",
        "    output_dataframe= data_adj_close_year_end_df\n",
        "    output_html1=output_string1 + output_dataframe.to_html()\n",
        "\n",
        "    #  Annual Total Return\n",
        "    output_string = f\"\\nAnnual Total Return (%) as {calculation_end_date_str}\\n\"\n",
        "    #output_dataframe = get_annual_returns_tickers_year_boundary_df(tickers, calculation_end_date_str)\n",
        "    output_dataframe = get_annual_returns_year_end_df(data_adj_close_year_end_df, calculation_end_date_str)\n",
        "    output_dataframe = output_dataframe.dropna(how='all')\n",
        "    output_dataframe = output_dataframe.round(4)*100\n",
        "    #output_dataframe.index=output_dataframe.index.date\n",
        "    # Assuming your DataFrame is named output_dataframe\n",
        "    last_date = output_dataframe.index[-1]\n",
        "    output_dataframe = output_dataframe.rename(index={last_date: calculation_end_date_str})\n",
        "    # Convert the DataFrame to HTML, Combine the expected string outputs\n",
        "    output_html2 = output_string + output_dataframe.to_html()\n",
        "    print(\"\\ndebug2  output_dataframe\\n\", output_dataframe)\n",
        "\n",
        "    # annual_returns  - at any given day, for calculating trailing and cumulative returns, not to be displayed\n",
        "    #annual_returns_dataframe=get_annual_returns_tickers_df(tickers, calculation_end_date_for_others_str)\n",
        "    annual_returns_dataframe=get_annual_returns_anyday_df(data_adj_close_df, calculation_end_date_str)\n",
        "    print(\"\\ndebug2-T  annual_returns_dataframe\\n\", annual_returns_dataframe)\n",
        "\n",
        "    # Trailing Return\n",
        "    if (leap_year):\n",
        "        output_string3 = f\"\\nTrailing Total Return (%) as {calculation_end_date_for_others_str} (leap year: Feb 29 replaced by Feb 28 for approximation)\\n\"\n",
        "    else:\n",
        "        output_string3 = f\"\\nTrailing Total Return (%) as {calculation_end_date_for_others_str}\\n\"\n",
        "    output_dataframe3=get_trailing_return_all(annual_returns_dataframe)\n",
        "    output_dataframe3 = output_dataframe3.dropna(how='all')\n",
        "    # Insert an empty to align the ticker symbols with annual return display\n",
        "    output_dataframe3.insert(0, \"--------\", \"      \")\n",
        "    output_dataframe3.index.name=\"years\"\n",
        "    output_html3=output_string3 + output_dataframe3.to_html()\n",
        "    #print(\"\\ndebug3\\n\", output_string3, output_dataframe3)\n",
        "    # Cumulative Return\n",
        "    output_string4 = f\"\\nCumulative Return (%) as {calculation_end_date_for_others_str}\\n\"\n",
        "    cumulative_return_all_dataframe=get_cumulative_return_all(annual_returns_dataframe)\n",
        "    cumulative_return_all_dataframe = cumulative_return_all_dataframe.dropna(how='all')\n",
        "    output_dataframe4=cumulative_return_all_dataframe.round(4)*100\n",
        "    output_dataframe4.index.name=\"years\"\n",
        "    output_html4=output_string4 + output_dataframe4.to_html()\n",
        "\n",
        "    # CAGR Return\n",
        "    output_string5 = f\"\\nCompound Annual Growth Rate (CAGR) (%) as {calculation_end_date_for_others_str}\\n\"\n",
        "    output_dataframe5=get_cagr_return_all (cumulative_return_all_dataframe)\n",
        "    output_dataframe5=output_dataframe5.round(4)*100\n",
        "    output_html5=output_string5 + output_dataframe5.to_html()\n",
        "    output_html = output_html1 + output_html2 + output_html3 + output_html4\n",
        "    return  output_html\n",
        "\n",
        "# Gradio Web interface\n",
        "with gr.Blocks() as web_block:\n",
        "\n",
        "    chatbot = gr.Chatbot(height=\"500px\")\n",
        "    # Create a row element for the Textbox and Clear button\n",
        "    with gr.Row():\n",
        "        #msg = gr.Textbox(label=\"stock tickers input\", scale=2, min_width=380)\n",
        "        msg = gr.Textbox(show_label=False, scale=2, min_width=380)\n",
        "        clear = gr.ClearButton([msg, chatbot], scale=0, min_width=50)\n",
        "\n",
        "    def respond(message, chat_history):\n",
        "        bot_message = calculation_response(message)\n",
        "        chat_history.append((message, bot_message))\n",
        "        return \"\", chat_history\n",
        "\n",
        "    msg.submit(respond, # function\n",
        "     [msg, chatbot],  # inputs of the function\n",
        "     [msg, chatbot]   # outputs of the function\n",
        "               )\n",
        "web_block.launch()\n",
        "#web_block.launch(debug=True)\n",
        "\n",
        "# test cases:\n",
        "# calculation_response(\"4\")\n",
        "#calculation_response(\"SPY\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Q2SHw-XtGon"
      },
      "source": [
        "# Example 8 = Example 7 improvement- annualy for arbitrary start date (multiple stocks) annual,  trailing, cumumlative, and CAGR  returns (not neccesry only for calender year boundary )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yMpT8mPFyfIr",
        "outputId": "7a47d6b6-3a03-45fe-c808-a0bc81b4666e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://2c3cd8100964a19576.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://2c3cd8100964a19576.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "Example 8 for using yfinance\n",
        "\n",
        "Calculate annual, trailing, cumumlative, and CAGR returns for multiple stocks.\n",
        "* The start date can be an arbitrary date.  The default is the current date.\n",
        "* annual return is displayed from the default current day, or an arbitrary given\n",
        "  day (except for Feb 29 for leap year)\n",
        "  For leap years, use Feb 28 to replace Feb 29 as simplification & approximation\n",
        "* trailing, cumumlative returns are currently displayed from the month boundary (last day of Month)\n",
        "  prior to the given date.\n",
        "* However, trailing, cumumlative returns can be displayed\n",
        "  from any date, which can be not at the month boundary (last day of Month),\n",
        "  by minor change of setting calculation_end_date_for_others_str = calculation_end_date_str.\n",
        "  prior to the given date in the function \"calculation_response(message, history)\"\n",
        "\n",
        "Author: Gang Luo\n",
        "'''\n",
        "script_version = '(2024-03-02.1)'\n",
        "import gradio as gr\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import pytz\n",
        "#==============================================================================\n",
        "\n",
        "print_yearly_total_return = True\n",
        "num_years_calculation=52   # total years for calculation\n",
        "\n",
        "# Define a list of years to calculate the trailing returns, cumulative returns, and so on\n",
        "# remove the row of current year row since it is not a full year.\n",
        "years_list = [1, 2, 3, 5, 10, 15, 20, 25, 30, 40, 50, 60]\n",
        "\n",
        "# Set the stock tickers list\n",
        "tickers_lists = [[\"qqq\",\"hxq.to\",\"spy\", \"vfv.to\",\"xiu.to\", \"xbb.to\",\"xcb.to\",\"xhb.to\"], #0  checking ETF\n",
        "    [\"qqq\",\"spy\", \"vfv.to\", \"vgg.to\", \"zlu.to\", \"xiu.to\", \"vdy.to\", \"xfn.to\", \"ry.to\", \"td.to\", \"na.to\",\n",
        "      \"slf.to\", \"gwo.to\", \"bce.to\", \"t.to\", \"rci-b.to\", \"enb.to\", \"trp.to\", \"zlb.to\", \"cp.to\"], #1 main monitoring list\n",
        "    [\"qqq\",\"spy\",\"vfv.to\", \"xiu.to\", \"zeb.to\", \"xfn.to\", \"na.to\",\"ry.to\", \"bmo.to\",\"bns.to\", \"td.to\", \"cm.to\", \"cwb.to\",\n",
        "      \"slf.to\", \"gwo.to\", \"bce.to\", \"t.to\", \"rci-b.to\", \"enb.to\", \"trp.to\", \"xdv.to\",\"cdz.to\",\"vdy.to\", \"xdiv.to\"],  #2   financial  ETF & stocks\n",
        "    [\"^ndx\",\"qqq\",\"^GSPC\",\"spy\", \"vfv.to\", \"vgg.to\",\"zlu.to\",\"msft\",\"AAPL\",\"goog\",\"AMZN\",\"NVDA\",\"meta\",\"tsla\",\"BRK-A\",\"shop.to\",\"hxq.to\"],   #3  US mega stocks + risky shopfy\n",
        "    [\"^DJI\",\"dia\",\"^GSPC\",\"spy\",\"voo\",\"ivv\", \"tpu-u.to\",\"vfv.to\", \"zsp.to\",\"hxs.to\",\"tpu.to\",\"xus.to\", \"xsp.to\",\n",
        "      \"^IXIC\",\"^ndx\", \"qqq\",\"hxq.to\",\"^GSPTSE\",\"xic.to\",\"xiu.to\", \"HXT.TO\", \"TTP.TO\",\"ZCN.TO\", \"xfn.to\", \"xit.to\"], #4   indexes and index ETFs\n",
        "    [\"dia\",\"^DJI\",\"^GSPC\",\"spy\",\"vfv.to\", \"zsp.to\",\"hxs.to\",\"xus.to\", \"xsp.to\",\n",
        "      \"^IXIC\",\"qqq\",\"hxq.to\",\"^GSPTSE\",\"xic.to\",\"xiu.to\", \"HXT.TO\", \"xfn.to\"], #5   indexes and typical index ETFs\n",
        "    [\"^IXIC\",\"^ndx\",\"ONEQ\",\"CIBR\",\"QQJG\", \"qqq\", \"tqqq\", \"spy\", \"vfv.to\", \"HXQ.to\", \"ZQQ.to\", \"XQQ.to\", \"QQC.to\", \"ZNQ.TO\",\n",
        "         \"xiu.to\", \"xit.to\"],  #6   Nasdaq ETF and TSX IT ETF\n",
        "    [\"qqq\",\"tqqq\",\"sqqq\", \"QLD\", \"spy\", \"spxu\", \"upro\", \"sso\", \"spxl\",\"tecl\"], #7 leveraged ETFs\n",
        "    [\"^IXIC\",\"^DJI\",\"^GSPC\",\"^GSPTSE\"] #8 testing\n",
        "]\n",
        "\n",
        "#==============================================================================\n",
        "# Part 1: fetch retrieve yearly total returns by yfinance & display\n",
        "# Function to fetch data from yfinance and extract yearly total returns#\n",
        "# annual return calculation can start at any given day\n",
        "def get_annual_returns_df(ticker, calculation_end_date_str):\n",
        "    # Get the historical data for the given ticker\n",
        "    stock = yf.Ticker(ticker)\n",
        "    calculation_end_date=pd.to_datetime(calculation_end_date_str).tz_localize('America/New_York')\n",
        "    try:\n",
        "        '''\n",
        "        'try' statement for handlingy the exception error of stock.history that a ticker is not yet at stock market,\n",
        "        For example, \"shop.to\" is not there in 2012\n",
        "        '''\n",
        "        stock_history=stock.history(period=\"max\")[\"Close\"]\n",
        "        '''\n",
        "        Between the start and end days in stock_history variable, there are some missing days where there are no corresponding rows.\n",
        "        Add rows of  missing  days such that the values of column \"Close\" are set to be the value of the closest earlier day's\n",
        "        value, by using date_range to create full range without any missing date.\n",
        "        '''\n",
        "        # Create a DataFrame with a complete date range\n",
        "        date_range = pd.date_range(start=stock_history.index.min(), end=stock_history.index.max(), freq='D')\n",
        "        complete_stock_history = pd.DataFrame(index=date_range)\n",
        "        # Merge the complete DataFrame with the original stock_history\n",
        "        complete_stock_history = complete_stock_history.merge(stock_history, how='left', left_index=True, right_index=True)\n",
        "        complete_stock_history['Close'] = complete_stock_history['Close'].ffill()  # fill the newy added rows with previous day value\n",
        "        '''\n",
        "        Filter out the rows that matches the month and date of calculation_end_date, which are the ends of\n",
        "        annual periods from the calculation_end_date.\n",
        "        '''\n",
        "        # Filter out rows with dates newer than calculation_end_date\n",
        "        filtered_stock_history = complete_stock_history[complete_stock_history.index <= calculation_end_date]\n",
        "        #print(filtered_stock_history)\n",
        "        target_month=filtered_stock_history.index.max().month\n",
        "        target_day=filtered_stock_history.index.max().day\n",
        "        #print(\"target_month\", target_month, \"target_day\",target_day, \"start_year\", filtered_stock_history.index.max().year)\n",
        "        annual_returns = filtered_stock_history[(filtered_stock_history.index.month == target_month)\n",
        "           & (filtered_stock_history.index.day ==target_day)]\n",
        "        annual_returns_percent = annual_returns.pct_change().dropna()\n",
        "    except:\n",
        "        return  pd.DataFrame()\n",
        "    else:\n",
        "        annual_returns_df = pd.DataFrame(annual_returns_percent, columns=['Close'])\n",
        "        annual_returns_df.rename(columns={'Close': ticker}, inplace=True)\n",
        "        return annual_returns_df\n",
        "\n",
        "# Function to fetch data from yfinance and extract yearly total returns\n",
        "# annual return calculation starts at only yaer end boundary, i.e, Dec 31,\n",
        "# by resample('A')\n",
        "def get_annual_returns_year_boundary_df(ticker, calculation_end_date_str):\n",
        "    # Get the historical data for the given ticker\n",
        "    stock = yf.Ticker(ticker)\n",
        "    calculation_end_date = datetime.strptime(calculation_end_date_str, \"%Y-%m-%d\")\n",
        "    calculation_start_date_str = (calculation_end_date\n",
        "                - timedelta(days=num_years_calculation * 365)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    try:\n",
        "        '''\n",
        "        1.  'try' statement for handlingy the exception error of stock.history that a ticker is not yet at stock market,\n",
        "             For example, \"shop.to\" is not there in 2012\n",
        "        2. The row with the latest day from .history(.., end='end_day_date') is the day prior to end_day_date.  Therefore,\n",
        "           let end=the expected end day plus one day.\n",
        "        '''\n",
        "        calculation_end_date_plus_1day_str =  (calculation_end_date + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
        "        annual_returns_history=stock.history(start=calculation_start_date_str,end=calculation_end_date_plus_1day_str)[\"Close\"]\n",
        "\n",
        "        #print(\"debug get_annual_returns_df \", ticker, annual_returns_history)\n",
        "        # For 'A', 'Y', see https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases\n",
        "        ffilled_history=annual_returns = annual_returns_history.resample('A').ffill()\n",
        "        #print(ffilled_history)\n",
        "        annual_returns = ffilled_history.pct_change().dropna()\n",
        "        #annual_returns = annual_returns_history.resample('A').ffill().pct_change().dropna()\n",
        "        #print(\"debug get_annual_returns_df after resample()\", ticker, calculation_end_date, \"\\n\", annual_returns)\n",
        "    except:\n",
        "        return  pd.DataFrame()\n",
        "    else:\n",
        "        annual_returns_df = pd.DataFrame(annual_returns, columns=['Close'])\n",
        "        annual_returns_df.rename(columns={'Close': ticker}, inplace=True)\n",
        "        return annual_returns_df\n",
        "\n",
        "#----------------------------------------------------------------------------------\n",
        "# handling a list of tickers by calling the functions (either get_annual_returns_df\n",
        "# get_annual_returns_year_boundary_df) that handle single tickers\n",
        "def get_annual_returns_tickers_common_df(tickers, calculation_end_date_str, annual_returns_func_df):\n",
        "    # Create an empty DataFrame to store all tickers' total returns\n",
        "    all_tickers_returns_df = pd.DataFrame()\n",
        "\n",
        "    # Loop through each ticker in the list\n",
        "    for ticker in tickers:\n",
        "        ticker_returns_df = annual_returns_func_df(ticker, calculation_end_date_str)\n",
        "        if not ticker_returns_df.empty:\n",
        "            if all_tickers_returns_df.empty:\n",
        "                all_tickers_returns_df = ticker_returns_df\n",
        "            else:\n",
        "                '''\n",
        "                When running in  huggingface, pd.concat changed the index order of ticker_returns_df\n",
        "                when ticker_returns_df has more rows than all_tickers_returns_df. However, it is ok\n",
        "                running in colab.  Therefore, use pd.merge to replace pd.concat.\n",
        "                all_tickers_returns_df = pd.concat([all_tickers_returns_df, ticker_returns_df],axis=1,join='outer')  # Concatenate DataFrames\n",
        "                all_tickers_returns_df.sort_index() # index may be changed when running in huggingface\n",
        "                '''\n",
        "                all_tickers_returns_df = pd.merge(all_tickers_returns_df, ticker_returns_df,\n",
        "                        left_index=True, right_index=True, how='outer')\n",
        "        else:\n",
        "            # New column with NaN values\n",
        "            new_column_name = ticker\n",
        "            new_column_values = [None] * len(all_tickers_returns_df)\n",
        "            new_column = pd.DataFrame({new_column_name: new_column_values}, index=all_tickers_returns_df.index)\n",
        "            # Concatenate the new column to the original DataFrame\n",
        "            all_tickers_returns_df = pd.concat([all_tickers_returns_df, new_column], axis=1)\n",
        "    #return date_label_conversion_strip_time(all_tickers_returns_df, calculation_end_date_str)\n",
        "    return all_tickers_returns_df\n",
        "\n",
        "def get_annual_returns_tickers_df(tickers, calculation_end_date_str):\n",
        "    return get_annual_returns_tickers_common_df(tickers, calculation_end_date_str,\n",
        "                                                get_annual_returns_df)\n",
        "\n",
        "def get_annual_returns_tickers_year_boundary_df(tickers, calculation_end_date_str):\n",
        "    return get_annual_returns_tickers_common_df(tickers, calculation_end_date_str,\n",
        "                                                get_annual_returns_year_boundary_df)\n",
        "\n",
        "#==============================================================================\n",
        "# Part 2: calculate the annualized trailing total return from the data generated in step 1 & display\n",
        "# Define a function to calculate the annualized trailing total return for a given number of years\n",
        "def get_trailing_return(ticker, data, years):\n",
        "    # Get the total return values for the last n years\n",
        "    trailing_data = data[ticker].tail(years)\n",
        "    # Check if there are empty values within years\n",
        "    if trailing_data.isna().any():\n",
        "        return np.nan\n",
        "    # Check if there are valid total return values for all years\n",
        "    if len(trailing_data) == years:\n",
        "        # Convert the percentage strings to numeric values\n",
        "        trailing_data = trailing_data.astype(str).str.replace('%', '').astype(float)\n",
        "        \"\"\" Calculate the annualized trailing total return using the formula from Investopedia[^1^][1]:\n",
        "            Annualized Return = [(1 + r1) * (1 + r2) * ... * (1 + rn)]^(1/n) - 1\n",
        "            Where r1, r2, ..., rn are the total return values for each year                    \"\"\"\n",
        "        annualized_trailing_return = (trailing_data + 1).prod() ** (1 / years) - 1\n",
        "\n",
        "        # Format the result as a percentage with two decimal places\n",
        "        annualized_trailing_return = annualized_trailing_return * 100\n",
        "        annualized_trailing_return = annualized_trailing_return.round(2)\n",
        "        return annualized_trailing_return\n",
        "    else:\n",
        "        return np.nan\n",
        "\n",
        "# Define a function to Loop through the list and print the trailing returns for each num_years\n",
        "def get_trailing_return_column(ticker, annual_returns_df):\n",
        "    trailing_return_column = {}\n",
        "    for num_years in years_list:\n",
        "        # Check if the ticker data is available in all_tickers_returns_df\n",
        "        if ticker in annual_returns_df.columns:\n",
        "            # using data from step 1, avoiding get_annual_returns_df(ticker) for less traffic from yahoo server\n",
        "            data = annual_returns_df[[ticker]]\n",
        "            trailing_return = get_trailing_return(ticker, data, num_years)\n",
        "            trailing_return_column[f\"{num_years}-Year\"] = trailing_return\n",
        "        else:\n",
        "            print(f\"Data not available for {ticker}. Skipping.\")\n",
        "            trailing_return_column[f\"{num_years}-Year\"] = np.nan\n",
        "    return trailing_return_column\n",
        "\n",
        "# Create an empty DataFrame to store all tickers' trailing returns\n",
        "def get_trailing_return_all(tickers, annual_returns_df):\n",
        "    all_tickers_trailing_returns_df = pd.DataFrame(index=years_list)\n",
        "\n",
        "    # Loop through each ticker in the list\n",
        "    for ticker in tickers:\n",
        "        trailing_returns = get_trailing_return_column(ticker, annual_returns_df)\n",
        "        # Add the trailing returns to the DataFrame\n",
        "        all_tickers_trailing_returns_df[ticker] = pd.Series(trailing_returns).values\n",
        "    all_tickers_trailing_returns_df.columns = map(str.lower, all_tickers_trailing_returns_df.columns)\n",
        "    return all_tickers_trailing_returns_df\n",
        "\n",
        "#==============================================================================\n",
        "# Part 3: calculate the cumulative return from the data (all_tickers_returns_df) generated in part 1 & display\n",
        "#  Define a function to calculate the cumulative return for a given number of years from a ticker\n",
        "def get_cumulative_return(ticker, data, years):\n",
        "    # Calculate the cumulative return\n",
        "    cumulative_return = (1 + data[ticker]).rolling(window=years).apply(lambda x: x.prod(), raw=True) - 1\n",
        "    return cumulative_return\n",
        "\n",
        "# Define a function to Loop through the list and return the cumulative returns for each num_years\n",
        "def get_cumulative_return_column(ticker, annual_returns_df):\n",
        "    cumulative_returns = {}\n",
        "    for years in years_list:\n",
        "        # Calculate the cumulative return for the given number of years\n",
        "        cumulative_return = get_cumulative_return(ticker, annual_returns_df, years)\n",
        "        # Get the last value, which is the cumulative return up to the current year\n",
        "        cumulative_returns[years] = cumulative_return.iloc[-1]\n",
        "    return cumulative_returns\n",
        "\n",
        "def get_cumulative_return_all(tickers, annual_returns_df):\n",
        "    # Create an empty DataFrame with years_list as the index for cumulative  returns\n",
        "    all_tickers_cumulative_returns_df = pd.DataFrame(index=years_list)\n",
        "    # Loop through each ticker in the list\n",
        "    for ticker in tickers:\n",
        "        cumulative_returns = get_cumulative_return_column(ticker, annual_returns_df)\n",
        "        # Add the trailing returns to the DataFrame\n",
        "        all_tickers_cumulative_returns_df[ticker] = pd.Series(cumulative_returns).values\n",
        "    all_tickers_cumulative_returns_df.columns = map(str.lower, all_tickers_cumulative_returns_df.columns)\n",
        "    return all_tickers_cumulative_returns_df\n",
        "\n",
        "#==============================================================================\n",
        "# Part 4: calculate the  CAGR (Compound Annual Growth Rate) from the data\n",
        "# in all_tickers_cumulative_returns_df generated earlier & display\n",
        "# Define a function to calculate the CAGR from the cumulative value and the years\n",
        "def calculate_cagr(value, years):\n",
        "    # Otherwise, calculate the CAGR using the formula\n",
        "    cagr = (value + 1) ** (1 / np.array(years)) - 1\n",
        "    #print(\"debug-cagr\\n\", cagr, \"end\")\n",
        "    return cagr\n",
        "\n",
        "# Define a function to format the Float64Index values into percentage strings\n",
        "def format_to_percentage(value):\n",
        "    # If any element in the value array is not null, format it as a percentage string with two decimal places\n",
        "    if np.any(pd.notnull(value)):\n",
        "        return f\"{value:.2f}%\"\n",
        "    # Otherwise, return None\n",
        "    return None\n",
        "\n",
        "def get_cagr_return_all(all_tickers_cumulative_returns_df):\n",
        "    # Apply the calculate_cagr function to each column of the DataFrame\n",
        "    all_tickers_cagrs_df = all_tickers_cumulative_returns_df.apply(lambda x: calculate_cagr(x, x.index), axis=0)\n",
        "    return all_tickers_cagrs_df\n",
        "\n",
        "#==============================================================================\n",
        "# Part 5: utility functions\n",
        "# get the last trading day of S&P 500 in string format\n",
        "def get_last_trading_day():\n",
        "    # Get today's date, use .strftime(\"%Y-%m-%d\") to convert to a string\n",
        "    today_date_str=datetime.now(pytz.timezone('America/New_York')).date().strftime(\"%Y-%m-%d\")\n",
        "    stock = yf.Ticker(\"^GSPC\") # S&P 500 (^GSPC) ticker\n",
        "    #  search and see yfinance_BUG_1 NOTE in this file\n",
        "    history_df=stock.history(period=\"max\", end=today_date_str)[\"Close\"]\n",
        "    last_trading_day_str = history_df.index.max().date().strftime(\"%Y-%m-%d\")\n",
        "    return last_trading_day_str\n",
        "\n",
        "def str_to_integer(integer_str):\n",
        "    try:\n",
        "        integer_number = int(integer_str)\n",
        "        return integer_number\n",
        "    except ValueError:\n",
        "        return -1\n",
        "\n",
        "# validate the date string\n",
        "def is_valid_date(date_string):\n",
        "    try:\n",
        "        # Attempt to parse the date string\n",
        "        datetime.strptime(date_string, \"%Y-%m-%d\")\n",
        "        return True\n",
        "    except ValueError:\n",
        "        # Raised when the date string is not in the expected format\n",
        "        return False\n",
        "\n",
        "def date_label_conversion_strip_time(all_tickers_returns_df, calculation_end_date_str):\n",
        "    all_tickers_returns_df.index=all_tickers_returns_df.index.date\n",
        "    all_tickers_returns_df.index.name='date'\n",
        "    # print(\"debug get_annual_returns_tickers_df\", all_tickers_returns_df)\n",
        "    # Convert calculation_end_date_str to a datetime object, replace the index's mon/day portion of date\n",
        "    end_date_datetime_obj = datetime.strptime(calculation_end_date_str, \"%Y-%m-%d\")\n",
        "    all_tickers_returns_df.index = all_tickers_returns_df.index.map(\n",
        "      lambda x: x.replace(month=end_date_datetime_obj.month,\n",
        "      day=end_date_datetime_obj.day))\n",
        "    return all_tickers_returns_df\n",
        "\n",
        "#==============================================================================\n",
        "# Part 6:\n",
        "# single ticker's Prices, Returns,Dividends, good for verifying whether \"Adj Close\" is correct.\n",
        "'''\n",
        "    Calculate and display: yearly dividendSum, 'Close' & 'Adj Close' prices,\n",
        "    Return(by 'Close' price), total return(by 'Adj Close' price),\n",
        "    CalReturn(total return by 'Close' price and \"dividendSum).\n",
        "    Note: CalReturn from  is expected to be nearly same as  total return,\n",
        "           when the 'Adj Close' price is correct.\n",
        "'''\n",
        "def get_yearly_single_stock_data(ticker):\n",
        "    stock = yf.Ticker(ticker)\n",
        "    #-------- mainly for downloading 'Dividends'\n",
        "    history = stock.history(period=\"max\")\n",
        "    dividend_history=history['Dividends']\n",
        "    dividend_history.index=dividend_history.index.date\n",
        "\n",
        "    #-------- mainly for downloading 'Close','Adj Close'\n",
        "    dld_history=yf.download(ticker, period=\"max\")\n",
        "    dld_history=dld_history[['Close','Adj Close']]\n",
        "    dld_history.rename(columns={'Adj Close': 'AdjClose'}, inplace=True)\n",
        "    date_range = pd.date_range(start=dld_history.index.min(), end=dld_history.index.max(), freq='D')\n",
        "    complete_history = pd.DataFrame(index=date_range)\n",
        "\n",
        "    # Merge the complete DataFrame with the original stock_history\n",
        "    complete_history = complete_history.merge(dld_history, how='left', left_index=True, right_index=True)\n",
        "    complete_history[['Close','AdjClose']] = complete_history[['Close','AdjClose']].ffill().round(3)\n",
        "\n",
        "    # Merge dividend into complete_history\n",
        "    complete_history = complete_history.merge(dividend_history, how='left', left_index=True, right_index=True)\n",
        "    # replace all NaN values in the 'Dividends' column with 0.0\n",
        "    complete_history['Dividends'] = complete_history['Dividends'].fillna(0.0).round(3)\n",
        "\n",
        "    complete_history['Year']=complete_history.index.year\n",
        "    complete_history['Date']=complete_history.index\n",
        "    yearly_data = complete_history.groupby('Year').agg({'Date': 'last', 'Close': 'last', 'AdjClose': 'last','Dividends': 'sum'})\n",
        "    yearly_data.rename(columns={'Dividends': 'DivSum'}, inplace=True)\n",
        "\n",
        "    # calculating 'Return' and 'TotalReturn'\n",
        "    yearly_data['DivRatio']=yearly_data['DivSum'] / yearly_data['Close']\n",
        "    yearly_data['Return']=yearly_data['Close'].pct_change()\n",
        "    yearly_data['TotalReturn']=yearly_data['AdjClose'].pct_change()\n",
        "\n",
        "    '''\n",
        "    The CalReturn column is the yearly total return calculated from un-adjusted \"Close\" prices and yearly \"dividend sum\",\n",
        "    which is expected to be equal to the total return that is calculated from \"AdjClose\" prices\n",
        "    '''\n",
        "    yearly_data['CalReturn'] = (yearly_data['Close'] + yearly_data['DivSum']) / yearly_data['Close'].shift(1) - 1\n",
        "    # set the display format\n",
        "    yearly_data[['DivRatio','Return','TotalReturn','CalReturn']] = yearly_data[['DivRatio','Return','TotalReturn','CalReturn']].mul(100).round(2)\n",
        "    '''\n",
        "    #yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']] = yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']].applymap(\"{:.2f}%\".format)\n",
        "    yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']]= \\\n",
        "     yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']].applymap(lambda x: f\"{x:.2f}%\" if not pd.isna(x) else \"NaN\")\n",
        "    '''\n",
        "    # Use .applymap() and lambda to format the values as percentage strings only if they are not NaN\n",
        "    yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']]= \\\n",
        "         yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']].applymap(lambda x: f\"{x:.2f}%\" if not pd.isna(x) else x)\n",
        "\n",
        "    # 'Date' column is no longer required\n",
        "    yearly_data.drop('Date', axis=1, inplace=True)\n",
        "    return yearly_data\n",
        "\n",
        "#==============================================================================\n",
        "# Part 7:\n",
        "# print the year-end adjusted close prices of a list of stockes\n",
        "def stock_prices_df(tickers_list, end_date_str):\n",
        "    tickers_list_upper = [ticker.upper() for ticker in tickers_list]\n",
        "    tickers_str = \", \".join(tickers_list_upper)\n",
        "    # Download the historical data\n",
        "    data = yf.download(tickers_str, period=\"max\")\n",
        "    data_adj_close = data['Adj Close']\n",
        "\n",
        "    # Filter out rows with dates newer than calculation_end_date\n",
        "    data_adj_close = data_adj_close[data_adj_close.index <= end_date_str]\n",
        "\n",
        "    # Rearrange columns based on the order in tickers_list_upper\n",
        "    if len(tickers_list)>1:\n",
        "        data_adj_close = data_adj_close.reindex(columns=tickers_list_upper)\n",
        "\n",
        "    data_adj_close = data_adj_close.resample('A').ffill().round(2)\n",
        "    data_adj_close.index=data_adj_close.index.date\n",
        "    last_date = data_adj_close.index[-1]\n",
        "    data_adj_close = data_adj_close.rename(index={last_date: end_date_str})\n",
        "    data_adj_close_df = pd.DataFrame(data_adj_close)\n",
        "    data_adj_close_df.columns = map(str.lower, data_adj_close_df.columns)\n",
        "    return data_adj_close_df\n",
        "\n",
        "#==============================================================================\n",
        "# Part 8: gradio handling - Input command handling and display in web page\n",
        "\n",
        "help_info_str=\"Input Formats:\\n  \\\n",
        "            1. ticker list....................Example:  spy vfv.to xiu.to xic.to xfn.to ry.to \\n \\\n",
        "            2. One of default ticker list, a number between 1 and 7....Example:   0, or 1, ...,7 \\n \\\n",
        "            3. CalculationEndDate as prefix.  Example:   2020-12-31 2 \\n \\\n",
        "            .........................................2020-12-31 spy vfv.to xiu.to xic.to xfn.to ry.to \\n \\\n",
        "            4. single ticker: Dividend/Close/AdjClose/Return/TotalReturn/CalReturn(by Close/Dividends).  @1 spy \\n \\\n",
        "            note: daily adjusted close data are from Yahoo Finance. \"\n",
        "\n",
        "# Main Handling Process\n",
        "def calculation_response(message):\n",
        "    # if there is no input, display help information\n",
        "    if message==\"\":\n",
        "        return help_info_str\n",
        "\n",
        "    tickers=message.split()\n",
        "\n",
        "    # ******************************************************************************\n",
        "    #  processing web input parameters\n",
        "    #  set calculation_end_date_str, and tickers\n",
        "\n",
        "    #---------------------------------------------------------\n",
        "    # single stock ticker - detailed information\n",
        "    if (tickers[0] == \"@1\"):\n",
        "        tickers.pop(0) # remove the first string which is \"@1\"\n",
        "        if len(tickers)==0:\n",
        "            ticker = 'spy' # default ticker = spy\n",
        "        else:\n",
        "            ticker=tickers[0]\n",
        "        output_string=f\"\\n {ticker}\\n\"\n",
        "        output_dataframe0=get_yearly_single_stock_data(ticker)\n",
        "        output_html=output_string + output_dataframe0.to_html()\n",
        "        return output_html\n",
        "\n",
        "    #----------------------------------------------------------\n",
        "    # Get today's date, use .strftime(\"%Y-%m-%d\") to convert to a string\n",
        "    #calculation_end_date_str=datetime.now(pytz.timezone('America/New_York')).date().strftime(\"%Y-%m-%d\")\n",
        "    calculation_end_date_str = get_last_trading_day()\n",
        "    # Check whether the first str is date for calculation end date\n",
        "    if is_valid_date(tickers[0]):\n",
        "        calculation_end_date_str = tickers[0] # reset calculation_end_date_str\n",
        "        tickers.pop(0) # remove the first string which is the date\n",
        "\n",
        "    #............ For display trailing and cumulative returns at month_boundary_date\n",
        "    # Assuming calculation_end_date_str contains the date string '2024-01-03'\n",
        "    calculation_end_date = datetime.strptime(calculation_end_date_str, '%Y-%m-%d')\n",
        "    # Calculate the first day of the current month\n",
        "    first_day_of_month = calculation_end_date.replace(day=1)\n",
        "    # Calculate the last day of the month\n",
        "    last_day_of_month = (calculation_end_date.replace(day=1) + timedelta(days=32)).replace(day=1) - timedelta(days=1)\n",
        "    # Calculate the last day of the previous month\n",
        "    last_day_of_previous_month = first_day_of_month - timedelta(days=1)\n",
        "    # Check if the original date is the last day of the month\n",
        "    if (calculation_end_date == last_day_of_month):\n",
        "        calculation_end_date_month_boundary_date_str=calculation_end_date_str\n",
        "    else:\n",
        "        calculation_end_date_month_boundary_date_str=last_day_of_previous_month.strftime('%Y-%m-%d')\n",
        "    # calculation_end_date_for_others are for trailing and cumulative returns\n",
        "    calculation_end_date_for_others_str=calculation_end_date_month_boundary_date_str\n",
        "\n",
        "    '''  Handling Feb 29 of leap years.\n",
        "    For leap years, to simiplify the calculation,  Feb 28 will be used to replace Feb 29 for\n",
        "    for calculating returns.\n",
        "    Therefore, if calculation_end_date_for_others_str is Feb 29, then replace 29 to 28 of calculation_end_date_for_others_str\n",
        "    '''\n",
        "    leap_year=False\n",
        "    if (\n",
        "        calculation_end_date_for_others_str[-5:] == '02-29'\n",
        "    ):\n",
        "        calculation_end_date_for_others_str = calculation_end_date_for_others_str[:-2] + '28'\n",
        "        leap_year=True\n",
        "    #................End\n",
        "\n",
        "    # Check whether numebr 0, 1, 2, .. is selected for using a default ticker list\n",
        "    integer_value=str_to_integer(tickers[0])\n",
        "    if (integer_value >= 0 and integer_value <len(tickers_lists)):\n",
        "        tickers=tickers_lists[integer_value]\n",
        "\n",
        "    # if no tickers were set, display help information\n",
        "    if len(tickers)==0:\n",
        "        return help_info_str\n",
        "\n",
        "    #*********************************************************************************\n",
        "    # Calculating year-end prices, Annual, Trailing, Cumulative, and CAGR returns & generating html for display\n",
        "    #\n",
        "    # list of year-end prices of stocks\n",
        "    output_string0= f\"\\nAdj Close Prices ($)\\n\"\n",
        "    output_dataframe= stock_prices_df(tickers, calculation_end_date_str)\n",
        "    output_html0=output_string0 + output_dataframe.to_html()\n",
        "    #  Annual Total Return\n",
        "    output_string = f\"\\nAnnual Total Return (%) as {calculation_end_date_str}\\n\"\n",
        "    output_dataframe = get_annual_returns_tickers_year_boundary_df(tickers, calculation_end_date_str)\n",
        "    output_dataframe = output_dataframe.dropna(how='all')\n",
        "    output_dataframe = output_dataframe.round(4)*100\n",
        "    output_dataframe.index=output_dataframe.index.date\n",
        "    # Assuming your DataFrame is named output_dataframe\n",
        "    last_date = output_dataframe.index[-1]\n",
        "    output_dataframe = output_dataframe.rename(index={last_date: calculation_end_date_str})\n",
        "    # Convert the DataFrame to HTML, Combine the expected string outputs\n",
        "    output_dataframe.columns = map(str.lower, output_dataframe.columns)\n",
        "    output_html1 = output_string + output_dataframe.to_html()\n",
        "\n",
        "    # annual_returns  - at any given day, for calculating trailing and cumulative returns, not to be displayed\n",
        "    annual_returns_dataframe=get_annual_returns_tickers_df(tickers, calculation_end_date_for_others_str)\n",
        "\n",
        "    # Trailing Return\n",
        "    if (leap_year):\n",
        "        output_string2 = f\"\\nTrailing Total Return (%) as {calculation_end_date_for_others_str} (leap year: Feb 29 replaced by Feb 28 for approximation)\\n\"\n",
        "    else:\n",
        "        output_string2 = f\"\\nTrailing Total Return (%) as {calculation_end_date_for_others_str}\\n\"\n",
        "    output_dataframe2=get_trailing_return_all(tickers, annual_returns_dataframe)\n",
        "    output_dataframe2 = output_dataframe2.dropna(how='all')\n",
        "    # Insert an empty to align the ticker symbols with annual return display\n",
        "    output_dataframe2.insert(0, \"--------\", \"      \")\n",
        "    output_dataframe2.index.name=\"years\"\n",
        "    output_html2=output_string2 + output_dataframe2.to_html()\n",
        "\n",
        "    # Cumulative Return\n",
        "    output_string3 = f\"\\nCumulative Return (%) as {calculation_end_date_for_others_str}\\n\"\n",
        "    cumulative_return_all_dataframe=get_cumulative_return_all(tickers, annual_returns_dataframe)\n",
        "    cumulative_return_all_dataframe = cumulative_return_all_dataframe.dropna(how='all')\n",
        "    output_dataframe3=cumulative_return_all_dataframe.round(4)*100\n",
        "    output_dataframe3.index.name=\"years\"\n",
        "    output_html3=output_string3 + output_dataframe3.to_html()\n",
        "\n",
        "    # CAGR Return\n",
        "    output_string4 = f\"\\nCompound Annual Growth Rate (CAGR) (%) as {calculation_end_date_for_others_str}\\n\"\n",
        "    output_dataframe4=get_cagr_return_all (cumulative_return_all_dataframe)\n",
        "    output_dataframe4=output_dataframe4.round(4)*100\n",
        "    output_html4=output_string4 + output_dataframe4.to_html()\n",
        "\n",
        "    #output_html = output_html1 + output_html2 + output_html3 + output_html4\n",
        "    output_html = output_html0 + output_html1 + output_html2 + output_html3\n",
        "    return  output_html\n",
        "\n",
        "# Gradio Web interface\n",
        "'''\n",
        "def ChatInterface_response(message, history):\n",
        "    output_html=calculation_response(message)\n",
        "    return output_html\n",
        "web_handling = gr.ChatInterface(ChatInterface_response)\n",
        "web_handling.launch(debug=False, share=False)\n",
        "'''\n",
        "with gr.Blocks() as web_block:\n",
        "    '''\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox()\n",
        "    clear = gr.ClearButton([msg, chatbot])\n",
        "    '''\n",
        "    chatbot = gr.Chatbot(height=\"500px\")\n",
        "    # Create a row element for the Textbox and Clear button\n",
        "    with gr.Row():\n",
        "        #msg = gr.Textbox(label=\"stock tickers input\", scale=2, min_width=380)\n",
        "        msg = gr.Textbox(show_label=False, scale=2, min_width=380)\n",
        "        clear = gr.ClearButton([msg, chatbot], scale=0, min_width=50)\n",
        "\n",
        "    def respond(message, chat_history):\n",
        "        bot_message = calculation_response(message)\n",
        "        chat_history.append((message, bot_message))\n",
        "        return \"\", chat_history\n",
        "\n",
        "    msg.submit(respond, # function\n",
        "     [msg, chatbot],  # inputs of the function\n",
        "     [msg, chatbot]   # outputs of the function\n",
        "               )\n",
        "web_block.launch()\n",
        "#web_block.launch(debug=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mh26Rmd1TIn"
      },
      "source": [
        "##  debug section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yg6uGYsk8FtI"
      },
      "outputs": [],
      "source": [
        "# debug section\n",
        "#calculation_response(\"0\", [])\n",
        "'''\n",
        "tickers=[\"spy\",\"vfv.to\"]\n",
        "calculation_end_date_str=\"2024-01-08\"\n",
        "calculation_end_date_month_boundary_date_str=\"2023-12-31\"\n",
        "output_dataframe = get_annual_returns_tickers_year_boundary_df(tickers, calculation_end_date_str)\n",
        "annual_returns_dataframe=get_annual_returns_tickers_df(tickers, calculation_end_date_month_boundary_date_str)\n",
        "#print(output_dataframe)\n",
        "print(annual_returns_dataframe)\n",
        "\n",
        "\n",
        "calculation_end_date_str= \"2012-01-02\"\n",
        "print(\"get_last_trading_day\", calculation_end_date_str)\n",
        "tickers = [\"spy\", \"vfv.to\", \"vgg.to\", \"goog\", \"msft\", \"meta\", \"tsla\",\"AMZN\", \"AAPL\", \"shop.to\"]\n",
        "output_string = f\"\\nAnnual Total Return (%) as {calculation_end_date}\\n\"\n",
        "annual_returns_dataframe=get_annual_returns_tickers_df(tickers, calculation_end_date_str)\n",
        "output_dataframe = annual_returns_dataframe.round(4)*100\n",
        "print(output_dataframe)\n",
        "\n",
        "help_info_str = \"\"\"Input Formats:\n",
        "| {0:30} | {1:30} |\n",
        "| {2:30} | {3:30} |\n",
        "| {4:30} | {5:30} |\"\"\".format(\n",
        "    \"1. ticker list.\", \"Example: spy vfv.to xiu.to xic.to xfn.to ry.to\",\n",
        "    \"2. One of default ticker list.\", \"Example: 0|1|...|5\",\n",
        "    \"3. CalculationEndDate as prefix.\", \"Example: 2020-12-31 2 or 2020-12-31 spy vfv.to xiu.to xic.to xfn.to ry.to\"\n",
        ")\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtBauhWaYM1w"
      },
      "source": [
        "## Backup Example 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "6vgXdUW4buBu",
        "outputId": "f0c4c36c-b591-4816-c9bf-f2e596f70449"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://227ecebb7068aebc31.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://227ecebb7068aebc31.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "Example 8 for using yfinance\n",
        "\n",
        "Calculate annual, trailing, cumumlative, and CAGR returns for multiple stocks.\n",
        "* The start date can be an arbitrary date.  The default is the current date.\n",
        "* annual return is displayed from the default current day, or an arbitrary given\n",
        "  day (except for Feb 29 for leap year)\n",
        "  For leap years, use Feb 28 to replace Feb 29 as simplification & approximation\n",
        "* trailing, cumumlative returns are currently displayed from the month boundary (last day of Month)\n",
        "  prior to the given date.\n",
        "* However, trailing, cumumlative returns can be displayed\n",
        "  from any date, which can be not at the month boundary (last day of Month),\n",
        "  by minor change of setting calculation_end_date_for_others_str = calculation_end_date_str.\n",
        "  prior to the given date in the function \"calculation_response(message, history)\"\n",
        "\n",
        "Author: Gang Luo\n",
        "'''\n",
        "script_version = '(2024-03-01.1)'\n",
        "import gradio as gr\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import pytz\n",
        "#==============================================================================\n",
        "\n",
        "print_yearly_total_return = True\n",
        "num_years_calculation=52   # total years for calculation\n",
        "\n",
        "# Define a list of years to calculate the trailing returns, cumulative returns, and so on\n",
        "# remove the row of current year row since it is not a full year.\n",
        "years_list = [1, 2, 3, 5, 10, 15, 20, 25, 30, 40, 50]\n",
        "\n",
        "# Set the stock tickers list\n",
        "tickers_lists = [[\"qqq\",\"hxq.to\",\"spy\", \"vfv.to\",\"xiu.to\", \"xbb.to\",\"xcb.to\",\"xhb.to\"], #0  checking ETF\n",
        "    [\"qqq\",\"spy\", \"vfv.to\", \"vgg.to\", \"zlu.to\", \"xiu.to\", \"vdy.to\", \"xfn.to\", \"ry.to\", \"td.to\", \"na.to\",\n",
        "      \"slf.to\", \"gwo.to\", \"bce.to\", \"t.to\", \"rci-b.to\", \"enb.to\", \"trp.to\", \"zlb.to\", \"cp.to\"], #1 main monitoring list\n",
        "    [\"qqq\",\"spy\",\"vfv.to\", \"xiu.to\", \"zeb.to\", \"xfn.to\", \"na.to\",\"ry.to\", \"bmo.to\",\"bns.to\", \"td.to\", \"cm.to\", \"cwb.to\",\n",
        "      \"slf.to\", \"gwo.to\", \"bce.to\", \"t.to\", \"rci-b.to\", \"enb.to\", \"trp.to\", \"xdv.to\",\"cdz.to\",\"vdy.to\", \"xdiv.to\"],  #2   financial  ETF & stocks\n",
        "    [\"^ndx\",\"qqq\",\"^GSPC\",\"spy\", \"vfv.to\", \"vgg.to\",\"zlu.to\",\"msft\",\"AAPL\",\"goog\",\"AMZN\",\"NVDA\",\"meta\",\"tsla\",\"BRK-A\",\"shop.to\",\"hxq.to\"],   #3  US mega stocks + risky shopfy\n",
        "    [\"^DJI\",\"dia\",\"^GSPC\",\"spy\",\"voo\",\"ivv\", \"tpu-u.to\",\"vfv.to\", \"zsp.to\",\"hxs.to\",\"tpu.to\",\"xus.to\", \"xsp.to\",\n",
        "      \"^IXIC\",\"^ndx\", \"qqq\",\"hxq.to\",\"^GSPTSE\",\"xic.to\",\"xiu.to\", \"HXT.TO\", \"TTP.TO\",\"ZCN.TO\", \"xfn.to\", \"xit.to\"], #4   indexes and index ETFs\n",
        "    [\"dia\",\"^DJI\",\"^GSPC\",\"spy\",\"vfv.to\", \"zsp.to\",\"hxs.to\",\"xus.to\", \"xsp.to\",\n",
        "      \"^IXIC\",\"qqq\",\"hxq.to\",\"^GSPTSE\",\"xic.to\",\"xiu.to\", \"HXT.TO\", \"xfn.to\"], #5   indexes and typical index ETFs\n",
        "    [\"^IXIC\",\"^ndx\",\"ONEQ\",\"CIBR\",\"QQJG\", \"qqq\", \"tqqq\", \"spy\", \"vfv.to\", \"HXQ.to\", \"ZQQ.to\", \"XQQ.to\", \"QQC.to\", \"ZNQ.TO\",\n",
        "         \"xiu.to\", \"xit.to\"],  #6   Nasdaq ETF and TSX IT ETF\n",
        "    [\"qqq\",\"tqqq\",\"sqqq\", \"QLD\", \"spy\", \"spxu\", \"upro\", \"sso\", \"spxl\",\"tecl\"], #7 leveraged ETFs\n",
        "    [\"^IXIC\",\"^DJI\",\"^GSPC\",\"^GSPTSE\"] #8 testing\n",
        "]\n",
        "\n",
        "#==============================================================================\n",
        "# Part 1: fetch retrieve yearly total returns by yfinance & display\n",
        "# Function to fetch data from yfinance and extract yearly total returns#\n",
        "# annual return calculation can start at any given day\n",
        "def get_annual_returns_df(ticker, calculation_end_date_str):\n",
        "    # Get the historical data for the given ticker\n",
        "    stock = yf.Ticker(ticker)\n",
        "    calculation_end_date=pd.to_datetime(calculation_end_date_str).tz_localize('America/New_York')\n",
        "    try:\n",
        "        '''\n",
        "        'try' statement for handlingy the exception error of stock.history that a ticker is not yet at stock market,\n",
        "        For example, \"shop.to\" is not there in 2012\n",
        "        '''\n",
        "        stock_history=stock.history(period=\"max\")[\"Close\"]\n",
        "        '''\n",
        "        Between the start and end days in stock_history variable, there are some missing days where there are no corresponding rows.\n",
        "        Add rows of  missing  days such that the values of column \"Close\" are set to be the value of the closest earlier day's\n",
        "        value, by using date_range to create full range without any missing date.\n",
        "        '''\n",
        "        # Create a DataFrame with a complete date range\n",
        "        date_range = pd.date_range(start=stock_history.index.min(), end=stock_history.index.max(), freq='D')\n",
        "        complete_stock_history = pd.DataFrame(index=date_range)\n",
        "        # Merge the complete DataFrame with the original stock_history\n",
        "        complete_stock_history = complete_stock_history.merge(stock_history, how='left', left_index=True, right_index=True)\n",
        "        complete_stock_history['Close'] = complete_stock_history['Close'].ffill()  # fill the newy added rows with previous day value\n",
        "        '''\n",
        "        Filter out the rows that matches the month and date of calculation_end_date, which are the ends of\n",
        "        annual periods from the calculation_end_date.\n",
        "        '''\n",
        "        # Filter out rows with dates newer than calculation_end_date\n",
        "        filtered_stock_history = complete_stock_history[complete_stock_history.index <= calculation_end_date]\n",
        "        #print(filtered_stock_history)\n",
        "        target_month=filtered_stock_history.index.max().month\n",
        "        target_day=filtered_stock_history.index.max().day\n",
        "        #print(\"target_month\", target_month, \"target_day\",target_day, \"start_year\", filtered_stock_history.index.max().year)\n",
        "        annual_returns = filtered_stock_history[(filtered_stock_history.index.month == target_month)\n",
        "           & (filtered_stock_history.index.day ==target_day)]\n",
        "        annual_returns_percent = annual_returns.pct_change().dropna()\n",
        "    except:\n",
        "        return  pd.DataFrame()\n",
        "    else:\n",
        "        annual_returns_df = pd.DataFrame(annual_returns_percent, columns=['Close'])\n",
        "        annual_returns_df.rename(columns={'Close': ticker}, inplace=True)\n",
        "        return annual_returns_df\n",
        "\n",
        "# Function to fetch data from yfinance and extract yearly total returns\n",
        "# annual return calculation starts at only yaer end boundary, i.e, Dec 31,\n",
        "# by resample('A')\n",
        "def get_annual_returns_year_boundary_df(ticker, calculation_end_date_str):\n",
        "    # Get the historical data for the given ticker\n",
        "    stock = yf.Ticker(ticker)\n",
        "    calculation_end_date = datetime.strptime(calculation_end_date_str, \"%Y-%m-%d\")\n",
        "    calculation_start_date_str = (calculation_end_date\n",
        "                - timedelta(days=num_years_calculation * 365)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    try:\n",
        "        '''\n",
        "        1.  'try' statement for handlingy the exception error of stock.history that a ticker is not yet at stock market,\n",
        "             For example, \"shop.to\" is not there in 2012\n",
        "        2. The row with the latest day from .history(.., end='end_day_date') is the day prior to end_day_date.  Therefore,\n",
        "           let end=the expected end day plus one day.\n",
        "        '''\n",
        "        calculation_end_date_plus_1day_str =  (calculation_end_date + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
        "        annual_returns_history=stock.history(start=calculation_start_date_str,end=calculation_end_date_plus_1day_str)[\"Close\"]\n",
        "\n",
        "        #print(\"debug get_annual_returns_df \", ticker, annual_returns_history)\n",
        "        # For 'A', 'Y', see https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases\n",
        "        ffilled_history=annual_returns = annual_returns_history.resample('A').ffill()\n",
        "        #print(ffilled_history)\n",
        "        annual_returns = ffilled_history.pct_change().dropna()\n",
        "        #annual_returns = annual_returns_history.resample('A').ffill().pct_change().dropna()\n",
        "        #print(\"debug get_annual_returns_df after resample()\", ticker, calculation_end_date, \"\\n\", annual_returns)\n",
        "    except:\n",
        "        return  pd.DataFrame()\n",
        "    else:\n",
        "        annual_returns_df = pd.DataFrame(annual_returns, columns=['Close'])\n",
        "        annual_returns_df.rename(columns={'Close': ticker}, inplace=True)\n",
        "        return annual_returns_df\n",
        "\n",
        "#----------------------------------------------------------------------------------\n",
        "# handling a list of tickers by calling the functions (either get_annual_returns_df\n",
        "# get_annual_returns_year_boundary_df) that handle single tickers\n",
        "def get_annual_returns_tickers_common_df(tickers, calculation_end_date_str, annual_returns_func_df):\n",
        "    # Create an empty DataFrame to store all tickers' total returns\n",
        "    all_tickers_returns_df = pd.DataFrame()\n",
        "\n",
        "    # Loop through each ticker in the list\n",
        "    for ticker in tickers:\n",
        "        ticker_returns_df = annual_returns_func_df(ticker, calculation_end_date_str)\n",
        "        if not ticker_returns_df.empty:\n",
        "            if all_tickers_returns_df.empty:\n",
        "                all_tickers_returns_df = ticker_returns_df\n",
        "            else:\n",
        "                '''\n",
        "                When running in  huggingface, pd.concat changed the index order of ticker_returns_df\n",
        "                when ticker_returns_df has more rows than all_tickers_returns_df. However, it is ok\n",
        "                running in colab.  Therefore, use pd.merge to replace pd.concat.\n",
        "                all_tickers_returns_df = pd.concat([all_tickers_returns_df, ticker_returns_df],axis=1,join='outer')  # Concatenate DataFrames\n",
        "                all_tickers_returns_df.sort_index() # index may be changed when running in huggingface\n",
        "                '''\n",
        "                all_tickers_returns_df = pd.merge(all_tickers_returns_df, ticker_returns_df,\n",
        "                        left_index=True, right_index=True, how='outer')\n",
        "        else:\n",
        "            # New column with NaN values\n",
        "            new_column_name = ticker\n",
        "            new_column_values = [None] * len(all_tickers_returns_df)\n",
        "            new_column = pd.DataFrame({new_column_name: new_column_values}, index=all_tickers_returns_df.index)\n",
        "            # Concatenate the new column to the original DataFrame\n",
        "            all_tickers_returns_df = pd.concat([all_tickers_returns_df, new_column], axis=1)\n",
        "    #return date_label_conversion_strip_time(all_tickers_returns_df, calculation_end_date_str)\n",
        "    return all_tickers_returns_df\n",
        "\n",
        "def get_annual_returns_tickers_df(tickers, calculation_end_date_str):\n",
        "    return get_annual_returns_tickers_common_df(tickers, calculation_end_date_str,\n",
        "                                                get_annual_returns_df)\n",
        "\n",
        "def get_annual_returns_tickers_year_boundary_df(tickers, calculation_end_date_str):\n",
        "    return get_annual_returns_tickers_common_df(tickers, calculation_end_date_str,\n",
        "                                                get_annual_returns_year_boundary_df)\n",
        "\n",
        "#==============================================================================\n",
        "# Part 2: calculate the annualized trailing total return from the data generated in step 1 & display\n",
        "# Define a function to calculate the annualized trailing total return for a given number of years\n",
        "def get_trailing_return(ticker, data, years):\n",
        "    # Get the total return values for the last n years\n",
        "    trailing_data = data[ticker].tail(years)\n",
        "    # Check if there are empty values within years\n",
        "    if trailing_data.isna().any():\n",
        "        return np.nan\n",
        "    # Check if there are valid total return values for all years\n",
        "    if len(trailing_data) == years:\n",
        "        # Convert the percentage strings to numeric values\n",
        "        trailing_data = trailing_data.astype(str).str.replace('%', '').astype(float)\n",
        "        \"\"\" Calculate the annualized trailing total return using the formula from Investopedia[^1^][1]:\n",
        "            Annualized Return = [(1 + r1) * (1 + r2) * ... * (1 + rn)]^(1/n) - 1\n",
        "            Where r1, r2, ..., rn are the total return values for each year                    \"\"\"\n",
        "        annualized_trailing_return = (trailing_data + 1).prod() ** (1 / years) - 1\n",
        "\n",
        "        # Format the result as a percentage with two decimal places\n",
        "        annualized_trailing_return = annualized_trailing_return * 100\n",
        "        annualized_trailing_return = annualized_trailing_return.round(2)\n",
        "        return annualized_trailing_return\n",
        "    else:\n",
        "        return np.nan\n",
        "\n",
        "# Define a function to Loop through the list and print the trailing returns for each num_years\n",
        "def get_trailing_return_column(ticker, annual_returns_df):\n",
        "    trailing_return_column = {}\n",
        "    for num_years in years_list:\n",
        "        # Check if the ticker data is available in all_tickers_returns_df\n",
        "        if ticker in annual_returns_df.columns:\n",
        "            # using data from step 1, avoiding get_annual_returns_df(ticker) for less traffic from yahoo server\n",
        "            data = annual_returns_df[[ticker]]\n",
        "            trailing_return = get_trailing_return(ticker, data, num_years)\n",
        "            trailing_return_column[f\"{num_years}-Year\"] = trailing_return\n",
        "        else:\n",
        "            print(f\"Data not available for {ticker}. Skipping.\")\n",
        "            trailing_return_column[f\"{num_years}-Year\"] = np.nan\n",
        "    return trailing_return_column\n",
        "\n",
        "# Create an empty DataFrame to store all tickers' trailing returns\n",
        "def get_trailing_return_all(tickers, annual_returns_df):\n",
        "    all_tickers_trailing_returns_df = pd.DataFrame(index=years_list)\n",
        "\n",
        "    # Loop through each ticker in the list\n",
        "    for ticker in tickers:\n",
        "        trailing_returns = get_trailing_return_column(ticker, annual_returns_df)\n",
        "        # Add the trailing returns to the DataFrame\n",
        "        all_tickers_trailing_returns_df[ticker] = pd.Series(trailing_returns).values\n",
        "    all_tickers_trailing_returns_df.columns = map(str.lower, all_tickers_trailing_returns_df.columns)\n",
        "    return all_tickers_trailing_returns_df\n",
        "\n",
        "#==============================================================================\n",
        "# Part 3: calculate the cumulative return from the data (all_tickers_returns_df) generated in part 1 & display\n",
        "#  Define a function to calculate the cumulative return for a given number of years from a ticker\n",
        "def get_cumulative_return(ticker, data, years):\n",
        "    # Calculate the cumulative return\n",
        "    cumulative_return = (1 + data[ticker]).rolling(window=years).apply(lambda x: x.prod(), raw=True) - 1\n",
        "    return cumulative_return\n",
        "\n",
        "# Define a function to Loop through the list and return the cumulative returns for each num_years\n",
        "def get_cumulative_return_column(ticker, annual_returns_df):\n",
        "    cumulative_returns = {}\n",
        "    for years in years_list:\n",
        "        # Calculate the cumulative return for the given number of years\n",
        "        cumulative_return = get_cumulative_return(ticker, annual_returns_df, years)\n",
        "        # Get the last value, which is the cumulative return up to the current year\n",
        "        cumulative_returns[years] = cumulative_return.iloc[-1]\n",
        "    return cumulative_returns\n",
        "\n",
        "def get_cumulative_return_all(tickers, annual_returns_df):\n",
        "    # Create an empty DataFrame with years_list as the index for cumulative  returns\n",
        "    all_tickers_cumulative_returns_df = pd.DataFrame(index=years_list)\n",
        "    # Loop through each ticker in the list\n",
        "    for ticker in tickers:\n",
        "        cumulative_returns = get_cumulative_return_column(ticker, annual_returns_df)\n",
        "        # Add the trailing returns to the DataFrame\n",
        "        all_tickers_cumulative_returns_df[ticker] = pd.Series(cumulative_returns).values\n",
        "    all_tickers_cumulative_returns_df.columns = map(str.lower, all_tickers_cumulative_returns_df.columns)\n",
        "    return all_tickers_cumulative_returns_df\n",
        "\n",
        "#==============================================================================\n",
        "# Part 4: calculate the  CAGR (Compound Annual Growth Rate) from the data\n",
        "# in all_tickers_cumulative_returns_df generated earlier & display\n",
        "# Define a function to calculate the CAGR from the cumulative value and the years\n",
        "def calculate_cagr(value, years):\n",
        "    # Otherwise, calculate the CAGR using the formula\n",
        "    cagr = (value + 1) ** (1 / np.array(years)) - 1\n",
        "    #print(\"debug-cagr\\n\", cagr, \"end\")\n",
        "    return cagr\n",
        "\n",
        "# Define a function to format the Float64Index values into percentage strings\n",
        "def format_to_percentage(value):\n",
        "    # If any element in the value array is not null, format it as a percentage string with two decimal places\n",
        "    if np.any(pd.notnull(value)):\n",
        "        return f\"{value:.2f}%\"\n",
        "    # Otherwise, return None\n",
        "    return None\n",
        "\n",
        "def get_cagr_return_all(all_tickers_cumulative_returns_df):\n",
        "    # Apply the calculate_cagr function to each column of the DataFrame\n",
        "    all_tickers_cagrs_df = all_tickers_cumulative_returns_df.apply(lambda x: calculate_cagr(x, x.index), axis=0)\n",
        "    return all_tickers_cagrs_df\n",
        "\n",
        "#==============================================================================\n",
        "# Part 5: utility functions\n",
        "# get the last trading day of S&P 500 in string format\n",
        "def get_last_trading_day():\n",
        "    # Get today's date, use .strftime(\"%Y-%m-%d\") to convert to a string\n",
        "    today_date_str=datetime.now(pytz.timezone('America/New_York')).date().strftime(\"%Y-%m-%d\")\n",
        "    stock = yf.Ticker(\"^GSPC\") # S&P 500 (^GSPC) ticker\n",
        "    #  search and see yfinance_BUG_1 NOTE in this file\n",
        "    history_df=stock.history(period=\"max\", end=today_date_str)[\"Close\"]\n",
        "    last_trading_day_str = history_df.index.max().date().strftime(\"%Y-%m-%d\")\n",
        "    return last_trading_day_str\n",
        "\n",
        "def str_to_integer(integer_str):\n",
        "    try:\n",
        "        integer_number = int(integer_str)\n",
        "        return integer_number\n",
        "    except ValueError:\n",
        "        return -1\n",
        "\n",
        "# validate the date string\n",
        "def is_valid_date(date_string):\n",
        "    try:\n",
        "        # Attempt to parse the date string\n",
        "        datetime.strptime(date_string, \"%Y-%m-%d\")\n",
        "        return True\n",
        "    except ValueError:\n",
        "        # Raised when the date string is not in the expected format\n",
        "        return False\n",
        "\n",
        "def date_label_conversion_strip_time(all_tickers_returns_df, calculation_end_date_str):\n",
        "    all_tickers_returns_df.index=all_tickers_returns_df.index.date\n",
        "    all_tickers_returns_df.index.name='date'\n",
        "    # print(\"debug get_annual_returns_tickers_df\", all_tickers_returns_df)\n",
        "    # Convert calculation_end_date_str to a datetime object, replace the index's mon/day portion of date\n",
        "    end_date_datetime_obj = datetime.strptime(calculation_end_date_str, \"%Y-%m-%d\")\n",
        "    all_tickers_returns_df.index = all_tickers_returns_df.index.map(\n",
        "      lambda x: x.replace(month=end_date_datetime_obj.month,\n",
        "      day=end_date_datetime_obj.day))\n",
        "    return all_tickers_returns_df\n",
        "\n",
        "#==============================================================================\n",
        "# Part 6:\n",
        "# single ticker's Prices, Returns,Dividends, good for verifying whether \"Adj Close\" is correct.\n",
        "'''\n",
        "    Calculate and display: yearly dividendSum, 'Close' & 'Adj Close' prices,\n",
        "    Return(by 'Close' price), total return(by 'Adj Close' price),\n",
        "    CalReturn(total return by 'Close' price and \"dividendSum).\n",
        "    Note: CalReturn from  is expected to be nearly same as  total return,\n",
        "           when the 'Adj Close' price is correct.\n",
        "'''\n",
        "def get_yearly_single_stock_data(ticker):\n",
        "    stock = yf.Ticker(ticker)\n",
        "    #-------- mainly for downloading 'Dividends'\n",
        "    history = stock.history(period=\"max\")\n",
        "    dividend_history=history['Dividends']\n",
        "    dividend_history.index=dividend_history.index.date\n",
        "\n",
        "    #-------- mainly for downloading 'Close','Adj Close'\n",
        "    dld_history=yf.download(ticker, period=\"max\")\n",
        "    dld_history=dld_history[['Close','Adj Close']]\n",
        "    dld_history.rename(columns={'Adj Close': 'AdjClose'}, inplace=True)\n",
        "    date_range = pd.date_range(start=dld_history.index.min(), end=dld_history.index.max(), freq='D')\n",
        "    complete_history = pd.DataFrame(index=date_range)\n",
        "\n",
        "    # Merge the complete DataFrame with the original stock_history\n",
        "    complete_history = complete_history.merge(dld_history, how='left', left_index=True, right_index=True)\n",
        "    complete_history[['Close','AdjClose']] = complete_history[['Close','AdjClose']].ffill().round(3)\n",
        "\n",
        "    # Merge dividend into complete_history\n",
        "    complete_history = complete_history.merge(dividend_history, how='left', left_index=True, right_index=True)\n",
        "    # replace all NaN values in the 'Dividends' column with 0.0\n",
        "    complete_history['Dividends'] = complete_history['Dividends'].fillna(0.0).round(3)\n",
        "\n",
        "    complete_history['Year']=complete_history.index.year\n",
        "    complete_history['Date']=complete_history.index\n",
        "    yearly_data = complete_history.groupby('Year').agg({'Date': 'last', 'Close': 'last', 'AdjClose': 'last','Dividends': 'sum'})\n",
        "    yearly_data.rename(columns={'Dividends': 'DivSum'}, inplace=True)\n",
        "\n",
        "    # calculating 'Return' and 'TotalReturn'\n",
        "    yearly_data['DivRatio']=yearly_data['DivSum'] / yearly_data['Close']\n",
        "    yearly_data['Return']=yearly_data['Close'].pct_change()\n",
        "    yearly_data['TotalReturn']=yearly_data['AdjClose'].pct_change()\n",
        "\n",
        "    '''\n",
        "    The CalReturn column is the yearly total return calculated from un-adjusted \"Close\" prices and yearly \"dividend sum\",\n",
        "    which is expected to be equal to the total return that is calculated from \"AdjClose\" prices\n",
        "    '''\n",
        "    yearly_data['CalReturn'] = (yearly_data['Close'] + yearly_data['DivSum']) / yearly_data['Close'].shift(1) - 1\n",
        "    # set the display format\n",
        "    yearly_data[['DivRatio','Return','TotalReturn','CalReturn']] = yearly_data[['DivRatio','Return','TotalReturn','CalReturn']].mul(100).round(2)\n",
        "    '''\n",
        "    #yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']] = yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']].applymap(\"{:.2f}%\".format)\n",
        "    yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']]= \\\n",
        "     yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']].applymap(lambda x: f\"{x:.2f}%\" if not pd.isna(x) else \"NaN\")\n",
        "    '''\n",
        "    # Use .applymap() and lambda to format the values as percentage strings only if they are not NaN\n",
        "    yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']]= \\\n",
        "         yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']].applymap(lambda x: f\"{x:.2f}%\" if not pd.isna(x) else x)\n",
        "\n",
        "    # 'Date' column is no longer required\n",
        "    yearly_data.drop('Date', axis=1, inplace=True)\n",
        "    return yearly_data\n",
        "\n",
        "#==============================================================================\n",
        "# Part 7:\n",
        "# print the year-end adjusted close prices of a list of stockes\n",
        "def stock_prices_df(tickers_list, end_date_str):\n",
        "    tickers_list_upper = [ticker.upper() for ticker in tickers_list]\n",
        "    tickers_str = \", \".join(tickers_list_upper)\n",
        "    # Download the historical data\n",
        "    data = yf.download(tickers_str, period=\"max\")\n",
        "    data_adj_close = data['Adj Close']\n",
        "\n",
        "    # Filter out rows with dates newer than calculation_end_date\n",
        "    data_adj_close = data_adj_close[data_adj_close.index <= end_date_str]\n",
        "\n",
        "    # Rearrange columns based on the order in tickers_list_upper\n",
        "    if len(tickers_list)>1:\n",
        "        data_adj_close = data_adj_close.reindex(columns=tickers_list_upper)\n",
        "\n",
        "    data_adj_close = data_adj_close.resample('A').ffill().round(2)\n",
        "    data_adj_close.index=data_adj_close.index.date\n",
        "    last_date = data_adj_close.index[-1]\n",
        "    data_adj_close = data_adj_close.rename(index={last_date: end_date_str})\n",
        "    data_adj_close_df = pd.DataFrame(data_adj_close)\n",
        "    data_adj_close_df.columns = map(str.lower, data_adj_close_df.columns)\n",
        "    return data_adj_close_df\n",
        "\n",
        "#==============================================================================\n",
        "# Part 8: gradio handling - Input command handling and display in web page\n",
        "\n",
        "help_info_str=\"Input Formats:\\n  \\\n",
        "            1. ticker list....................Example:  spy vfv.to xiu.to xic.to xfn.to ry.to \\n \\\n",
        "            2. One of default ticker list, a number between 1 and 7....Example:   0, or 1, ...,7 \\n \\\n",
        "            3. CalculationEndDate as prefix.  Example:   2020-12-31 2 \\n \\\n",
        "            .........................................2020-12-31 spy vfv.to xiu.to xic.to xfn.to ry.to \\n \\\n",
        "            4. single ticker: Dividend/Close/AdjClose/Return/TotalReturn/CalReturn(by Close/Dividends).  @1 spy \\n \\\n",
        "            note: daily adjusted close data are from Yahoo Finance. \"\n",
        "\n",
        "# Main Handling Process\n",
        "def calculation_response(message):\n",
        "    # if there is no input, display help information\n",
        "    if message==\"\":\n",
        "        return help_info_str\n",
        "\n",
        "    tickers=message.split()\n",
        "\n",
        "    # ******************************************************************************\n",
        "    #  processing web input parameters\n",
        "    #  set calculation_end_date_str, and tickers\n",
        "\n",
        "    #---------------------------------------------------------\n",
        "    # single stock ticker - detailed information\n",
        "    if (tickers[0] == \"@1\"):\n",
        "        tickers.pop(0) # remove the first string which is \"@1\"\n",
        "        if len(tickers)==0:\n",
        "            ticker = 'spy' # default ticker = spy\n",
        "        else:\n",
        "            ticker=tickers[0]\n",
        "        output_string=f\"\\n {ticker}\\n\"\n",
        "        output_dataframe0=get_yearly_single_stock_data(ticker)\n",
        "        output_html=output_string + output_dataframe0.to_html()\n",
        "        return output_html\n",
        "\n",
        "    #----------------------------------------------------------\n",
        "    # Get today's date, use .strftime(\"%Y-%m-%d\") to convert to a string\n",
        "    #calculation_end_date_str=datetime.now(pytz.timezone('America/New_York')).date().strftime(\"%Y-%m-%d\")\n",
        "    calculation_end_date_str = get_last_trading_day()\n",
        "    # Check whether the first str is date for calculation end date\n",
        "    if is_valid_date(tickers[0]):\n",
        "        calculation_end_date_str = tickers[0] # reset calculation_end_date_str\n",
        "        tickers.pop(0) # remove the first string which is the date\n",
        "\n",
        "    #............ For display trailing and cumulative returns at month_boundary_date\n",
        "    # Assuming calculation_end_date_str contains the date string '2024-01-03'\n",
        "    calculation_end_date = datetime.strptime(calculation_end_date_str, '%Y-%m-%d')\n",
        "    # Calculate the first day of the current month\n",
        "    first_day_of_month = calculation_end_date.replace(day=1)\n",
        "    # Calculate the last day of the month\n",
        "    last_day_of_month = (calculation_end_date.replace(day=1) + timedelta(days=32)).replace(day=1) - timedelta(days=1)\n",
        "    # Calculate the last day of the previous month\n",
        "    last_day_of_previous_month = first_day_of_month - timedelta(days=1)\n",
        "    # Check if the original date is the last day of the month\n",
        "    if (calculation_end_date == last_day_of_month):\n",
        "        calculation_end_date_month_boundary_date_str=calculation_end_date_str\n",
        "    else:\n",
        "        calculation_end_date_month_boundary_date_str=last_day_of_previous_month.strftime('%Y-%m-%d')\n",
        "    # calculation_end_date_for_others are for trailing and cumulative returns\n",
        "    calculation_end_date_for_others_str=calculation_end_date_month_boundary_date_str\n",
        "\n",
        "    '''  Handling Feb 29 of leap years.\n",
        "    For leap years, to simiplify the calculation,  Feb 28 will be used to replace Feb 29 for\n",
        "    for calculating returns.\n",
        "    Therefore, if calculation_end_date_for_others_str is Feb 29, then replace 29 to 28 of calculation_end_date_for_others_str\n",
        "    '''\n",
        "    leap_year=False\n",
        "    if (\n",
        "        calculation_end_date_for_others_str[-5:] == '02-29'\n",
        "    ):\n",
        "        calculation_end_date_for_others_str = calculation_end_date_for_others_str[:-2] + '28'\n",
        "        leap_year=True\n",
        "    #................End\n",
        "\n",
        "    # Check whether numebr 0, 1, 2, .. is selected for using a default ticker list\n",
        "    integer_value=str_to_integer(tickers[0])\n",
        "    if (integer_value >= 0 and integer_value <len(tickers_lists)):\n",
        "        tickers=tickers_lists[integer_value]\n",
        "\n",
        "    # if no tickers were set, display help information\n",
        "    if len(tickers)==0:\n",
        "        return help_info_str\n",
        "\n",
        "    #*********************************************************************************\n",
        "    # Calculating year-end prices, Annual, Trailing, Cumulative, and CAGR returns & generating html for display\n",
        "    #\n",
        "    # list of year-end prices of stocks\n",
        "    output_string0= f\"\\nAdj Close Prices ($)\\n\"\n",
        "    output_dataframe= stock_prices_df(tickers, calculation_end_date_str)\n",
        "    output_html0=output_string0 + output_dataframe.to_html()\n",
        "    #  Annual Total Return\n",
        "    output_string = f\"\\nAnnual Total Return (%) as {calculation_end_date_str}\\n\"\n",
        "    output_dataframe = get_annual_returns_tickers_year_boundary_df(tickers, calculation_end_date_str)\n",
        "    output_dataframe = output_dataframe.dropna(how='all')\n",
        "    output_dataframe = output_dataframe.round(4)*100\n",
        "    output_dataframe.index=output_dataframe.index.date\n",
        "    # Assuming your DataFrame is named output_dataframe\n",
        "    last_date = output_dataframe.index[-1]\n",
        "    output_dataframe = output_dataframe.rename(index={last_date: calculation_end_date_str})\n",
        "    # Convert the DataFrame to HTML, Combine the expected string outputs\n",
        "    output_dataframe.columns = map(str.lower, output_dataframe.columns)\n",
        "    output_html1 = output_string + output_dataframe.to_html()\n",
        "\n",
        "    # annual_returns  - at any given day, for calculating trailing and cumulative returns, not to be displayed\n",
        "    annual_returns_dataframe=get_annual_returns_tickers_df(tickers, calculation_end_date_for_others_str)\n",
        "\n",
        "    # Trailing Return\n",
        "    if (leap_year):\n",
        "        output_string2 = f\"\\nTrailing Total Return (%) as {calculation_end_date_for_others_str} (leap year: Feb 29 replaced by Feb 28 for approximation)\\n\"\n",
        "    else:\n",
        "        output_string2 = f\"\\nTrailing Total Return (%) as {calculation_end_date_for_others_str}\\n\"\n",
        "    output_dataframe2=get_trailing_return_all(tickers, annual_returns_dataframe)\n",
        "    output_dataframe2 = output_dataframe2.dropna(how='all')\n",
        "    # Insert an empty to align the ticker symbols with annual return display\n",
        "    output_dataframe2.insert(0, \"--------\", \"      \")\n",
        "    output_dataframe2.index.name=\"years\"\n",
        "    output_html2=output_string2 + output_dataframe2.to_html()\n",
        "\n",
        "    # Cumulative Return\n",
        "    output_string3 = f\"\\nCumulative Return (%) as {calculation_end_date_for_others_str}\\n\"\n",
        "    cumulative_return_all_dataframe=get_cumulative_return_all(tickers, annual_returns_dataframe)\n",
        "    cumulative_return_all_dataframe = cumulative_return_all_dataframe.dropna(how='all')\n",
        "    output_dataframe3=cumulative_return_all_dataframe.round(4)*100\n",
        "    output_dataframe3.index.name=\"years\"\n",
        "    output_html3=output_string3 + output_dataframe3.to_html()\n",
        "\n",
        "    # CAGR Return\n",
        "    output_string4 = f\"\\nCompound Annual Growth Rate (CAGR) (%) as {calculation_end_date_for_others_str}\\n\"\n",
        "    output_dataframe4=get_cagr_return_all (cumulative_return_all_dataframe)\n",
        "    output_dataframe4=output_dataframe4.round(4)*100\n",
        "    output_html4=output_string4 + output_dataframe4.to_html()\n",
        "\n",
        "    #output_html = output_html1 + output_html2 + output_html3 + output_html4\n",
        "    output_html = output_html0 + output_html1 + output_html2 + output_html3\n",
        "    return  output_html\n",
        "\n",
        "# Gradio Web interface\n",
        "'''\n",
        "def ChatInterface_response(message, history):\n",
        "    output_html=calculation_response(message)\n",
        "    return output_html\n",
        "web_handling = gr.ChatInterface(ChatInterface_response)\n",
        "web_handling.launch(debug=False, share=False)\n",
        "'''\n",
        "with gr.Blocks() as web_block:\n",
        "    '''\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox()\n",
        "    clear = gr.ClearButton([msg, chatbot])\n",
        "    '''\n",
        "    chatbot = gr.Chatbot(height=\"500px\")\n",
        "    # Create a row element for the Textbox and Clear button\n",
        "    with gr.Row():\n",
        "        #msg = gr.Textbox(label=\"stock tickers input\", scale=2, min_width=380)\n",
        "        msg = gr.Textbox(show_label=False, scale=2, min_width=380)\n",
        "        clear = gr.ClearButton([msg, chatbot], scale=0, min_width=50)\n",
        "\n",
        "    def respond(message, chat_history):\n",
        "        bot_message = calculation_response(message)\n",
        "        chat_history.append((message, bot_message))\n",
        "        return \"\", chat_history\n",
        "\n",
        "    msg.submit(respond, # function\n",
        "     [msg, chatbot],  # inputs of the function\n",
        "     [msg, chatbot]   # outputs of the function\n",
        "               )\n",
        "web_block.launch()\n",
        "#web_block.launch(debug=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUfctn_9Wcqs"
      },
      "source": [
        "# Example 7 = gradio + Example 6- calender year boundary  (multiple stocks) annual,  trailing, cumumlative, and CAGR  returns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "1oDKEyOiAEGC",
        "outputId": "cdfda9b6-6bae-4055-b723-0ddc07505ded"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7871, \"/\", \"100%\", 500, false, window.element)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "!pip install gradio\n",
        "!pip install yfinance\n",
        "!pip install datetime\n",
        "!pip install pytz\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "'''\n",
        "script_version = '(2024-01-06.1)'\n",
        "import gradio as gr\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import pytz\n",
        "#--------------------------------------------------------------------\n",
        "\n",
        "print_yearly_total_return = True\n",
        "num_years_calculation=32   # total years for calculation\n",
        "\n",
        "# Define a list of years to calculate the trailing returns, cumulative returns, and so on\n",
        "# remove the row of current year row since it is not a full year.\n",
        "years_list = [1, 2, 3, 5, 9, 10, 15, 20, 25, 30]\n",
        "\n",
        "# Set the stock tickers list\n",
        "tickers_lists = [[\"spy\", \"vfv.to\",\"xiu.to\"], #0\n",
        "    [\"spy\", \"vfv.to\", \"vgg.to\", \"zlu.to\", \"xiu.to\", \"vdy.to\", \"xfn.to\", \"ry.to\", \"td.to\", \"na.to\",\n",
        "      \"slf.to\", \"gwo.to\", \"bce.to\", \"t.to\", \"rci-b.to\", \"enb.to\", \"trp.to\", \"zlb.to\", \"cp.to\"], #1\n",
        "    [\"spy\",\"vfv.to\", \"xiu.to\", \"fie.to\", \"xfn.to\", \"na.to\",\"ry.to\", \"bmo.to\", \"cm.to\", \"bns.to\", \"cwb.to\",\n",
        "      \"slf.to\", \"gwo.to\", \"bce.to\", \"t.to\", \"rci-b.to\", \"enb.to\", \"trp.to\", \"xdv.to\",\"cdz.to\",\"vdy.to\"],  #2\n",
        "    [\"spy\", \"vfv.to\", \"vgg.to\", \"zlu.to\",\"goog\", \"msft\", \"meta\", \"tsla\",\"AMZN\", \"AAPL\", \"shop.to\"],   #3\n",
        "    [\"^IXIC\",\"^GSPC\",\"spy\", \"vfv.to\", \"zsp.to\", \"xsp.to\",\"^GSPTSE\",\"xic.to\",\"xiu.to\",\"xfn.to\",\"fie.to\", \"TX60.TS\"], #4\n",
        "    [\"xic.to\",\"xiu.to\",\"xfn.to\"]  #5\n",
        "]\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 1: fetch retrieve yearly total returns by yfinance & display\n",
        "# Function to fetch data from yfinance and extract yearly total returns\n",
        "def get_annual_returns_df(ticker, calculation_end_date):\n",
        "    # Get the historical data for the given ticker\n",
        "    stock = yf.Ticker(ticker)\n",
        "    calculation_start_date = (datetime.strptime(calculation_end_date, \"%Y-%m-%d\")\n",
        "                - timedelta(days=num_years_calculation * 365)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    # Get today's date, use .strftime(\"%Y-%m-%d\") to convert to a string\n",
        "    today_date=datetime.now(pytz.timezone('America/New_York')).date().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    ''' yfinance_BUG_1 NOTE:\n",
        "    There is bug for  when using end=\"2024-01-02\" on 2024-01-02 which is the first trading of the year on 8:10pm\n",
        "    for using annual_returns_history=stock.history(start=calculation_start_date,end=calculation_end_date)[\"Close\"]\n",
        "     (tried tickers: \"^GSPC\",\"spy\" for stock = yf.Ticker(ticker)) that 2024-01-02 data is not returned.\n",
        "     however, when end parameter, it is fine for returning  2024-01-02 data as below\n",
        "     annual_returns_history=stock.history(start=calculation_start_date)[\"Close\"]\n",
        "    '''\n",
        "    try:\n",
        "        #'try' statement for handlingy the exception error of stock.history that a ticker is not yet at stock market, \"shop.to\" is not there in 2012\n",
        "        # the following if statement for handling yfinance_BUG_1\n",
        "        if (calculation_end_date != today_date):\n",
        "            annual_returns_history=stock.history(start=calculation_start_date,end=calculation_end_date)[\"Close\"]\n",
        "        else:\n",
        "            annual_returns_history=stock.history(start=calculation_start_date)[\"Close\"]\n",
        "\n",
        "        #print(\"debug get_annual_returns_df \", ticker, annual_returns_history)\n",
        "        # Tried resample('A', origin=calculation_end_date),  \"origin=\"\" looks not working.\n",
        "        # For 'A', 'Y', see https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases\n",
        "        annual_returns = annual_returns_history.resample('A').ffill().pct_change().dropna()\n",
        "        #print(\"debug get_annual_returns_df after resample()\", ticker, calculation_end_date, \"\\n\", annual_returns)\n",
        "    except:\n",
        "        return  pd.DataFrame()\n",
        "    else:\n",
        "        annual_returns_df = pd.DataFrame(annual_returns, columns=['Close'])\n",
        "        annual_returns_df.rename(columns={'Close': ticker}, inplace=True)\n",
        "        return annual_returns_df\n",
        "\n",
        "def get_annual_returns_tickers_df(tickers, calculation_end_date):\n",
        "    # Create an empty DataFrame to store all tickers' total returns\n",
        "    all_tickers_returns_df = pd.DataFrame()\n",
        "\n",
        "    # Loop through each ticker in the list\n",
        "    for ticker in tickers:\n",
        "        ticker_returns_df = get_annual_returns_df(ticker, calculation_end_date)\n",
        "        if not ticker_returns_df.empty:\n",
        "            if all_tickers_returns_df.empty:\n",
        "                all_tickers_returns_df = ticker_returns_df\n",
        "            else:\n",
        "                all_tickers_returns_df = pd.concat([all_tickers_returns_df, ticker_returns_df], axis=1)  # Concatenate DataFrames\n",
        "        else:\n",
        "            # New column with NaN values\n",
        "            new_column_name = ticker\n",
        "            new_column_values = [None] * len(all_tickers_returns_df)\n",
        "            new_column = pd.DataFrame({new_column_name: new_column_values}, index=all_tickers_returns_df.index)\n",
        "            # Concatenate the new column to the original DataFrame\n",
        "            all_tickers_returns_df = pd.concat([all_tickers_returns_df, new_column], axis=1)\n",
        "    #return date_label_conversion_strip_time(all_tickers_returns_df, calculation_end_date)\n",
        "    return all_tickers_returns_df\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 2: calculate the annualized trailing total return from the data generated in step 1 & display\n",
        "# Define a function to calculate the annualized trailing total return for a given number of years\n",
        "def get_trailing_return(ticker, data, years):\n",
        "    # Get the total return values for the last n years\n",
        "    trailing_data = data[ticker].tail(years)\n",
        "    # Check if there are empty values within years\n",
        "    if trailing_data.isna().any():\n",
        "        return \"N/A\"\n",
        "    # Check if there are valid total return values for all years\n",
        "    if len(trailing_data) == years:\n",
        "        # Convert the percentage strings to numeric values\n",
        "        trailing_data = trailing_data.astype(str).str.replace('%', '').astype(float)\n",
        "        \"\"\" Calculate the annualized trailing total return using the formula from Investopedia[^1^][1]:\n",
        "            Annualized Return = [(1 + r1) * (1 + r2) * ... * (1 + rn)]^(1/n) - 1\n",
        "            Where r1, r2, ..., rn are the total return values for each year                    \"\"\"\n",
        "        annualized_trailing_return = (trailing_data + 1).prod() ** (1 / years) - 1\n",
        "\n",
        "        # Format the result as a percentage with two decimal places\n",
        "        annualized_trailing_return = annualized_trailing_return * 100\n",
        "        annualized_trailing_return = annualized_trailing_return.round(2)\n",
        "        return annualized_trailing_return\n",
        "    else:\n",
        "        return \"N/A\"\n",
        "\n",
        "# Define a function to Loop through the list and print the trailing returns for each num_years\n",
        "def get_trailing_return_column(ticker, annual_returns_df):\n",
        "    trailing_return_column = {}\n",
        "    for num_years in years_list:\n",
        "        # Check if the ticker data is available in all_tickers_returns_df\n",
        "        if ticker in annual_returns_df.columns:\n",
        "            # using data from step 1, avoiding get_annual_returns_df(ticker) for less traffic from yahoo server\n",
        "            data = annual_returns_df[[ticker]]\n",
        "            trailing_return = get_trailing_return(ticker, data, num_years)\n",
        "            trailing_return_column[f\"{num_years}-Year\"] = trailing_return\n",
        "        else:\n",
        "            print(f\"Data not available for {ticker}. Skipping.\")\n",
        "            trailing_return_column[f\"{num_years}-Year\"] = \"N/A\"\n",
        "    return trailing_return_column\n",
        "\n",
        "# Create an empty DataFrame to store all tickers' trailing returns\n",
        "def get_trailing_return_all(tickers, annual_returns_df):\n",
        "    all_tickers_trailing_returns_df = pd.DataFrame(index=years_list)\n",
        "\n",
        "    # Loop through each ticker in the list\n",
        "    for ticker in tickers:\n",
        "        trailing_returns = get_trailing_return_column(ticker, annual_returns_df)\n",
        "        # Add the trailing returns to the DataFrame\n",
        "        all_tickers_trailing_returns_df[ticker] = pd.Series(trailing_returns).values\n",
        "    return all_tickers_trailing_returns_df\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 3: calculate the cumulative return from the data (all_tickers_returns_df) generated in step 1 & display\n",
        "# 4.1 Define a function to calculate the cumulative return for a given number of years from a ticker\n",
        "def get_cumulative_return(ticker, data, years):\n",
        "    # Calculate the cumulative return\n",
        "    cumulative_return = (1 + data[ticker]).rolling(window=years).apply(lambda x: x.prod(), raw=True) - 1\n",
        "    return cumulative_return\n",
        "\n",
        "# Define a function to Loop through the list and return the cumulative returns for each num_years\n",
        "def get_cumulative_return_column(ticker, annual_returns_df):\n",
        "    cumulative_returns = {}\n",
        "    for years in years_list:\n",
        "        # Calculate the cumulative return for the given number of years\n",
        "        cumulative_return = get_cumulative_return(ticker, annual_returns_df, years)\n",
        "        # Get the last value, which is the cumulative return up to the current year\n",
        "        cumulative_returns[years] = cumulative_return.iloc[-1]\n",
        "    return cumulative_returns\n",
        "\n",
        "def get_cumulative_return_all(tickers, annual_returns_df):\n",
        "    # Create an empty DataFrame with years_list as the index for cumulative  returns\n",
        "    all_tickers_cumulative_returns_df = pd.DataFrame(index=years_list)\n",
        "    # Loop through each ticker in the list\n",
        "    for ticker in tickers:\n",
        "        cumulative_returns = get_cumulative_return_column(ticker, annual_returns_df)\n",
        "        # Add the trailing returns to the DataFrame\n",
        "        all_tickers_cumulative_returns_df[ticker] = pd.Series(cumulative_returns).values\n",
        "    return all_tickers_cumulative_returns_df\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 4: calculate the  CAGR (Compound Annual Growth Rate) from the data\n",
        "# in all_tickers_cumulative_returns_df generated earlier & display\n",
        "# Define a function to calculate the CAGR from the cumulative value and the years\n",
        "def calculate_cagr(value, years):\n",
        "    # Otherwise, calculate the CAGR using the formula\n",
        "    cagr = (value + 1) ** (1 / np.array(years)) - 1\n",
        "    #print(\"debug-cagr\\n\", cagr, \"end\")\n",
        "    return cagr\n",
        "\n",
        "# Define a function to format the Float64Index values into percentage strings\n",
        "def format_to_percentage(value):\n",
        "    # If any element in the value array is not null, format it as a percentage string with two decimal places\n",
        "    if np.any(pd.notnull(value)):\n",
        "        return f\"{value:.2f}%\"\n",
        "    # Otherwise, return None\n",
        "    return None\n",
        "\n",
        "def get_cagr_return_all(all_tickers_cumulative_returns_df):\n",
        "    # Apply the calculate_cagr function to each column of the DataFrame\n",
        "    all_tickers_cagrs_df = all_tickers_cumulative_returns_df.apply(lambda x: calculate_cagr(x, x.index), axis=0)\n",
        "    return all_tickers_cagrs_df\n",
        "\n",
        "#---------------------------------------------------------------\n",
        "# utility functions\n",
        "# get the last trading day of S&P 500 in string format\n",
        "def get_last_trading_day():\n",
        "    # Get today's date, use .strftime(\"%Y-%m-%d\") to convert to a string\n",
        "    #calculation_end_date=datetime.now(pytz.timezone('America/New_York')).date().strftime(\"%Y-%m-%d\")\n",
        "    today_date_str=datetime.now(pytz.timezone('America/New_York')).date().strftime(\"%Y-%m-%d\")\n",
        "    stock = yf.Ticker(\"^GSPC\") # S&P 500 (^GSPC) ticker\n",
        "    #  search and see yfinance_BUG_1 NOTE in this file\n",
        "    history_df=stock.history(period=\"max\", end=today_date_str)[\"Close\"]\n",
        "    calculation_end_date_str = history_df.index.max().date().strftime(\"%Y-%m-%d\")\n",
        "    return calculation_end_date_str\n",
        "\n",
        "def str_to_integer(integer_str):\n",
        "    try:\n",
        "        integer_number = int(integer_str)\n",
        "        return integer_number\n",
        "    except ValueError:\n",
        "        return -1\n",
        "\n",
        "# validate the date string\n",
        "def is_valid_date(date_string):\n",
        "    try:\n",
        "        # Attempt to parse the date string\n",
        "        datetime.strptime(date_string, \"%Y-%m-%d\")\n",
        "        return True\n",
        "    except ValueError:\n",
        "        # Raised when the date string is not in the expected format\n",
        "        return False\n",
        "\n",
        "def date_label_conversion_strip_time(all_tickers_returns_df, calculation_end_date):\n",
        "    all_tickers_returns_df.index=all_tickers_returns_df.index.date\n",
        "    all_tickers_returns_df.index.name='date'\n",
        "    # print(\"debug get_annual_returns_tickers_df\", all_tickers_returns_df)\n",
        "    # Convert calculation_end_date to a datetime object, replace the index's mon/day portion of date\n",
        "    calculation_end_date_datetime_obj = datetime.strptime(calculation_end_date, \"%Y-%m-%d\")\n",
        "    all_tickers_returns_df.index = all_tickers_returns_df.index.map(\n",
        "      lambda x: x.replace(month=calculation_end_date_datetime_obj.month,\n",
        "      day=calculation_end_date_datetime_obj.day))\n",
        "    return all_tickers_returns_df\n",
        "\n",
        "help_info_str=\"Input Formats:\\n  \\\n",
        "            1. ticker list....................Example:  spy vfv.to xiu.to xic.to xfn.to ry.to \\n \\\n",
        "            2. One of default ticker list, a number between 1 and 5....Example:   0, or 1, ...,5 \\n \\\n",
        "            3. CalculationEndDate as prefix.  Example:   2020-12-31 2 \\n \\\n",
        "            .........................................2020-12-31 spy vfv.to xiu.to xic.to xfn.to ry.to \\n \\\n",
        "            note: daily adjusted close data are from Yahoo Finance. \"\n",
        "\n",
        "#---------------------------------------------------------------\n",
        "# step 5:  Display in web page using gradio\n",
        "# Gradio Web interface\n",
        "def calculation_response(message, history):\n",
        "    # if there is no input, display help information\n",
        "    if message==\"\":\n",
        "        return help_info_str\n",
        "\n",
        "    tickers=message.split()\n",
        "\n",
        "    # -----------\n",
        "    #  set calculation_end_date\n",
        "    # Get today's date, use .strftime(\"%Y-%m-%d\") to convert to a string\n",
        "    #calculation_end_date=datetime.now(pytz.timezone('America/New_York')).date().strftime(\"%Y-%m-%d\")\n",
        "    calculation_end_date = get_last_trading_day()\n",
        "    # Check whether the first str is date for calculation end date\n",
        "    if is_valid_date(tickers[0]):\n",
        "        calculation_end_date = tickers[0] # reset calculation_end_date\n",
        "        tickers.pop(0) # remove the first string which is the date\n",
        "\n",
        "    # Check whether numebr 0, 1, 2, .. is selected for using a default ticker list\n",
        "    integer_value=str_to_integer(tickers[0])\n",
        "    if (integer_value >= 0 and integer_value <len(tickers_lists)):\n",
        "        tickers=tickers_lists[integer_value]\n",
        "\n",
        "    # if no tickers were set, display help information\n",
        "    if len(tickers)==0:\n",
        "        return help_info_str\n",
        "\n",
        "    #---------------\n",
        "    # Calculating Annual, Trailing, Cumulative, and CAGR & generating html for display\n",
        "    # annual_returns\n",
        "    output_string = f\"\\nAnnual Total Return (%) as {calculation_end_date}\\n\"\n",
        "    annual_returns_dataframe=get_annual_returns_tickers_df(tickers, calculation_end_date)\n",
        "    output_dataframe = annual_returns_dataframe.round(4)*100\n",
        "    output_dataframe.index=output_dataframe.index.year\n",
        "    # Convert the DataFrame to HTML, Combine the expected string outputs\n",
        "    output_html1 = output_string + output_dataframe.to_html()\n",
        "\n",
        "    # Removing the current year's data\n",
        "    today_date=datetime.now(pytz.timezone('America/New_York')).date()\n",
        "    all_tickers_returns_all_years_df=annual_returns_dataframe\n",
        "    if (annual_returns_dataframe.index.max().year == today_date.year):\n",
        "        annual_returns_dataframe=annual_returns_dataframe[annual_returns_dataframe.index.year < today_date.year]\n",
        "        month_date = \"12-31\"\n",
        "        calculation_end_date = f\"{annual_returns_dataframe.index.max().year}-{month_date}\"\n",
        "\n",
        "    # Trailing Return\n",
        "    output_string2 = f\"\\nTrailing Total Return (%) as {calculation_end_date}\\n\"\n",
        "    output_dataframe2=get_trailing_return_all(tickers, annual_returns_dataframe)\n",
        "    output_dataframe2.index.name=\"years\"\n",
        "    output_html2=output_string2 + output_dataframe2.to_html()\n",
        "\n",
        "    # Cumulative Return\n",
        "    output_string3 = f\"\\nCumulative Return (%) as {calculation_end_date}\\n\"\n",
        "    cumulative_return_all_dataframe=get_cumulative_return_all(tickers, annual_returns_dataframe)\n",
        "    output_dataframe3=cumulative_return_all_dataframe.round(4)*100\n",
        "    output_dataframe3.index.name=\"years\"\n",
        "    output_html3=output_string3 + output_dataframe3.to_html()\n",
        "\n",
        "    # CAGR Return\n",
        "    output_string4 = f\"\\nCompound Annual Growth Rate (CAGR) (%) as {calculation_end_date}\\n\"\n",
        "    output_dataframe4=get_cagr_return_all (cumulative_return_all_dataframe)\n",
        "    output_dataframe4=output_dataframe4.round(4)*100\n",
        "    output_html4=output_string4 + output_dataframe4.to_html()\n",
        "\n",
        "    #output_html = output_html1 + output_html2 + output_html3 + output_html4\n",
        "    output_html = output_html1 + output_html2 + output_html3\n",
        "    return  output_html\n",
        "\n",
        "demo = gr.ChatInterface(calculation_response)\n",
        "demo.launch(debug=False, share=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdYMJ0MyBIiz"
      },
      "outputs": [],
      "source": [
        "# debug section\n",
        "#calculation_response(\"0\", [])\n",
        "'''\n",
        "calculation_end_date= \"2012-01-02\"\n",
        "print(\"get_last_trading_day\", calculation_end_date)\n",
        "tickers = [\"spy\", \"vfv.to\", \"vgg.to\", \"goog\", \"msft\", \"meta\", \"tsla\",\"AMZN\", \"AAPL\", \"shop.to\"]\n",
        "output_string = f\"\\nAnnual Total Return (%) as {calculation_end_date}\\n\"\n",
        "annual_returns_dataframe=get_annual_returns_tickers_df(tickers, calculation_end_date)\n",
        "output_dataframe = annual_returns_dataframe.round(4)*100\n",
        "print(output_dataframe)\n",
        "\n",
        "help_info_str = \"\"\"Input Formats:\n",
        "| {0:30} | {1:30} |\n",
        "| {2:30} | {3:30} |\n",
        "| {4:30} | {5:30} |\"\"\".format(\n",
        "    \"1. ticker list.\", \"Example: spy vfv.to xiu.to xic.to xfn.to ry.to\",\n",
        "    \"2. One of default ticker list.\", \"Example: 0|1|...|5\",\n",
        "    \"3. CalculationEndDate as prefix.\", \"Example: 2020-12-31 2 or 2020-12-31 spy vfv.to xiu.to xic.to xfn.to ry.to\"\n",
        ")\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kbZjydOUiRq"
      },
      "source": [
        "## example 7 backup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "2TsOzhZNUsNi",
        "outputId": "215a3a0b-d3d6-4b32-d7d6-aafd7a81d0ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "!pip install gradio\n",
        "!pip install yfinance\n",
        "!pip install datetime\n",
        "!pip install pytz\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "'''\n",
        "script_version = '(2024-01-06.1)'\n",
        "import gradio as gr\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import pytz\n",
        "#--------------------------------------------------------------------\n",
        "\n",
        "print_yearly_total_return = True\n",
        "num_years_calculation=32   # total years for calculation\n",
        "\n",
        "# Define a list of years to calculate the trailing returns, cumulative returns, and so on\n",
        "# remove the row of current year row since it is not a full year.\n",
        "years_list = [1, 2, 3, 5, 9, 10, 15, 20, 25, 30]\n",
        "\n",
        "# Set the stock tickers list\n",
        "tickers_lists = [[\"spy\", \"vfv.to\",\"xiu.to\"], #0\n",
        "    [\"spy\", \"vfv.to\", \"vgg.to\", \"zlu.to\", \"xiu.to\", \"vdy.to\", \"xfn.to\", \"ry.to\", \"td.to\", \"na.to\",\n",
        "      \"slf.to\", \"gwo.to\", \"bce.to\", \"t.to\", \"rci-b.to\", \"enb.to\", \"trp.to\", \"zlb.to\", \"cp.to\"], #1\n",
        "    [\"spy\",\"vfv.to\", \"xiu.to\", \"fie.to\", \"xfn.to\", \"na.to\",\"ry.to\", \"bmo.to\", \"cm.to\", \"bns.to\", \"cwb.to\",\n",
        "      \"slf.to\", \"gwo.to\", \"bce.to\", \"t.to\", \"rci-b.to\", \"enb.to\", \"trp.to\", \"xdv.to\",\"cdz.to\",\"vdy.to\"],  #2\n",
        "    [\"spy\", \"vfv.to\", \"vgg.to\", \"zlu.to\",\"goog\", \"msft\", \"meta\", \"tsla\",\"AMZN\", \"AAPL\", \"shop.to\"],   #3\n",
        "    [\"^IXIC\",\"^GSPC\",\"spy\", \"vfv.to\", \"zsp.to\", \"xsp.to\",\"^GSPTSE\",\"xic.to\",\"xiu.to\",\"xfn.to\",\"fie.to\", \"TX60.TS\"], #4\n",
        "    [\"xic.to\",\"xiu.to\",\"xfn.to\"]  #5\n",
        "]\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 1: fetch retrieve yearly total returns by yfinance & display\n",
        "# Function to fetch data from yfinance and extract yearly total returns\n",
        "def get_annual_returns_df(ticker, calculation_end_date):\n",
        "    # Get the historical data for the given ticker\n",
        "    stock = yf.Ticker(ticker)\n",
        "    calculation_start_date = (datetime.strptime(calculation_end_date, \"%Y-%m-%d\")\n",
        "                - timedelta(days=num_years_calculation * 365)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    # Get today's date, use .strftime(\"%Y-%m-%d\") to convert to a string\n",
        "    today_date=datetime.now(pytz.timezone('America/New_York')).date().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    ''' yfinance_BUG_1 NOTE:\n",
        "    There is bug for  when using end=\"2024-01-02\" on 2024-01-02 which is the first trading of the year on 8:10pm\n",
        "    for using annual_returns_history=stock.history(start=calculation_start_date,end=calculation_end_date)[\"Close\"]\n",
        "     (tried tickers: \"^GSPC\",\"spy\" for stock = yf.Ticker(ticker)) that 2024-01-02 data is not returned.\n",
        "     however, when end parameter, it is fine for returning  2024-01-02 data as below\n",
        "     annual_returns_history=stock.history(start=calculation_start_date)[\"Close\"]\n",
        "    '''\n",
        "    try:\n",
        "        #'try' statement for handlingy the exception error of stock.history that a ticker is not yet at stock market, \"shop.to\" is not there in 2012\n",
        "        # the following if statement for handling yfinance_BUG_1\n",
        "        if (calculation_end_date != today_date):\n",
        "            annual_returns_history=stock.history(start=calculation_start_date,end=calculation_end_date)[\"Close\"]\n",
        "        else:\n",
        "            annual_returns_history=stock.history(start=calculation_start_date)[\"Close\"]\n",
        "\n",
        "        #print(\"debug get_annual_returns_df \", ticker, annual_returns_history)\n",
        "        # Tried resample('A', origin=calculation_end_date),  \"origin=\"\" looks not working.\n",
        "        # For 'A', 'Y', see https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases\n",
        "        annual_returns = annual_returns_history.resample('A').ffill().pct_change().dropna()\n",
        "        #print(\"debug get_annual_returns_df after resample()\", ticker, calculation_end_date, \"\\n\", annual_returns)\n",
        "    except:\n",
        "        return  pd.DataFrame()\n",
        "    else:\n",
        "        annual_returns_df = pd.DataFrame(annual_returns, columns=['Close'])\n",
        "        annual_returns_df.rename(columns={'Close': ticker}, inplace=True)\n",
        "        return annual_returns_df\n",
        "\n",
        "def get_annual_returns_tickers_df(tickers, calculation_end_date):\n",
        "    # Create an empty DataFrame to store all tickers' total returns\n",
        "    all_tickers_returns_df = pd.DataFrame()\n",
        "\n",
        "    # Loop through each ticker in the list\n",
        "    for ticker in tickers:\n",
        "        ticker_returns_df = get_annual_returns_df(ticker, calculation_end_date)\n",
        "        if not ticker_returns_df.empty:\n",
        "            if all_tickers_returns_df.empty:\n",
        "                all_tickers_returns_df = ticker_returns_df\n",
        "            else:\n",
        "                all_tickers_returns_df = pd.concat([all_tickers_returns_df, ticker_returns_df], axis=1)  # Concatenate DataFrames\n",
        "        else:\n",
        "            # New column with NaN values\n",
        "            new_column_name = ticker\n",
        "            new_column_values = [None] * len(all_tickers_returns_df)\n",
        "            new_column = pd.DataFrame({new_column_name: new_column_values}, index=all_tickers_returns_df.index)\n",
        "            # Concatenate the new column to the original DataFrame\n",
        "            all_tickers_returns_df = pd.concat([all_tickers_returns_df, new_column], axis=1)\n",
        "    #return date_label_conversion_strip_time(all_tickers_returns_df, calculation_end_date)\n",
        "    return all_tickers_returns_df\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 2: calculate the annualized trailing total return from the data generated in step 1 & display\n",
        "# Define a function to calculate the annualized trailing total return for a given number of years\n",
        "def get_trailing_return(ticker, data, years):\n",
        "    # Get the total return values for the last n years\n",
        "    trailing_data = data[ticker].tail(years)\n",
        "    # Check if there are empty values within years\n",
        "    if trailing_data.isna().any():\n",
        "        return \"N/A\"\n",
        "    # Check if there are valid total return values for all years\n",
        "    if len(trailing_data) == years:\n",
        "        # Convert the percentage strings to numeric values\n",
        "        trailing_data = trailing_data.astype(str).str.replace('%', '').astype(float)\n",
        "        \"\"\" Calculate the annualized trailing total return using the formula from Investopedia[^1^][1]:\n",
        "            Annualized Return = [(1 + r1) * (1 + r2) * ... * (1 + rn)]^(1/n) - 1\n",
        "            Where r1, r2, ..., rn are the total return values for each year                    \"\"\"\n",
        "        annualized_trailing_return = (trailing_data + 1).prod() ** (1 / years) - 1\n",
        "\n",
        "        # Format the result as a percentage with two decimal places\n",
        "        annualized_trailing_return = annualized_trailing_return * 100\n",
        "        annualized_trailing_return = annualized_trailing_return.round(2)\n",
        "        return annualized_trailing_return\n",
        "    else:\n",
        "        return \"N/A\"\n",
        "\n",
        "# Define a function to Loop through the list and print the trailing returns for each num_years\n",
        "def get_trailing_return_column(ticker, annual_returns_df):\n",
        "    trailing_return_column = {}\n",
        "    for num_years in years_list:\n",
        "        # Check if the ticker data is available in all_tickers_returns_df\n",
        "        if ticker in annual_returns_df.columns:\n",
        "            # using data from step 1, avoiding get_annual_returns_df(ticker) for less traffic from yahoo server\n",
        "            data = annual_returns_df[[ticker]]\n",
        "            trailing_return = get_trailing_return(ticker, data, num_years)\n",
        "            trailing_return_column[f\"{num_years}-Year\"] = trailing_return\n",
        "        else:\n",
        "            print(f\"Data not available for {ticker}. Skipping.\")\n",
        "            trailing_return_column[f\"{num_years}-Year\"] = \"N/A\"\n",
        "    return trailing_return_column\n",
        "\n",
        "# Create an empty DataFrame to store all tickers' trailing returns\n",
        "def get_trailing_return_all(tickers, annual_returns_df):\n",
        "    all_tickers_trailing_returns_df = pd.DataFrame(index=years_list)\n",
        "\n",
        "    # Loop through each ticker in the list\n",
        "    for ticker in tickers:\n",
        "        trailing_returns = get_trailing_return_column(ticker, annual_returns_df)\n",
        "        # Add the trailing returns to the DataFrame\n",
        "        all_tickers_trailing_returns_df[ticker] = pd.Series(trailing_returns).values\n",
        "    return all_tickers_trailing_returns_df\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 3: calculate the cumulative return from the data (all_tickers_returns_df) generated in step 1 & display\n",
        "# 4.1 Define a function to calculate the cumulative return for a given number of years from a ticker\n",
        "def get_cumulative_return(ticker, data, years):\n",
        "    # Calculate the cumulative return\n",
        "    cumulative_return = (1 + data[ticker]).rolling(window=years).apply(lambda x: x.prod(), raw=True) - 1\n",
        "    return cumulative_return\n",
        "\n",
        "# Define a function to Loop through the list and return the cumulative returns for each num_years\n",
        "def get_cumulative_return_column(ticker, annual_returns_df):\n",
        "    cumulative_returns = {}\n",
        "    for years in years_list:\n",
        "        # Calculate the cumulative return for the given number of years\n",
        "        cumulative_return = get_cumulative_return(ticker, annual_returns_df, years)\n",
        "        # Get the last value, which is the cumulative return up to the current year\n",
        "        cumulative_returns[years] = cumulative_return.iloc[-1]\n",
        "    return cumulative_returns\n",
        "\n",
        "def get_cumulative_return_all(tickers, annual_returns_df):\n",
        "    # Create an empty DataFrame with years_list as the index for cumulative  returns\n",
        "    all_tickers_cumulative_returns_df = pd.DataFrame(index=years_list)\n",
        "    # Loop through each ticker in the list\n",
        "    for ticker in tickers:\n",
        "        cumulative_returns = get_cumulative_return_column(ticker, annual_returns_df)\n",
        "        # Add the trailing returns to the DataFrame\n",
        "        all_tickers_cumulative_returns_df[ticker] = pd.Series(cumulative_returns).values\n",
        "    return all_tickers_cumulative_returns_df\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 4: calculate the  CAGR (Compound Annual Growth Rate) from the data\n",
        "# in all_tickers_cumulative_returns_df generated earlier & display\n",
        "# Define a function to calculate the CAGR from the cumulative value and the years\n",
        "def calculate_cagr(value, years):\n",
        "    # Otherwise, calculate the CAGR using the formula\n",
        "    cagr = (value + 1) ** (1 / np.array(years)) - 1\n",
        "    #print(\"debug-cagr\\n\", cagr, \"end\")\n",
        "    return cagr\n",
        "\n",
        "# Define a function to format the Float64Index values into percentage strings\n",
        "def format_to_percentage(value):\n",
        "    # If any element in the value array is not null, format it as a percentage string with two decimal places\n",
        "    if np.any(pd.notnull(value)):\n",
        "        return f\"{value:.2f}%\"\n",
        "    # Otherwise, return None\n",
        "    return None\n",
        "\n",
        "def get_cagr_return_all(all_tickers_cumulative_returns_df):\n",
        "    # Apply the calculate_cagr function to each column of the DataFrame\n",
        "    all_tickers_cagrs_df = all_tickers_cumulative_returns_df.apply(lambda x: calculate_cagr(x, x.index), axis=0)\n",
        "    return all_tickers_cagrs_df\n",
        "\n",
        "#---------------------------------------------------------------\n",
        "# utility functions\n",
        "# get the last trading day of S&P 500 in string format\n",
        "def get_last_trading_day():\n",
        "    # Get today's date, use .strftime(\"%Y-%m-%d\") to convert to a string\n",
        "    #calculation_end_date=datetime.now(pytz.timezone('America/New_York')).date().strftime(\"%Y-%m-%d\")\n",
        "    today_date_str=datetime.now(pytz.timezone('America/New_York')).date().strftime(\"%Y-%m-%d\")\n",
        "    stock = yf.Ticker(\"^GSPC\") # S&P 500 (^GSPC) ticker\n",
        "    #  search and see yfinance_BUG_1 NOTE in this file\n",
        "    history_df=stock.history(period=\"max\", end=today_date_str)[\"Close\"]\n",
        "    calculation_end_date_str = history_df.index.max().date().strftime(\"%Y-%m-%d\")\n",
        "    return calculation_end_date_str\n",
        "\n",
        "def str_to_integer(integer_str):\n",
        "    try:\n",
        "        integer_number = int(integer_str)\n",
        "        return integer_number\n",
        "    except ValueError:\n",
        "        return -1\n",
        "\n",
        "# validate the date string\n",
        "def is_valid_date(date_string):\n",
        "    try:\n",
        "        # Attempt to parse the date string\n",
        "        datetime.strptime(date_string, \"%Y-%m-%d\")\n",
        "        return True\n",
        "    except ValueError:\n",
        "        # Raised when the date string is not in the expected format\n",
        "        return False\n",
        "\n",
        "def date_label_conversion_strip_time(all_tickers_returns_df, calculation_end_date):\n",
        "    all_tickers_returns_df.index=all_tickers_returns_df.index.date\n",
        "    all_tickers_returns_df.index.name='date'\n",
        "    # print(\"debug get_annual_returns_tickers_df\", all_tickers_returns_df)\n",
        "    # Convert calculation_end_date to a datetime object, replace the index's mon/day portion of date\n",
        "    calculation_end_date_datetime_obj = datetime.strptime(calculation_end_date, \"%Y-%m-%d\")\n",
        "    all_tickers_returns_df.index = all_tickers_returns_df.index.map(\n",
        "      lambda x: x.replace(month=calculation_end_date_datetime_obj.month,\n",
        "      day=calculation_end_date_datetime_obj.day))\n",
        "    return all_tickers_returns_df\n",
        "\n",
        "help_info_str=\"Input Formats:\\n  \\\n",
        "            1. ticker list....................Example:  spy vfv.to xiu.to xic.to xfn.to ry.to \\n \\\n",
        "            2. One of default ticker list, a number between 1 and 5....Example:   0, or 1, ...,5 \\n \\\n",
        "            3. CalculationEndDate as prefix.  Example:   2020-12-31 2 \\n \\\n",
        "            .........................................2020-12-31 spy vfv.to xiu.to xic.to xfn.to ry.to \\n \\\n",
        "            note: daily adjusted close data are from Yahoo Finance. \"\n",
        "\n",
        "#---------------------------------------------------------------\n",
        "# step 5:  Display in web page using gradio\n",
        "# Gradio Web interface\n",
        "def calculation_response(message, history):\n",
        "    # if there is no input, display help information\n",
        "    if message==\"\":\n",
        "        return help_info_str\n",
        "\n",
        "    tickers=message.split()\n",
        "\n",
        "    # -----------\n",
        "    #  set calculation_end_date\n",
        "    # Get today's date, use .strftime(\"%Y-%m-%d\") to convert to a string\n",
        "    #calculation_end_date=datetime.now(pytz.timezone('America/New_York')).date().strftime(\"%Y-%m-%d\")\n",
        "    calculation_end_date = get_last_trading_day()\n",
        "    # Check whether the first str is date for calculation end date\n",
        "    if is_valid_date(tickers[0]):\n",
        "        calculation_end_date = tickers[0] # reset calculation_end_date\n",
        "        tickers.pop(0) # remove the first string which is the date\n",
        "\n",
        "    # Check whether numebr 0, 1, 2, .. is selected for using a default ticker list\n",
        "    integer_value=str_to_integer(tickers[0])\n",
        "    if (integer_value >= 0 and integer_value <len(tickers_lists)):\n",
        "        tickers=tickers_lists[integer_value]\n",
        "\n",
        "    # if no tickers were set, display help information\n",
        "    if len(tickers)==0:\n",
        "        return help_info_str\n",
        "\n",
        "    #---------------\n",
        "    # Calculating Annual, Trailing, Cumulative, and CAGR & generating html for display\n",
        "    # annual_returns\n",
        "    output_string = f\"\\nAnnual Total Return (%) as {calculation_end_date}\\n\"\n",
        "    annual_returns_dataframe=get_annual_returns_tickers_df(tickers, calculation_end_date)\n",
        "    output_dataframe = annual_returns_dataframe.round(4)*100\n",
        "    output_dataframe.index=output_dataframe.index.year\n",
        "    # Convert the DataFrame to HTML, Combine the expected string outputs\n",
        "    output_html1 = output_string + output_dataframe.to_html()\n",
        "\n",
        "    # Removing the current year's data\n",
        "    today_date=datetime.now(pytz.timezone('America/New_York')).date()\n",
        "    all_tickers_returns_all_years_df=annual_returns_dataframe\n",
        "    if (annual_returns_dataframe.index.max().year == today_date.year):\n",
        "        annual_returns_dataframe=annual_returns_dataframe[annual_returns_dataframe.index.year < today_date.year]\n",
        "        month_date = \"12-31\"\n",
        "        calculation_end_date = f\"{annual_returns_dataframe.index.max().year}-{month_date}\"\n",
        "\n",
        "    # Trailing Return\n",
        "    output_string2 = f\"\\nTrailing Total Return (%) as {calculation_end_date}\\n\"\n",
        "    output_dataframe2=get_trailing_return_all(tickers, annual_returns_dataframe)\n",
        "    output_dataframe2.index.name=\"years\"\n",
        "    output_html2=output_string2 + output_dataframe2.to_html()\n",
        "\n",
        "    # Cumulative Return\n",
        "    output_string3 = f\"\\nCumulative Return (%) as {calculation_end_date}\\n\"\n",
        "    cumulative_return_all_dataframe=get_cumulative_return_all(tickers, annual_returns_dataframe)\n",
        "    output_dataframe3=cumulative_return_all_dataframe.round(4)*100\n",
        "    output_dataframe3.index.name=\"years\"\n",
        "    output_html3=output_string3 + output_dataframe3.to_html()\n",
        "\n",
        "    # CAGR Return\n",
        "    output_string4 = f\"\\nCompound Annual Growth Rate (CAGR) (%) as {calculation_end_date}\\n\"\n",
        "    output_dataframe4=get_cagr_return_all (cumulative_return_all_dataframe)\n",
        "    output_dataframe4=output_dataframe4.round(4)*100\n",
        "    output_html4=output_string4 + output_dataframe4.to_html()\n",
        "\n",
        "    #output_html = output_html1 + output_html2 + output_html3 + output_html4\n",
        "    output_html = output_html1 + output_html2 + output_html3\n",
        "    return  output_html\n",
        "\n",
        "demo = gr.ChatInterface(calculation_response)\n",
        "demo.launch(debug=False, share=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1lqgNnpDtiN"
      },
      "source": [
        "# Example 4: Calendar-year based - Yearly Total Return, Annualized Trailing return, Cumulative Returns & Compound Annual Growth Rate (GAGR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5Heh6grEDAv",
        "outputId": "ace34dba-39c1-4823-d476-0804c6a37e66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The result of version-(2024-01-04) script  start:\n",
            " ###\n",
            "\n",
            "Annual Total Return (%) as year 2024\n",
            "        spy  vfv.to  vgg.to  zlu.to  xiu.to  xfn.to  ry.to  td.to   na.to  \\\n",
            "year                                                                        \n",
            "1994   0.40     NaN     NaN     NaN     NaN     NaN    NaN    NaN     NaN   \n",
            "1995  38.05     NaN     NaN     NaN     NaN     NaN    NaN    NaN     NaN   \n",
            "1996  22.50     NaN     NaN     NaN     NaN     NaN  59.20  52.30   29.73   \n",
            "1997  33.48     NaN     NaN     NaN     NaN     NaN  61.23  56.87   75.97   \n",
            "1998  28.69     NaN     NaN     NaN     NaN     NaN   3.58   2.50    7.92   \n",
            "1999  20.39     NaN     NaN     NaN     NaN     NaN -14.82  46.56  -22.65   \n",
            "2000  -9.74     NaN     NaN     NaN    8.02     NaN  65.34  14.84   43.78   \n",
            "2001 -11.76     NaN     NaN     NaN  -14.24     NaN   4.90  -2.81   11.65   \n",
            "2002 -21.58     NaN     NaN     NaN  -14.02   -3.06  14.85 -14.56    8.75   \n",
            "2003  28.18     NaN     NaN     NaN   24.82   26.14   9.13  31.37   35.63   \n",
            "2004  10.70     NaN     NaN     NaN   13.28   18.57   7.38  18.83   18.76   \n",
            "2005   4.83     NaN     NaN     NaN   25.47   22.90  45.87  26.19   25.57   \n",
            "2006  15.85     NaN     NaN     NaN   19.12   17.79  26.02  16.55   12.71   \n",
            "2007   5.15     NaN     NaN     NaN   10.83   -1.44  -5.57   2.66  -17.21   \n",
            "2008 -36.79     NaN     NaN     NaN  -31.09  -35.98 -25.70 -35.15  -36.68   \n",
            "2009  26.35     NaN     NaN     NaN   31.35   44.58  63.73  59.16  101.42   \n",
            "2010  15.06     NaN     NaN     NaN   13.85    7.90  -3.85  16.52   18.31   \n",
            "2011   1.89     NaN     NaN     NaN   -9.31   -4.41   3.31   6.22    9.41   \n",
            "2012  15.99     NaN     NaN     NaN    7.92   16.44  20.06  13.80   11.61   \n",
            "2013  32.31   40.91     NaN     NaN   13.06   26.00  24.05  24.13   19.48   \n",
            "2014  13.46   24.05   21.49   37.61   11.94   11.88  16.64  14.83   16.48   \n",
            "2015   1.23   20.29   14.58   24.17   -7.80   -3.71  -3.81   1.42  -14.56   \n",
            "2016  12.00    7.63    7.28    5.11   20.32   23.38  27.84  26.92   41.68   \n",
            "2017  21.71   13.68   13.99    5.06    9.58   12.54  17.12  15.15   19.77   \n",
            "2018  -4.57    2.94    5.20    8.39   -7.82   -9.76  -5.50  -4.57   -6.92   \n",
            "2019  31.22   25.15   23.32   20.48   21.81   20.66  14.33  11.66   34.04   \n",
            "2020  18.33   15.61   12.67    1.56    5.27    0.99   6.52   3.72    2.65   \n",
            "2021  28.73   27.51   22.23   20.72   28.06   35.57  33.09  40.15   39.02   \n",
            "2022 -18.18  -12.58   -4.21    7.94   -6.35   -9.92  -1.52  -6.01   -1.45   \n",
            "2023  26.18   23.23   11.58   -3.26   11.85   13.09   9.80   1.10   15.53   \n",
            "2024  -1.37   -0.63    0.00    1.98   -0.41   -1.15  -0.31  -0.76   -0.92   \n",
            "\n",
            "      cm.to  slf.to  gwo.to  bce.to   t.to  rci-b.to  enb.to  trp.to  zlb.to  \n",
            "year                                                                          \n",
            "1994    NaN     NaN     NaN     NaN    NaN       NaN     NaN     NaN     NaN  \n",
            "1995    NaN     NaN     NaN     NaN    NaN       NaN     NaN     NaN     NaN  \n",
            "1996  54.45     NaN     NaN     NaN  24.41    -33.77   32.52   30.92     NaN  \n",
            "1997  51.82     NaN     NaN   52.22  56.17    -31.68   71.09   37.26     NaN  \n",
            "1998 -12.17     NaN     NaN   24.40  -4.06     97.83   11.59  -27.43     NaN  \n",
            "1999  -5.92     NaN     NaN  130.73 -12.46    158.61  -15.71  -40.61     NaN  \n",
            "2000  38.81     NaN     NaN   42.94  21.36    -28.22   58.66   44.57     NaN  \n",
            "2001  20.56  -13.63     NaN  -14.16 -39.27      7.19    2.82   19.65     NaN  \n",
            "2002 -17.74  -19.87     NaN  -17.56 -25.07    -45.94    1.48   19.25     NaN  \n",
            "2003  51.72   23.78   25.64    5.65  52.83     46.26   30.48   25.88     NaN  \n",
            "2004  16.77   27.27   20.62    4.44  42.95     47.75   15.17   10.31     NaN  \n",
            "2005   9.63   19.14   18.24    0.79  34.88     56.94   25.51   27.54     NaN  \n",
            "2006  32.92    8.15   13.56   17.88  14.49     41.45   14.40   14.94     NaN  \n",
            "2007 -25.56   15.88    8.41   31.36  -4.93     30.88    2.63    3.49     NaN  \n",
            "2008 -23.14  -46.96  -39.47  -34.98 -21.45    -15.97    2.01  -14.92     NaN  \n",
            "2009  41.60   12.47   37.32   22.58  -2.85     -7.15   27.48   14.28     NaN  \n",
            "2010  20.34    4.70    3.02   28.68  39.93      9.64   19.66    9.54     NaN  \n",
            "2011  -1.31  -33.66  -18.54   26.82  32.22     18.00   39.75   22.03     NaN  \n",
            "2012  13.68   48.51   26.08    5.77  17.54     19.77   16.23    9.89     NaN  \n",
            "2013  18.85   48.78   40.18   13.57  16.74     10.49   10.92    7.38   20.71  \n",
            "2014  14.59   14.75    6.64   21.76  18.98     -2.06   32.31   21.94   28.36  \n",
            "2015  -4.25    6.77    6.64    5.28  -4.95     10.31  -20.43  -17.44    2.73  \n",
            "2016  25.91   23.87    6.04   13.66  16.77     12.57   28.05   39.37   13.03  \n",
            "2017  17.02    4.39    4.08    9.18  16.35     27.57   -8.84    5.23   11.07  \n",
            "2018 -12.96   -9.44  -15.76   -5.65  -0.66     12.53   -8.30  -16.01   -2.76  \n",
            "2019  12.03   35.86   24.53   17.39  16.30     -5.06   29.43   48.49   21.92  \n",
            "2020   6.99   -0.52   -2.64   -3.92   5.23     -4.94  -15.30  -20.74    0.66  \n",
            "2021  41.53   28.82   31.45   27.90  23.58      5.03   29.98   20.34   22.93  \n",
            "2022 -21.70   -6.73  -12.58   -4.33  -8.27      8.69   13.96   -2.76   -0.35  \n",
            "2023  23.83   14.37   47.70   -6.21  -4.41      1.25   -3.27    3.02    9.41  \n",
            "2024  -0.99   -0.57   -0.62    4.06   1.48      0.50    2.12    1.99   -0.76  \n",
            "\n",
            "Annualized Trailing Returns as end of year 2023 :\n",
            "         spy vfv.to vgg.to zlu.to xiu.to xfn.to  ry.to  td.to  na.to  cm.to  \\\n",
            "Years                                                                         \n",
            "1      26.18  23.23  11.58  -3.26  11.85  13.09    9.8    1.1  15.53  23.83   \n",
            "2       1.61   3.79   3.38   2.19   2.35   0.93   3.99  -2.52    6.7  -1.54   \n",
            "3       9.95  11.16   9.32   8.03  10.29  11.37   12.9  10.02  16.54  11.12   \n",
            "5      15.59  14.72  12.66   9.05  11.46  10.97  11.87   9.05  16.84  10.46   \n",
            "10     11.92  14.08  12.51  12.18   7.99   8.55  10.77   9.62  13.09   8.75   \n",
            "15     13.86    N/A    N/A    N/A   8.86  11.28  13.56  13.82  17.95   11.7   \n",
            "20      9.61    N/A    N/A    N/A   7.95   8.78  11.81  11.03  12.47   8.51   \n",
            "25      7.46    N/A    N/A    N/A    N/A    N/A  12.07  11.41  12.55   9.67   \n",
            "30     10.03    N/A    N/A    N/A    N/A    N/A    N/A    N/A    N/A    N/A   \n",
            "\n",
            "      slf.to gwo.to bce.to   t.to rci-b.to enb.to trp.to zlb.to  \n",
            "Years                                                            \n",
            "1      14.37   47.7  -6.21  -4.41     1.25  -3.27   3.02   9.41  \n",
            "2       3.28  13.63  -5.28  -6.36     4.91   4.99   0.09   4.41  \n",
            "3      11.18  19.28    4.7   2.71     4.95  12.73   6.43  10.25  \n",
            "5      13.18  15.52    5.3   5.81     0.85   9.45   7.25  10.46  \n",
            "10      10.3   8.08   6.87   7.31     6.18   5.88   5.81  10.23  \n",
            "15     10.71  10.43  10.82  11.31     7.34  11.12    8.0    N/A  \n",
            "20      7.97   8.06   8.32  11.11    12.45  11.24   7.83    N/A  \n",
            "25       N/A    N/A  10.52   7.49    11.85  11.54   8.07    N/A  \n",
            "30       N/A    N/A    N/A    N/A      N/A    N/A    N/A    N/A  \n",
            "\n",
            "Cumulative Returns as end of year 2023 :\n",
            "           spy  vfv.to  vgg.to  zlu.to  xiu.to  xfn.to    ry.to    td.to  \\\n",
            "Years                                                                      \n",
            "1        26.18   23.23   11.58   -3.26   11.85   13.09     9.80     1.10   \n",
            "2         3.24    7.73    6.88    4.42    4.75    1.88     8.13    -4.98   \n",
            "3        32.90   37.36   30.63   26.06   34.14   38.12    43.91    33.17   \n",
            "5       106.37   98.74   81.50   54.25   72.01   68.30    75.25    54.23   \n",
            "10      208.35  273.46  225.03  215.51  115.76  127.18   178.20   150.49   \n",
            "15      600.96     NaN     NaN     NaN  257.06  397.03   573.77   597.05   \n",
            "20      526.23     NaN     NaN     NaN  361.73  438.33   833.13   711.00   \n",
            "25      503.55     NaN     NaN     NaN     NaN     NaN  1627.90  1389.04   \n",
            "30     1660.14     NaN     NaN     NaN     NaN     NaN      NaN      NaN   \n",
            "\n",
            "         na.to   cm.to  slf.to  gwo.to   bce.to    t.to  rci-b.to   enb.to  \\\n",
            "Years                                                                        \n",
            "1        15.53   23.83   14.37   47.70    -6.21   -4.41      1.25    -3.27   \n",
            "2        13.86   -3.05    6.68   29.12   -10.27  -12.31     10.05    10.23   \n",
            "3        58.29   37.21   37.43   69.72    14.76    8.36     15.58    43.28   \n",
            "5       117.78   64.47   85.72  105.77    29.44   32.62      4.31    57.06   \n",
            "10      242.30  131.43  166.44  117.56    94.28  102.43     82.10    76.99   \n",
            "15     1090.08  425.89  359.93  343.07   366.82  399.19    189.51   386.40   \n",
            "20      948.63  411.97  363.62  370.91   394.66  723.02    944.31   742.15   \n",
            "25     1820.79  906.04     NaN     NaN  1119.73  508.08   1543.01  1433.32   \n",
            "30         NaN     NaN     NaN     NaN      NaN     NaN       NaN      NaN   \n",
            "\n",
            "       trp.to  zlb.to  \n",
            "Years                  \n",
            "1        3.02    9.41  \n",
            "2        0.18    9.02  \n",
            "3       20.55   34.02  \n",
            "5       41.89   64.46  \n",
            "10      75.95  164.73  \n",
            "15     217.18     NaN  \n",
            "20     351.60     NaN  \n",
            "25     596.32     NaN  \n",
            "30        NaN     NaN  \n",
            "\n",
            "Compound Annual Growth Rates (GAGRs) (%) as end of year 2023 :\n",
            "         spy  vfv.to  vgg.to  zlu.to  xiu.to  xfn.to  ry.to  td.to  na.to  \\\n",
            "Years                                                                       \n",
            "1      26.18   23.23   11.58   -3.26   11.85   13.09   9.80   1.10  15.53   \n",
            "2       1.61    3.79    3.38    2.19    2.35    0.93   3.99  -2.52   6.70   \n",
            "3       9.95   11.16    9.32    8.03   10.29   11.37  12.90  10.02  16.54   \n",
            "5      15.59   14.72   12.66    9.05   11.46   10.97  11.87   9.05  16.84   \n",
            "10     11.92   14.08   12.51   12.18    7.99    8.55  10.77   9.62  13.09   \n",
            "15     13.86     NaN     NaN     NaN    8.86   11.28  13.56  13.82  17.95   \n",
            "20      9.61     NaN     NaN     NaN    7.95    8.78  11.81  11.03  12.47   \n",
            "25      7.46     NaN     NaN     NaN     NaN     NaN  12.07  11.41  12.55   \n",
            "30     10.03     NaN     NaN     NaN     NaN     NaN    NaN    NaN    NaN   \n",
            "\n",
            "       cm.to  slf.to  gwo.to  bce.to   t.to  rci-b.to  enb.to  trp.to  zlb.to  \n",
            "Years                                                                          \n",
            "1      23.83   14.37   47.70   -6.21  -4.41      1.25   -3.27    3.02    9.41  \n",
            "2      -1.54    3.28   13.63   -5.28  -6.36      4.91    4.99    0.09    4.41  \n",
            "3      11.12   11.18   19.28    4.70   2.71      4.95   12.73    6.43   10.25  \n",
            "5      10.46   13.18   15.52    5.30   5.81      0.85    9.45    7.25   10.46  \n",
            "10      8.75   10.30    8.08    6.87   7.31      6.18    5.88    5.81   10.23  \n",
            "15     11.70   10.71   10.43   10.82  11.31      7.34   11.12    8.00     NaN  \n",
            "20      8.51    7.97    8.06    8.32  11.11     12.45   11.24    7.83     NaN  \n",
            "25      9.67     NaN     NaN   10.52   7.49     11.85   11.54    8.07     NaN  \n",
            "30       NaN     NaN     NaN     NaN    NaN       NaN     NaN     NaN     NaN  \n",
            "The result of version-(2024-01-04) script  ends here.\n",
            " ###\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "### CODE start (for AI tool)\n",
        "Retrieve multiple tickers for total returns and trailing total returns from yahoo\n",
        "History:\n",
        "Author: Gang Luo\n",
        "\"\"\"\n",
        "result_marker='###'\n",
        "script_version = '(2024-01-04)'\n",
        "print(f\"The result of version-{script_version} script  start:\\n {result_marker}\")\n",
        "#!pip install yfinance\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "print_yearly_total_return = True\n",
        "\n",
        "# Set the stock tickers list\n",
        "tickers_list1 = [\"spy\", \"vfv.to\", \"vgg.to\", \"zlu.to\", \"xiu.to\", \"xfn.to\", \"ry.to\", \"td.to\", \"na.to\",\n",
        " \"cm.to\", \"slf.to\", \"gwo.to\", \"bce.to\", \"t.to\", \"rci-b.to\", \"enb.to\", \"trp.to\", \"zlb.to\"]\n",
        "tickers_list2 = [\"vfv.to\", \"xiu.to\", \"xic.to\", \"xfn.to\", \"ry.to\", \"td.to\", \"na.to\",\n",
        "                \"bns.to\", \"bmo.to\", \"cm.to\", \"cwb.to\", \"slf.to\", \"gwo.to\"]\n",
        "tickers_list3 = [\"spy\", \"vfv.to\", \"xfn.to\", \"ry.to\"]\n",
        "tickers_list = tickers_list1\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 1: fetch retrieve yearly total returns by yfinance & display\n",
        "# Function to fetch data from yfinance and extract yearly total returns\n",
        "def get_annual_returns_df(ticker):\n",
        "    # Get the historical data for the given ticker\n",
        "    stock = yf.Ticker(ticker)\n",
        "    ''' Get annual total return data.   Explanation the following statement\n",
        "    1.  'Close'  in .\n",
        "    Ticker(ticker).history is the same as 'Adj Close' in .download(ticker, ...)\n",
        "        print(df.columns.tolist()) - Display all column names of DataFrame\n",
        "        yf.Ticker(ticker).history: ['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
        "        yf.download(ticker, ...): ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
        "    2.  [\"Close\"]: Selects the \"Close\" column from the historical stock data.\n",
        "        .resample('Y'): Resamples the time series data annually ('Y'), based on the last trading day of each year.\n",
        "        .resample('A'): Resamples the time series data annually ('A'), based on the any trading day of each year.\n",
        "        .ffill(): Forward fills missing values, ensuring that each annual period has a value.\n",
        "        .pct_change(): Calculates the percentage change between the current and previous values, representing the annual returns.\n",
        "        .dropna(): Removes any rows with missing values (which may occur after calculating percentage changes).\n",
        "    '''\n",
        "    annual_returns = stock.history(period=\"max\")[\"Close\"].resample('Y').ffill().pct_change().dropna()\n",
        "    annual_returns_df = pd.DataFrame(annual_returns, columns=['Close'])\n",
        "    annual_returns_df.rename(columns={'Close': ticker}, inplace=True)\n",
        "    return annual_returns_df\n",
        "# Create an empty DataFrame to store all tickers' total returns\n",
        "all_tickers_returns_df = pd.DataFrame()\n",
        "\n",
        "# Loop through each ticker in the list\n",
        "for ticker in tickers_list:\n",
        "    ticker_returns_df = get_annual_returns_df(ticker)\n",
        "    if not ticker_returns_df.empty:\n",
        "        if all_tickers_returns_df.empty:\n",
        "            all_tickers_returns_df = ticker_returns_df\n",
        "        else:\n",
        "            all_tickers_returns_df = pd.concat([all_tickers_returns_df, ticker_returns_df], axis=1)  # Concatenate DataFrames\n",
        "\n",
        "# Display the results if the DataFrame is not empty\n",
        "\n",
        "if all_tickers_returns_df.empty:\n",
        "    print(\"No data available for the specified tickers.\")\n",
        "\n",
        "#print(\"\\nAnnual Total Return (%) History:\")\n",
        "# keep the date portion of index only - stripping time portion\n",
        "#all_tickers_returns_df.index=all_tickers_returns_df.index.date\n",
        "#print(all_tickers_returns_df)\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 2:\n",
        "# Define a list of years to calculate the trailing returns, cumulative returns, and so on\n",
        "# remove the row of current year row since it is not a full year.\n",
        "years_list = [1, 2, 3, 5, 10, 15, 20, 25, 30]\n",
        "current_year=all_tickers_returns_df.index.year.max()\n",
        "all_tickers_returns_with_current_year_df=all_tickers_returns_df\n",
        "all_tickers_returns_df=all_tickers_returns_df[all_tickers_returns_df.index.year < current_year]\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 3: calculate the annualized trailing total return from the data generated in step 1 & display\n",
        "# Define a function to calculate the annualized trailing total return for a given number of years\n",
        "def get_trailing_return(ticker, data, years):\n",
        "    # Get the total return values for the last n years\n",
        "    trailing_data = data[ticker].tail(years)\n",
        "    # Check if there are empty values within years\n",
        "    if trailing_data.isna().any():\n",
        "        return \"N/A\"\n",
        "    # Check if there are valid total return values for all years\n",
        "    if len(trailing_data) == years:\n",
        "        # Convert the percentage strings to numeric values\n",
        "        trailing_data = trailing_data.astype(str).str.replace('%', '').astype(float)\n",
        "        \"\"\" Calculate the annualized trailing total return using the formula from Investopedia[^1^][1]:\n",
        "            Annualized Return = [(1 + r1) * (1 + r2) * ... * (1 + rn)]^(1/n) - 1\n",
        "            Where r1, r2, ..., rn are the total return values for each year                    \"\"\"\n",
        "        annualized_trailing_return = (trailing_data + 1).prod() ** (1 / years) - 1\n",
        "\n",
        "        # Format the result as a percentage with two decimal places\n",
        "        annualized_trailing_return = annualized_trailing_return * 100\n",
        "        annualized_trailing_return = annualized_trailing_return.round(2)\n",
        "        return annualized_trailing_return\n",
        "    else:\n",
        "        return \"N/A\"\n",
        "\n",
        "# Define a function to Loop through the list and print the trailing returns for each num_years\n",
        "def get_trailing_return_column(ticker):\n",
        "    trailing_return_column = {}\n",
        "    for num_years in years_list:\n",
        "        # Check if the ticker data is available in all_tickers_returns_df\n",
        "        if ticker in all_tickers_returns_df.columns:\n",
        "            # using data from step 1, avoiding get_annual_returns_df(ticker) for less traffic from yahoo server\n",
        "            data = all_tickers_returns_df[[ticker]]\n",
        "            trailing_return = get_trailing_return(ticker, data, num_years)\n",
        "            trailing_return_column[f\"{num_years}-Year\"] = trailing_return\n",
        "        else:\n",
        "            print(f\"Data not available for {ticker}. Skipping.\")\n",
        "            trailing_return_column[f\"{num_years}-Year\"] = \"N/A\"\n",
        "    return trailing_return_column\n",
        "\n",
        "# Create an empty DataFrame to store all tickers' trailing returns\n",
        "all_tickers_trailing_returns_df = pd.DataFrame(index=years_list)\n",
        "\n",
        "# Loop through each ticker in the list\n",
        "for ticker in tickers_list:\n",
        "    trailing_returns = get_trailing_return_column(ticker)\n",
        "    # Add the trailing returns to the DataFrame\n",
        "    all_tickers_trailing_returns_df[ticker] = pd.Series(trailing_returns).values\n",
        "\n",
        "# Display the trailing returns DataFrame\n",
        "#print(\"\\nAnnualized Trailing Returns as end of year\", current_year-1, \":\")\n",
        "#print(\"years\")\n",
        "#print(all_tickers_trailing_returns_df)\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 4: calculate the cumulative return from the data (all_tickers_returns_df) generated in step 1 & display\n",
        "# 4.1 Define a function to calculate the cumulative return for a given number of years from a ticker\n",
        "def get_cumulative_return(ticker, data, years):\n",
        "    # Calculate the cumulative return\n",
        "    cumulative_return = (1 + data[ticker]).rolling(window=years).apply(lambda x: x.prod(), raw=True) - 1\n",
        "    return cumulative_return\n",
        "\n",
        "# Create an empty DataFrame with years_list as the index for cumulative  returns\n",
        "all_tickers_cumulative_returns_df = pd.DataFrame(index=years_list)\n",
        "\n",
        "# Define a function to Loop through the list and return the cumulative returns for each num_years\n",
        "def get_cumulative_return_column(ticker):\n",
        "    cumulative_returns = {}\n",
        "    for years in years_list:\n",
        "        # Calculate the cumulative return for the given number of years\n",
        "        cumulative_return = get_cumulative_return(ticker, all_tickers_returns_df, years)\n",
        "        # Get the last value, which is the cumulative return up to the current year\n",
        "        cumulative_returns[years] = cumulative_return.iloc[-1]\n",
        "    return cumulative_returns\n",
        "\n",
        "# Loop through each ticker in the list\n",
        "for ticker in tickers_list:\n",
        "    cumulative_returns = get_cumulative_return_column(ticker)\n",
        "    # Add the trailing returns to the DataFrame\n",
        "    all_tickers_cumulative_returns_df[ticker] = pd.Series(cumulative_returns).values\n",
        "\n",
        "# Display the cumulative returns DataFrame\n",
        "#print(\"\\nCumulative Returns as end of year\", current_year-1, \":\")\n",
        "#print(\"years\")\n",
        "#print(all_tickers_cumulative_returns_df.round(4) * 100)\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 5: calculate the  CAGR from the data (all_tickers_cumulative_returns_df) generated earlier & display\n",
        "# Define a function to calculate the CAGR from the cumulative value and the years\n",
        "import numpy as np\n",
        "def calculate_cagr(value, years):\n",
        "    # Otherwise, calculate the CAGR using the formula\n",
        "    cagr = (value + 1) ** (1 / np.array(years)) - 1\n",
        "    #print(\"debug-cagr\\n\", cagr, \"end\")\n",
        "    return cagr\n",
        "\n",
        "# Define a function to format the Float64Index values into percentage strings\n",
        "def format_to_percentage(value):\n",
        "    # If any element in the value array is not null, format it as a percentage string with two decimal places\n",
        "    if np.any(pd.notnull(value)):\n",
        "        return f\"{value:.2f}%\"\n",
        "    # Otherwise, return None\n",
        "    return None\n",
        "\n",
        "# Apply the calculate_cagr function to each column of the DataFrame\n",
        "all_tickers_cagrs_df = all_tickers_cumulative_returns_df.apply(lambda x: calculate_cagr(x, x.index), axis=0)\n",
        "\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Display the formatted DataFrame  all_tickers_returns_df\n",
        "print(\"\\nAnnual Total Return (%) as year\", current_year)\n",
        "if (print_yearly_total_return):\n",
        "    all_tickers_returns_with_current_year_df.index=all_tickers_returns_with_current_year_df.index.year\n",
        "    all_tickers_returns_with_current_year_df.index.name='year'\n",
        "    print(all_tickers_returns_with_current_year_df.round(4) * 100)\n",
        "\n",
        "# Display the trailing returns DataFrame\n",
        "print(\"\\nAnnualized Trailing Returns as end of year\", current_year-1, \":\")\n",
        "all_tickers_trailing_returns_df.index.name = 'Years'\n",
        "print(all_tickers_trailing_returns_df)\n",
        "\n",
        "# Display the cumulative returns DataFrame\n",
        "print(\"\\nCumulative Returns as end of year\", current_year-1, \":\")\n",
        "all_tickers_cumulative_returns_df.index.name = 'Years'\n",
        "print(all_tickers_cumulative_returns_df.round(4) * 100)\n",
        "\n",
        "\n",
        "# Display the formatted DataFrame  all_tickers_cagrs_df\n",
        "print(\"\\nCompound Annual Growth Rates (GAGRs) (%) as end of year\", current_year-1, \":\")\n",
        "all_tickers_cagrs_df.index.name = 'Years'\n",
        "print(all_tickers_cagrs_df.round(4) * 100)\n",
        "\n",
        "\n",
        "# print an indicator to mark the end of execution result\n",
        "print(f\"The result of version-{script_version} script  ends here.\\n {result_marker}\")\n",
        "### CODE end (for AI tool)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yadi4ykCr9uI"
      },
      "source": [
        "##  backup - Example 4: Calendar-year based - Yearly Total Return, Annualized Trailing return, Cumulative Returns & Compound Annual Growth Rate (GAGR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzjD5-p2rkVm",
        "outputId": "ace34dba-39c1-4823-d476-0804c6a37e66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The result of version-(2024-01-04) script  start:\n",
            " ###\n",
            "\n",
            "Annual Total Return (%) as year 2024\n",
            "        spy  vfv.to  vgg.to  zlu.to  xiu.to  xfn.to  ry.to  td.to   na.to  \\\n",
            "year                                                                        \n",
            "1994   0.40     NaN     NaN     NaN     NaN     NaN    NaN    NaN     NaN   \n",
            "1995  38.05     NaN     NaN     NaN     NaN     NaN    NaN    NaN     NaN   \n",
            "1996  22.50     NaN     NaN     NaN     NaN     NaN  59.20  52.30   29.73   \n",
            "1997  33.48     NaN     NaN     NaN     NaN     NaN  61.23  56.87   75.97   \n",
            "1998  28.69     NaN     NaN     NaN     NaN     NaN   3.58   2.50    7.92   \n",
            "1999  20.39     NaN     NaN     NaN     NaN     NaN -14.82  46.56  -22.65   \n",
            "2000  -9.74     NaN     NaN     NaN    8.02     NaN  65.34  14.84   43.78   \n",
            "2001 -11.76     NaN     NaN     NaN  -14.24     NaN   4.90  -2.81   11.65   \n",
            "2002 -21.58     NaN     NaN     NaN  -14.02   -3.06  14.85 -14.56    8.75   \n",
            "2003  28.18     NaN     NaN     NaN   24.82   26.14   9.13  31.37   35.63   \n",
            "2004  10.70     NaN     NaN     NaN   13.28   18.57   7.38  18.83   18.76   \n",
            "2005   4.83     NaN     NaN     NaN   25.47   22.90  45.87  26.19   25.57   \n",
            "2006  15.85     NaN     NaN     NaN   19.12   17.79  26.02  16.55   12.71   \n",
            "2007   5.15     NaN     NaN     NaN   10.83   -1.44  -5.57   2.66  -17.21   \n",
            "2008 -36.79     NaN     NaN     NaN  -31.09  -35.98 -25.70 -35.15  -36.68   \n",
            "2009  26.35     NaN     NaN     NaN   31.35   44.58  63.73  59.16  101.42   \n",
            "2010  15.06     NaN     NaN     NaN   13.85    7.90  -3.85  16.52   18.31   \n",
            "2011   1.89     NaN     NaN     NaN   -9.31   -4.41   3.31   6.22    9.41   \n",
            "2012  15.99     NaN     NaN     NaN    7.92   16.44  20.06  13.80   11.61   \n",
            "2013  32.31   40.91     NaN     NaN   13.06   26.00  24.05  24.13   19.48   \n",
            "2014  13.46   24.05   21.49   37.61   11.94   11.88  16.64  14.83   16.48   \n",
            "2015   1.23   20.29   14.58   24.17   -7.80   -3.71  -3.81   1.42  -14.56   \n",
            "2016  12.00    7.63    7.28    5.11   20.32   23.38  27.84  26.92   41.68   \n",
            "2017  21.71   13.68   13.99    5.06    9.58   12.54  17.12  15.15   19.77   \n",
            "2018  -4.57    2.94    5.20    8.39   -7.82   -9.76  -5.50  -4.57   -6.92   \n",
            "2019  31.22   25.15   23.32   20.48   21.81   20.66  14.33  11.66   34.04   \n",
            "2020  18.33   15.61   12.67    1.56    5.27    0.99   6.52   3.72    2.65   \n",
            "2021  28.73   27.51   22.23   20.72   28.06   35.57  33.09  40.15   39.02   \n",
            "2022 -18.18  -12.58   -4.21    7.94   -6.35   -9.92  -1.52  -6.01   -1.45   \n",
            "2023  26.18   23.23   11.58   -3.26   11.85   13.09   9.80   1.10   15.53   \n",
            "2024  -1.37   -0.63    0.00    1.98   -0.41   -1.15  -0.31  -0.76   -0.92   \n",
            "\n",
            "      cm.to  slf.to  gwo.to  bce.to   t.to  rci-b.to  enb.to  trp.to  zlb.to  \n",
            "year                                                                          \n",
            "1994    NaN     NaN     NaN     NaN    NaN       NaN     NaN     NaN     NaN  \n",
            "1995    NaN     NaN     NaN     NaN    NaN       NaN     NaN     NaN     NaN  \n",
            "1996  54.45     NaN     NaN     NaN  24.41    -33.77   32.52   30.92     NaN  \n",
            "1997  51.82     NaN     NaN   52.22  56.17    -31.68   71.09   37.26     NaN  \n",
            "1998 -12.17     NaN     NaN   24.40  -4.06     97.83   11.59  -27.43     NaN  \n",
            "1999  -5.92     NaN     NaN  130.73 -12.46    158.61  -15.71  -40.61     NaN  \n",
            "2000  38.81     NaN     NaN   42.94  21.36    -28.22   58.66   44.57     NaN  \n",
            "2001  20.56  -13.63     NaN  -14.16 -39.27      7.19    2.82   19.65     NaN  \n",
            "2002 -17.74  -19.87     NaN  -17.56 -25.07    -45.94    1.48   19.25     NaN  \n",
            "2003  51.72   23.78   25.64    5.65  52.83     46.26   30.48   25.88     NaN  \n",
            "2004  16.77   27.27   20.62    4.44  42.95     47.75   15.17   10.31     NaN  \n",
            "2005   9.63   19.14   18.24    0.79  34.88     56.94   25.51   27.54     NaN  \n",
            "2006  32.92    8.15   13.56   17.88  14.49     41.45   14.40   14.94     NaN  \n",
            "2007 -25.56   15.88    8.41   31.36  -4.93     30.88    2.63    3.49     NaN  \n",
            "2008 -23.14  -46.96  -39.47  -34.98 -21.45    -15.97    2.01  -14.92     NaN  \n",
            "2009  41.60   12.47   37.32   22.58  -2.85     -7.15   27.48   14.28     NaN  \n",
            "2010  20.34    4.70    3.02   28.68  39.93      9.64   19.66    9.54     NaN  \n",
            "2011  -1.31  -33.66  -18.54   26.82  32.22     18.00   39.75   22.03     NaN  \n",
            "2012  13.68   48.51   26.08    5.77  17.54     19.77   16.23    9.89     NaN  \n",
            "2013  18.85   48.78   40.18   13.57  16.74     10.49   10.92    7.38   20.71  \n",
            "2014  14.59   14.75    6.64   21.76  18.98     -2.06   32.31   21.94   28.36  \n",
            "2015  -4.25    6.77    6.64    5.28  -4.95     10.31  -20.43  -17.44    2.73  \n",
            "2016  25.91   23.87    6.04   13.66  16.77     12.57   28.05   39.37   13.03  \n",
            "2017  17.02    4.39    4.08    9.18  16.35     27.57   -8.84    5.23   11.07  \n",
            "2018 -12.96   -9.44  -15.76   -5.65  -0.66     12.53   -8.30  -16.01   -2.76  \n",
            "2019  12.03   35.86   24.53   17.39  16.30     -5.06   29.43   48.49   21.92  \n",
            "2020   6.99   -0.52   -2.64   -3.92   5.23     -4.94  -15.30  -20.74    0.66  \n",
            "2021  41.53   28.82   31.45   27.90  23.58      5.03   29.98   20.34   22.93  \n",
            "2022 -21.70   -6.73  -12.58   -4.33  -8.27      8.69   13.96   -2.76   -0.35  \n",
            "2023  23.83   14.37   47.70   -6.21  -4.41      1.25   -3.27    3.02    9.41  \n",
            "2024  -0.99   -0.57   -0.62    4.06   1.48      0.50    2.12    1.99   -0.76  \n",
            "\n",
            "Annualized Trailing Returns as end of year 2023 :\n",
            "         spy vfv.to vgg.to zlu.to xiu.to xfn.to  ry.to  td.to  na.to  cm.to  \\\n",
            "Years                                                                         \n",
            "1      26.18  23.23  11.58  -3.26  11.85  13.09    9.8    1.1  15.53  23.83   \n",
            "2       1.61   3.79   3.38   2.19   2.35   0.93   3.99  -2.52    6.7  -1.54   \n",
            "3       9.95  11.16   9.32   8.03  10.29  11.37   12.9  10.02  16.54  11.12   \n",
            "5      15.59  14.72  12.66   9.05  11.46  10.97  11.87   9.05  16.84  10.46   \n",
            "10     11.92  14.08  12.51  12.18   7.99   8.55  10.77   9.62  13.09   8.75   \n",
            "15     13.86    N/A    N/A    N/A   8.86  11.28  13.56  13.82  17.95   11.7   \n",
            "20      9.61    N/A    N/A    N/A   7.95   8.78  11.81  11.03  12.47   8.51   \n",
            "25      7.46    N/A    N/A    N/A    N/A    N/A  12.07  11.41  12.55   9.67   \n",
            "30     10.03    N/A    N/A    N/A    N/A    N/A    N/A    N/A    N/A    N/A   \n",
            "\n",
            "      slf.to gwo.to bce.to   t.to rci-b.to enb.to trp.to zlb.to  \n",
            "Years                                                            \n",
            "1      14.37   47.7  -6.21  -4.41     1.25  -3.27   3.02   9.41  \n",
            "2       3.28  13.63  -5.28  -6.36     4.91   4.99   0.09   4.41  \n",
            "3      11.18  19.28    4.7   2.71     4.95  12.73   6.43  10.25  \n",
            "5      13.18  15.52    5.3   5.81     0.85   9.45   7.25  10.46  \n",
            "10      10.3   8.08   6.87   7.31     6.18   5.88   5.81  10.23  \n",
            "15     10.71  10.43  10.82  11.31     7.34  11.12    8.0    N/A  \n",
            "20      7.97   8.06   8.32  11.11    12.45  11.24   7.83    N/A  \n",
            "25       N/A    N/A  10.52   7.49    11.85  11.54   8.07    N/A  \n",
            "30       N/A    N/A    N/A    N/A      N/A    N/A    N/A    N/A  \n",
            "\n",
            "Cumulative Returns as end of year 2023 :\n",
            "           spy  vfv.to  vgg.to  zlu.to  xiu.to  xfn.to    ry.to    td.to  \\\n",
            "Years                                                                      \n",
            "1        26.18   23.23   11.58   -3.26   11.85   13.09     9.80     1.10   \n",
            "2         3.24    7.73    6.88    4.42    4.75    1.88     8.13    -4.98   \n",
            "3        32.90   37.36   30.63   26.06   34.14   38.12    43.91    33.17   \n",
            "5       106.37   98.74   81.50   54.25   72.01   68.30    75.25    54.23   \n",
            "10      208.35  273.46  225.03  215.51  115.76  127.18   178.20   150.49   \n",
            "15      600.96     NaN     NaN     NaN  257.06  397.03   573.77   597.05   \n",
            "20      526.23     NaN     NaN     NaN  361.73  438.33   833.13   711.00   \n",
            "25      503.55     NaN     NaN     NaN     NaN     NaN  1627.90  1389.04   \n",
            "30     1660.14     NaN     NaN     NaN     NaN     NaN      NaN      NaN   \n",
            "\n",
            "         na.to   cm.to  slf.to  gwo.to   bce.to    t.to  rci-b.to   enb.to  \\\n",
            "Years                                                                        \n",
            "1        15.53   23.83   14.37   47.70    -6.21   -4.41      1.25    -3.27   \n",
            "2        13.86   -3.05    6.68   29.12   -10.27  -12.31     10.05    10.23   \n",
            "3        58.29   37.21   37.43   69.72    14.76    8.36     15.58    43.28   \n",
            "5       117.78   64.47   85.72  105.77    29.44   32.62      4.31    57.06   \n",
            "10      242.30  131.43  166.44  117.56    94.28  102.43     82.10    76.99   \n",
            "15     1090.08  425.89  359.93  343.07   366.82  399.19    189.51   386.40   \n",
            "20      948.63  411.97  363.62  370.91   394.66  723.02    944.31   742.15   \n",
            "25     1820.79  906.04     NaN     NaN  1119.73  508.08   1543.01  1433.32   \n",
            "30         NaN     NaN     NaN     NaN      NaN     NaN       NaN      NaN   \n",
            "\n",
            "       trp.to  zlb.to  \n",
            "Years                  \n",
            "1        3.02    9.41  \n",
            "2        0.18    9.02  \n",
            "3       20.55   34.02  \n",
            "5       41.89   64.46  \n",
            "10      75.95  164.73  \n",
            "15     217.18     NaN  \n",
            "20     351.60     NaN  \n",
            "25     596.32     NaN  \n",
            "30        NaN     NaN  \n",
            "\n",
            "Compound Annual Growth Rates (GAGRs) (%) as end of year 2023 :\n",
            "         spy  vfv.to  vgg.to  zlu.to  xiu.to  xfn.to  ry.to  td.to  na.to  \\\n",
            "Years                                                                       \n",
            "1      26.18   23.23   11.58   -3.26   11.85   13.09   9.80   1.10  15.53   \n",
            "2       1.61    3.79    3.38    2.19    2.35    0.93   3.99  -2.52   6.70   \n",
            "3       9.95   11.16    9.32    8.03   10.29   11.37  12.90  10.02  16.54   \n",
            "5      15.59   14.72   12.66    9.05   11.46   10.97  11.87   9.05  16.84   \n",
            "10     11.92   14.08   12.51   12.18    7.99    8.55  10.77   9.62  13.09   \n",
            "15     13.86     NaN     NaN     NaN    8.86   11.28  13.56  13.82  17.95   \n",
            "20      9.61     NaN     NaN     NaN    7.95    8.78  11.81  11.03  12.47   \n",
            "25      7.46     NaN     NaN     NaN     NaN     NaN  12.07  11.41  12.55   \n",
            "30     10.03     NaN     NaN     NaN     NaN     NaN    NaN    NaN    NaN   \n",
            "\n",
            "       cm.to  slf.to  gwo.to  bce.to   t.to  rci-b.to  enb.to  trp.to  zlb.to  \n",
            "Years                                                                          \n",
            "1      23.83   14.37   47.70   -6.21  -4.41      1.25   -3.27    3.02    9.41  \n",
            "2      -1.54    3.28   13.63   -5.28  -6.36      4.91    4.99    0.09    4.41  \n",
            "3      11.12   11.18   19.28    4.70   2.71      4.95   12.73    6.43   10.25  \n",
            "5      10.46   13.18   15.52    5.30   5.81      0.85    9.45    7.25   10.46  \n",
            "10      8.75   10.30    8.08    6.87   7.31      6.18    5.88    5.81   10.23  \n",
            "15     11.70   10.71   10.43   10.82  11.31      7.34   11.12    8.00     NaN  \n",
            "20      8.51    7.97    8.06    8.32  11.11     12.45   11.24    7.83     NaN  \n",
            "25      9.67     NaN     NaN   10.52   7.49     11.85   11.54    8.07     NaN  \n",
            "30       NaN     NaN     NaN     NaN    NaN       NaN     NaN     NaN     NaN  \n",
            "The result of version-(2024-01-04) script  ends here.\n",
            " ###\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "### CODE start (for AI tool)\n",
        "Retrieve multiple tickers for total returns and trailing total returns from yahoo\n",
        "History:\n",
        "Author: Gang Luo\n",
        "\"\"\"\n",
        "result_marker='###'\n",
        "script_version = '(2024-01-04)'\n",
        "print(f\"The result of version-{script_version} script  start:\\n {result_marker}\")\n",
        "#!pip install yfinance\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "print_yearly_total_return = True\n",
        "\n",
        "# Set the stock tickers list\n",
        "tickers_list1 = [\"spy\", \"vfv.to\", \"vgg.to\", \"zlu.to\", \"xiu.to\", \"xfn.to\", \"ry.to\", \"td.to\", \"na.to\",\n",
        " \"cm.to\", \"slf.to\", \"gwo.to\", \"bce.to\", \"t.to\", \"rci-b.to\", \"enb.to\", \"trp.to\", \"zlb.to\"]\n",
        "tickers_list2 = [\"vfv.to\", \"xiu.to\", \"xic.to\", \"xfn.to\", \"ry.to\", \"td.to\", \"na.to\",\n",
        "                \"bns.to\", \"bmo.to\", \"cm.to\", \"cwb.to\", \"slf.to\", \"gwo.to\"]\n",
        "tickers_list3 = [\"spy\", \"vfv.to\", \"xfn.to\", \"ry.to\"]\n",
        "tickers_list = tickers_list1\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 1: fetch retrieve yearly total returns by yfinance & display\n",
        "# Function to fetch data from yfinance and extract yearly total returns\n",
        "def get_annual_returns_df(ticker):\n",
        "    # Get the historical data for the given ticker\n",
        "    stock = yf.Ticker(ticker)\n",
        "    ''' Get annual total return data.   Explanation the following statement\n",
        "    1.  'Close'  in .\n",
        "    Ticker(ticker).history is the same as 'Adj Close' in .download(ticker, ...)\n",
        "        print(df.columns.tolist()) - Display all column names of DataFrame\n",
        "        yf.Ticker(ticker).history: ['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
        "        yf.download(ticker, ...): ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
        "    2.  [\"Close\"]: Selects the \"Close\" column from the historical stock data.\n",
        "        .resample('Y'): Resamples the time series data annually ('Y'), based on the last trading day of each year.\n",
        "        .resample('A'): Resamples the time series data annually ('A'), based on the any trading day of each year.\n",
        "        .ffill(): Forward fills missing values, ensuring that each annual period has a value.\n",
        "        .pct_change(): Calculates the percentage change between the current and previous values, representing the annual returns.\n",
        "        .dropna(): Removes any rows with missing values (which may occur after calculating percentage changes).\n",
        "    '''\n",
        "    annual_returns = stock.history(period=\"max\")[\"Close\"].resample('Y').ffill().pct_change().dropna()\n",
        "    annual_returns_df = pd.DataFrame(annual_returns, columns=['Close'])\n",
        "    annual_returns_df.rename(columns={'Close': ticker}, inplace=True)\n",
        "    return annual_returns_df\n",
        "# Create an empty DataFrame to store all tickers' total returns\n",
        "all_tickers_returns_df = pd.DataFrame()\n",
        "\n",
        "# Loop through each ticker in the list\n",
        "for ticker in tickers_list:\n",
        "    ticker_returns_df = get_annual_returns_df(ticker)\n",
        "    if not ticker_returns_df.empty:\n",
        "        if all_tickers_returns_df.empty:\n",
        "            all_tickers_returns_df = ticker_returns_df\n",
        "        else:\n",
        "            all_tickers_returns_df = pd.concat([all_tickers_returns_df, ticker_returns_df], axis=1)  # Concatenate DataFrames\n",
        "\n",
        "# Display the results if the DataFrame is not empty\n",
        "\n",
        "if all_tickers_returns_df.empty:\n",
        "    print(\"No data available for the specified tickers.\")\n",
        "\n",
        "#print(\"\\nAnnual Total Return (%) History:\")\n",
        "# keep the date portion of index only - stripping time portion\n",
        "#all_tickers_returns_df.index=all_tickers_returns_df.index.date\n",
        "#print(all_tickers_returns_df)\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 2:\n",
        "# Define a list of years to calculate the trailing returns, cumulative returns, and so on\n",
        "# remove the row of current year row since it is not a full year.\n",
        "years_list = [1, 2, 3, 5, 10, 15, 20, 25, 30]\n",
        "current_year=all_tickers_returns_df.index.year.max()\n",
        "all_tickers_returns_with_current_year_df=all_tickers_returns_df\n",
        "all_tickers_returns_df=all_tickers_returns_df[all_tickers_returns_df.index.year < current_year]\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 3: calculate the annualized trailing total return from the data generated in step 1 & display\n",
        "# Define a function to calculate the annualized trailing total return for a given number of years\n",
        "def get_trailing_return(ticker, data, years):\n",
        "    # Get the total return values for the last n years\n",
        "    trailing_data = data[ticker].tail(years)\n",
        "    # Check if there are empty values within years\n",
        "    if trailing_data.isna().any():\n",
        "        return \"N/A\"\n",
        "    # Check if there are valid total return values for all years\n",
        "    if len(trailing_data) == years:\n",
        "        # Convert the percentage strings to numeric values\n",
        "        trailing_data = trailing_data.astype(str).str.replace('%', '').astype(float)\n",
        "        \"\"\" Calculate the annualized trailing total return using the formula from Investopedia[^1^][1]:\n",
        "            Annualized Return = [(1 + r1) * (1 + r2) * ... * (1 + rn)]^(1/n) - 1\n",
        "            Where r1, r2, ..., rn are the total return values for each year                    \"\"\"\n",
        "        annualized_trailing_return = (trailing_data + 1).prod() ** (1 / years) - 1\n",
        "\n",
        "        # Format the result as a percentage with two decimal places\n",
        "        annualized_trailing_return = annualized_trailing_return * 100\n",
        "        annualized_trailing_return = annualized_trailing_return.round(2)\n",
        "        return annualized_trailing_return\n",
        "    else:\n",
        "        return \"N/A\"\n",
        "\n",
        "# Define a function to Loop through the list and print the trailing returns for each num_years\n",
        "def get_trailing_return_column(ticker):\n",
        "    trailing_return_column = {}\n",
        "    for num_years in years_list:\n",
        "        # Check if the ticker data is available in all_tickers_returns_df\n",
        "        if ticker in all_tickers_returns_df.columns:\n",
        "            # using data from step 1, avoiding get_annual_returns_df(ticker) for less traffic from yahoo server\n",
        "            data = all_tickers_returns_df[[ticker]]\n",
        "            trailing_return = get_trailing_return(ticker, data, num_years)\n",
        "            trailing_return_column[f\"{num_years}-Year\"] = trailing_return\n",
        "        else:\n",
        "            print(f\"Data not available for {ticker}. Skipping.\")\n",
        "            trailing_return_column[f\"{num_years}-Year\"] = \"N/A\"\n",
        "    return trailing_return_column\n",
        "\n",
        "# Create an empty DataFrame to store all tickers' trailing returns\n",
        "all_tickers_trailing_returns_df = pd.DataFrame(index=years_list)\n",
        "\n",
        "# Loop through each ticker in the list\n",
        "for ticker in tickers_list:\n",
        "    trailing_returns = get_trailing_return_column(ticker)\n",
        "    # Add the trailing returns to the DataFrame\n",
        "    all_tickers_trailing_returns_df[ticker] = pd.Series(trailing_returns).values\n",
        "\n",
        "# Display the trailing returns DataFrame\n",
        "#print(\"\\nAnnualized Trailing Returns as end of year\", current_year-1, \":\")\n",
        "#print(\"years\")\n",
        "#print(all_tickers_trailing_returns_df)\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 4: calculate the cumulative return from the data (all_tickers_returns_df) generated in step 1 & display\n",
        "# 4.1 Define a function to calculate the cumulative return for a given number of years from a ticker\n",
        "def get_cumulative_return(ticker, data, years):\n",
        "    # Calculate the cumulative return\n",
        "    cumulative_return = (1 + data[ticker]).rolling(window=years).apply(lambda x: x.prod(), raw=True) - 1\n",
        "    return cumulative_return\n",
        "\n",
        "# Create an empty DataFrame with years_list as the index for cumulative  returns\n",
        "all_tickers_cumulative_returns_df = pd.DataFrame(index=years_list)\n",
        "\n",
        "# Define a function to Loop through the list and return the cumulative returns for each num_years\n",
        "def get_cumulative_return_column(ticker):\n",
        "    cumulative_returns = {}\n",
        "    for years in years_list:\n",
        "        # Calculate the cumulative return for the given number of years\n",
        "        cumulative_return = get_cumulative_return(ticker, all_tickers_returns_df, years)\n",
        "        # Get the last value, which is the cumulative return up to the current year\n",
        "        cumulative_returns[years] = cumulative_return.iloc[-1]\n",
        "    return cumulative_returns\n",
        "\n",
        "# Loop through each ticker in the list\n",
        "for ticker in tickers_list:\n",
        "    cumulative_returns = get_cumulative_return_column(ticker)\n",
        "    # Add the trailing returns to the DataFrame\n",
        "    all_tickers_cumulative_returns_df[ticker] = pd.Series(cumulative_returns).values\n",
        "\n",
        "# Display the cumulative returns DataFrame\n",
        "#print(\"\\nCumulative Returns as end of year\", current_year-1, \":\")\n",
        "#print(\"years\")\n",
        "#print(all_tickers_cumulative_returns_df.round(4) * 100)\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 5: calculate the  CAGR from the data (all_tickers_cumulative_returns_df) generated earlier & display\n",
        "# Define a function to calculate the CAGR from the cumulative value and the years\n",
        "import numpy as np\n",
        "def calculate_cagr(value, years):\n",
        "    # Otherwise, calculate the CAGR using the formula\n",
        "    cagr = (value + 1) ** (1 / np.array(years)) - 1\n",
        "    #print(\"debug-cagr\\n\", cagr, \"end\")\n",
        "    return cagr\n",
        "\n",
        "# Define a function to format the Float64Index values into percentage strings\n",
        "def format_to_percentage(value):\n",
        "    # If any element in the value array is not null, format it as a percentage string with two decimal places\n",
        "    if np.any(pd.notnull(value)):\n",
        "        return f\"{value:.2f}%\"\n",
        "    # Otherwise, return None\n",
        "    return None\n",
        "\n",
        "# Apply the calculate_cagr function to each column of the DataFrame\n",
        "all_tickers_cagrs_df = all_tickers_cumulative_returns_df.apply(lambda x: calculate_cagr(x, x.index), axis=0)\n",
        "\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Display the formatted DataFrame  all_tickers_returns_df\n",
        "print(\"\\nAnnual Total Return (%) as year\", current_year)\n",
        "if (print_yearly_total_return):\n",
        "    all_tickers_returns_with_current_year_df.index=all_tickers_returns_with_current_year_df.index.year\n",
        "    all_tickers_returns_with_current_year_df.index.name='year'\n",
        "    print(all_tickers_returns_with_current_year_df.round(4) * 100)\n",
        "\n",
        "# Display the trailing returns DataFrame\n",
        "print(\"\\nAnnualized Trailing Returns as end of year\", current_year-1, \":\")\n",
        "all_tickers_trailing_returns_df.index.name = 'Years'\n",
        "print(all_tickers_trailing_returns_df)\n",
        "\n",
        "# Display the cumulative returns DataFrame\n",
        "print(\"\\nCumulative Returns as end of year\", current_year-1, \":\")\n",
        "all_tickers_cumulative_returns_df.index.name = 'Years'\n",
        "print(all_tickers_cumulative_returns_df.round(4) * 100)\n",
        "\n",
        "\n",
        "# Display the formatted DataFrame  all_tickers_cagrs_df\n",
        "print(\"\\nCompound Annual Growth Rates (GAGRs) (%) as end of year\", current_year-1, \":\")\n",
        "all_tickers_cagrs_df.index.name = 'Years'\n",
        "print(all_tickers_cagrs_df.round(4) * 100)\n",
        "\n",
        "\n",
        "# print an indicator to mark the end of execution result\n",
        "print(f\"The result of version-{script_version} script  ends here.\\n {result_marker}\")\n",
        "### CODE end (for AI tool)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtLY7xuxvDlE",
        "outputId": "c6b6e70a-9e3e-4d6c-eb12-3ce58bba1969"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The result of version-12 script  start:\n",
            " ###\n",
            "\n",
            "Annual Total Return (%) History:\n",
            "            xiu.to  xfn.to  ry.to  td.to   na.to  cwb.to  slf.to  gwo.to\n",
            "1996-12-31     NaN     NaN  59.20  52.30   29.73   38.08     NaN     NaN\n",
            "1997-12-31     NaN     NaN  61.23  56.87   75.97   62.90     NaN     NaN\n",
            "1998-12-31     NaN     NaN   3.58   2.50    7.92   10.75     NaN     NaN\n",
            "1999-12-31     NaN     NaN -14.82  46.56  -22.65  -21.16     NaN     NaN\n",
            "2000-12-31    8.02     NaN  65.34  14.84   43.78   42.46     NaN     NaN\n",
            "2001-12-31  -14.24     NaN   4.90  -2.81   11.65    9.86  -13.63     NaN\n",
            "2002-12-31  -14.02   -3.06  14.85 -14.56    8.75   -5.13  -19.87     NaN\n",
            "2003-12-31   24.82   26.14   9.13  31.37   35.63   50.03   23.78   25.64\n",
            "2004-12-31   13.28   18.57   7.38  18.83   18.76   37.62   27.27   20.62\n",
            "2005-12-31   25.47   22.90  45.87  26.19   25.57   36.52   19.14   18.24\n",
            "2006-12-31   19.12   17.79  26.02  16.55   12.71   49.19    8.15   13.56\n",
            "2007-12-31   10.83   -1.44  -5.57   2.66  -17.21   20.31   15.88    8.41\n",
            "2008-12-31  -31.09  -35.98 -25.70 -35.15  -36.69  -59.55  -46.96  -39.47\n",
            "2009-12-31   31.35   44.58  63.73  59.16  101.42   82.31   12.47   37.32\n",
            "2010-12-31   13.85    7.90  -3.85  16.52   18.31   31.59    4.70    3.02\n",
            "2011-12-31   -9.31   -4.41   3.31   6.22    9.41   -7.18  -33.66  -18.54\n",
            "2012-12-31    7.92   16.44  20.06  13.80   11.61   12.76   48.51   26.08\n",
            "2013-12-31   13.06   26.00  24.05  24.13   19.48   39.14   48.78   40.18\n",
            "2014-12-31   11.94   11.88  16.64  14.83   16.48  -13.38   14.75    6.64\n",
            "2015-12-31   -7.80   -3.71  -3.81   1.42  -14.56  -26.04    6.77    6.64\n",
            "2016-12-31   20.32   23.38  27.84  26.92   41.68   34.34   23.87    6.04\n",
            "2017-12-31    9.58   12.54  17.12  15.15   19.77   33.40    4.39    4.08\n",
            "2018-12-31   -7.82   -9.76  -5.50  -4.57   -6.92  -31.55   -9.44  -15.76\n",
            "2019-12-31   21.81   20.66  14.33  11.66   34.04   26.93   35.86   24.53\n",
            "2020-12-31    5.27    0.99   6.52   3.72    2.65   -6.25   -0.52   -2.64\n",
            "2021-12-31   28.06   35.57  33.09  40.15   39.02   31.07   28.82   31.45\n",
            "2022-12-31   -6.35   -9.92  -1.52  -6.01   -1.45  -30.69   -6.73  -12.58\n",
            "2023-12-31   11.19   12.24   9.53   0.51   14.40   35.00   12.31   44.29\n",
            "\n",
            "Annualized Trailing Returns as end of year 2022 :\n",
            "years\n",
            "   xiu.to xfn.to  ry.to  td.to  na.to cwb.to slf.to gwo.to\n",
            "1   -6.35  -9.92  -1.52  -6.01  -1.45 -30.69  -6.73 -12.58\n",
            "2    9.51  10.51  14.48  14.77  17.05  -4.69   9.62    7.2\n",
            "3    8.08   7.24  11.76  10.96  12.04  -5.21   6.13   3.81\n",
            "5    7.23   6.07   8.57    7.8   11.9  -5.84   8.02   3.25\n",
            "10   8.11   9.73  12.13  11.89  13.47   1.69  13.24   7.52\n",
            "15    5.4   7.14  10.64   10.5  13.32   1.23   5.18   4.06\n",
            "20   8.54   9.38  11.78   12.5  13.37   9.44    8.4   7.19\n",
            "25   5.81    7.3  11.81  11.47  12.24   8.61   5.11   5.71\n",
            "30    N/A    N/A    N/A    N/A    N/A    N/A    N/A    N/A\n",
            "The result of version-12 script  ends here.\n",
            " ###\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "### CODE start (for AI tool)\n",
        "Retrieve multiple tickers for total returns and trailing total returns from yahoo\n",
        "History:\n",
        "Dec 21, 2023, version 12\n",
        "\n",
        "Author: Gang Luo\n",
        "\"\"\"\n",
        "result_marker='###'\n",
        "script_version = 12\n",
        "print(f\"The result of version-{script_version} script  start:\\n {result_marker}\")\n",
        "#!pip install yfinance\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "# Set the stock tickers list\n",
        "#tickers_list = [\"spy\", \"vfv.to\", \"xiu.to\", \"xic.to\", \"xfn.to\", \"ry.to\", \"enb.to\"]\n",
        "tickers_list = [\"xiu.to\", \"xfn.to\", \"ry.to\", \"td.to\", \"na.to\", \"cwb.to\", \"slf.to\", \"gwo.to\"]\n",
        "#-------------------------------------------------------------------\n",
        "# step 1: fetch retrieve yearly total returns by yfinance & display\n",
        "\n",
        "# Function to fetch data from yfinance and extract yearly total returns\n",
        "def get_annual_returns_df(ticker):\n",
        "    # Get the historical data for the given ticker\n",
        "    stock = yf.Ticker(ticker)\n",
        "    ''' Get annual total return data.   Explanation the following statement\n",
        "    1.  'Close'  in .Ticker(ticker).history is the same as 'Adj Close' in .download(ticker, ...)\n",
        "        print(df.columns.tolist()) - Display all column names of DataFrame\n",
        "        yf.Ticker(ticker).history: ['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
        "        yf.download(ticker, ...): ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
        "    2.  [\"Close\"]: Selects the \"Close\" column from the historical stock data.\n",
        "        .resample('Y'): Resamples the time series data annually ('Y').\n",
        "        .ffill(): Forward fills missing values, ensuring that each annual period has a value.\n",
        "        .pct_change(): Calculates the percentage change between the current and previous values, representing the annual returns.\n",
        "        .dropna(): Removes any rows with missing values (which may occur after calculating percentage changes).\n",
        "    '''\n",
        "    annual_returns = stock.history(period=\"max\")[\"Close\"].resample('Y').ffill().pct_change().dropna()\n",
        "    annual_returns_df = pd.DataFrame(annual_returns, columns=['Close'])\n",
        "    annual_returns_df.rename(columns={'Close': ticker}, inplace=True)\n",
        "    return annual_returns_df\n",
        "# Create an empty DataFrame to store all tickers' total returns\n",
        "all_tickers_returns_df = pd.DataFrame()\n",
        "\n",
        "# Loop through each ticker in the list\n",
        "for ticker in tickers_list:\n",
        "    ticker_returns_df = get_annual_returns_df(ticker)\n",
        "    if not ticker_returns_df.empty:\n",
        "        if all_tickers_returns_df.empty:\n",
        "            all_tickers_returns_df = ticker_returns_df\n",
        "        else:\n",
        "            all_tickers_returns_df = pd.concat([all_tickers_returns_df, ticker_returns_df], axis=1)  # Concatenate DataFrames\n",
        "\n",
        "# Display the results if the DataFrame is not empty\n",
        "print(\"\\nAnnual Total Return (%) History:\")\n",
        "if not all_tickers_returns_df.empty:\n",
        "    # keep the date portion of index only - stripping time portion\n",
        "    #all_tickers_returns_df.index=all_tickers_returns_df.index.date\n",
        "\n",
        "    # Format the DataFrame to display percentage\n",
        "    all_tickers_returns_df_copy = all_tickers_returns_df * 100\n",
        "    all_tickers_returns_df_copy=all_tickers_returns_df_copy.round(2)\n",
        "    all_tickers_returns_df_copy.index=all_tickers_returns_df_copy.index.date\n",
        "    print(all_tickers_returns_df_copy)\n",
        "else:\n",
        "    print(\"No data available for the specified tickers.\")\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 2: Remove the row of the current year for the later steps\n",
        "# Define a list of years to calculate the trailing returns, cumulative returns, and so on\n",
        "years_list = [1, 2, 3, 5, 10, 15, 20, 25, 30]\n",
        "current_year=all_tickers_returns_df.index.year.max()\n",
        "all_tickers_returns_df['Year']=all_tickers_returns_df.index.year\n",
        "all_tickers_returns_df=all_tickers_returns_df[all_tickers_returns_df['Year'] < current_year]\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 3: calculate the annualized trailing total return from the data generated in step 1 & display\n",
        "# Define a function to calculate the annualized trailing total return for a given number of years\n",
        "def get_trailing_return(ticker, data, years):\n",
        "    # Get the total return values for the last n years\n",
        "    trailing_data = data[ticker].tail(years)\n",
        "\n",
        "    # Check if there are valid total return values for all years\n",
        "    if len(trailing_data) == years:\n",
        "        # Convert the percentage strings to numeric values\n",
        "        trailing_data = trailing_data.astype(str).str.replace('%', '').astype(float)\n",
        "\n",
        "        \"\"\" Calculate the annualized trailing total return using the formula from Investopedia[^1^][1]:\n",
        "            Annualized Return = [(1 + r1) * (1 + r2) * ... * (1 + rn)]^(1/n) - 1\n",
        "            Where r1, r2, ..., rn are the total return values for each year                    \"\"\"\n",
        "        annualized_trailing_return = (trailing_data + 1).prod() ** (1 / years) - 1\n",
        "\n",
        "        # Format the result as a percentage with two decimal places\n",
        "        annualized_trailing_return = annualized_trailing_return * 100\n",
        "        annualized_trailing_return = annualized_trailing_return.round(2)\n",
        "        return annualized_trailing_return\n",
        "    else:\n",
        "        return \"N/A\"\n",
        "\n",
        "# Create an empty DataFrame with years_list as the index for trailing total returns\n",
        "all_tickers_trailing_returns_df = pd.DataFrame(index=years_list)\n",
        "\n",
        "# Define a function to Loop through the list and print the trailing returns for each num_years\n",
        "def get_trailing_return_column(ticker):\n",
        "    trailing_return_column = {}\n",
        "    for num_years in years_list:\n",
        "        # Check if the ticker data is available in all_tickers_returns_df\n",
        "        if ticker in all_tickers_returns_df.columns:\n",
        "            # using data from step 1, avoiding get_annual_returns_df(ticker) for less traffic from yahoo server\n",
        "            data = all_tickers_returns_df[[ticker]]\n",
        "            trailing_return = get_trailing_return(ticker, data, num_years)\n",
        "            trailing_return_column[f\"{num_years}-Year\"] = trailing_return\n",
        "        else:\n",
        "            print(f\"Data not available for {ticker}. Skipping.\")\n",
        "            trailing_return_column[f\"{num_years}-Year\"] = \"N/A\"\n",
        "    return trailing_return_column\n",
        "\n",
        "# Create an empty DataFrame to store all tickers' trailing returns\n",
        "all_tickers_trailing_returns_df = pd.DataFrame(index=years_list)\n",
        "\n",
        "# Loop through each ticker in the list\n",
        "for ticker in tickers_list:\n",
        "    trailing_returns = get_trailing_return_column(ticker)\n",
        "    # Add the trailing returns to the DataFrame\n",
        "    all_tickers_trailing_returns_df[ticker] = pd.Series(trailing_returns).values\n",
        "\n",
        "# Display the trailing returns DataFrame\n",
        "print(\"\\nAnnualized Trailing Returns as end of year\", current_year-1, \":\")\n",
        "print(\"years\")\n",
        "print(all_tickers_trailing_returns_df)\n",
        "\n",
        "# print an indicator to mark the end of execution result\n",
        "print(f\"The result of version-{script_version} script  ends here.\\n {result_marker}\")\n",
        "### CODE end (for AI tool)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d53-mRovARl",
        "outputId": "92fbef2e-1e08-46e2-fd54-9faf1256f1dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The result of version-12 script  start:\n",
            " ###\n",
            "\n",
            "Annual Total Return (%) History:\n",
            "            xiu.to  xfn.to  ry.to  td.to   na.to  cwb.to  slf.to  gwo.to\n",
            "1996-12-31     NaN     NaN  59.20  52.30   29.73   38.08     NaN     NaN\n",
            "1997-12-31     NaN     NaN  61.23  56.87   75.97   62.90     NaN     NaN\n",
            "1998-12-31     NaN     NaN   3.58   2.50    7.92   10.75     NaN     NaN\n",
            "1999-12-31     NaN     NaN -14.82  46.56  -22.65  -21.16     NaN     NaN\n",
            "2000-12-31    8.02     NaN  65.34  14.84   43.78   42.47     NaN     NaN\n",
            "2001-12-31  -14.24     NaN   4.90  -2.81   11.65    9.86  -13.63     NaN\n",
            "2002-12-31  -14.02   -3.06  14.85 -14.56    8.75   -5.13  -19.87     NaN\n",
            "2003-12-31   24.82   26.14   9.13  31.37   35.63   50.03   23.78   25.64\n",
            "2004-12-31   13.28   18.57   7.38  18.83   18.76   37.62   27.27   20.62\n",
            "2005-12-31   25.47   22.90  45.87  26.19   25.57   36.52   19.14   18.24\n",
            "2006-12-31   19.12   17.79  26.02  16.55   12.71   49.19    8.15   13.56\n",
            "2007-12-31   10.83   -1.44  -5.57   2.66  -17.21   20.31   15.88    8.41\n",
            "2008-12-31  -31.09  -35.98 -25.70 -35.15  -36.68  -59.55  -46.96  -39.47\n",
            "2009-12-31   31.35   44.58  63.73  59.16  101.42   82.31   12.47   37.32\n",
            "2010-12-31   13.85    7.90  -3.85  16.52   18.31   31.59    4.70    3.02\n",
            "2011-12-31   -9.31   -4.41   3.31   6.22    9.41   -7.18  -33.66  -18.54\n",
            "2012-12-31    7.92   16.44  20.06  13.80   11.61   12.76   48.51   26.08\n",
            "2013-12-31   13.06   26.00  24.05  24.13   19.48   39.14   48.78   40.18\n",
            "2014-12-31   11.94   11.88  16.64  14.83   16.48  -13.38   14.75    6.64\n",
            "2015-12-31   -7.80   -3.71  -3.81   1.42  -14.56  -26.04    6.77    6.64\n",
            "2016-12-31   20.32   23.38  27.84  26.92   41.68   34.34   23.87    6.04\n",
            "2017-12-31    9.58   12.54  17.12  15.15   19.77   33.40    4.39    4.08\n",
            "2018-12-31   -7.82   -9.76  -5.50  -4.57   -6.92  -31.55   -9.44  -15.76\n",
            "2019-12-31   21.81   20.66  14.33  11.66   34.04   26.93   35.86   24.53\n",
            "2020-12-31    5.27    0.99   6.52   3.72    2.65   -6.25   -0.52   -2.64\n",
            "2021-12-31   28.06   35.57  33.09  40.15   39.02   31.07   28.82   31.45\n",
            "2022-12-31   -6.35   -9.92  -1.52  -6.01   -1.45  -30.69   -6.73  -12.58\n",
            "2023-12-31   11.19   12.24   9.53   0.51   14.40   35.00   12.31   44.29\n",
            "\n",
            "Annualized Trailing Returns as end of year 2022 :\n",
            "years\n",
            "   xiu.to xfn.to  ry.to  td.to  na.to cwb.to slf.to gwo.to\n",
            "1   -6.35  -9.92  -1.52  -6.01  -1.45 -30.69  -6.73 -12.58\n",
            "2    9.51  10.51  14.48  14.77  17.05  -4.69   9.62    7.2\n",
            "3    8.08   7.24  11.76  10.96  12.04  -5.21   6.13   3.81\n",
            "5    7.23   6.07   8.57    7.8   11.9  -5.84   8.02   3.25\n",
            "10   8.11   9.73  12.13  11.89  13.47   1.69  13.24   7.52\n",
            "15    5.4   7.14  10.64   10.5  13.32   1.23   5.18   4.06\n",
            "20   8.54   9.38  11.78   12.5  13.37   9.44    8.4   7.19\n",
            "25   5.81    7.3  11.81  11.47  12.24   8.61   5.11   5.71\n",
            "30    N/A    N/A    N/A    N/A    N/A    N/A    N/A    N/A\n",
            "The result of version-12 script  ends here.\n",
            " ###\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "### CODE start (for AI tool)\n",
        "Retrieve multiple tickers for total returns and trailing total returns from yahoo\n",
        "History:\n",
        "Dec 21, 2023, version 12\n",
        "\n",
        "Author: Gang Luo\n",
        "\"\"\"\n",
        "result_marker='###'\n",
        "script_version = 12\n",
        "print(f\"The result of version-{script_version} script  start:\\n {result_marker}\")\n",
        "#!pip install yfinance\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "# Set the stock tickers list\n",
        "#tickers_list = [\"spy\", \"vfv.to\", \"xiu.to\", \"xic.to\", \"xfn.to\", \"ry.to\", \"enb.to\"]\n",
        "tickers_list = [\"xiu.to\", \"xfn.to\", \"ry.to\", \"td.to\", \"na.to\", \"cwb.to\", \"slf.to\", \"gwo.to\"]\n",
        "#-------------------------------------------------------------------\n",
        "# step 1: fetch retrieve yearly total returns by yfinance & display\n",
        "\n",
        "# Function to fetch data from yfinance and extract yearly total returns\n",
        "def get_annual_returns_df(ticker):\n",
        "    # Get the historical data for the given ticker\n",
        "    stock = yf.Ticker(ticker)\n",
        "    ''' Get annual total return data.   Explanation the following statement\n",
        "    1.  'Close'  in .Ticker(ticker).history is the same as 'Adj Close' in .download(ticker, ...)\n",
        "        print(df.columns.tolist()) - Display all column names of DataFrame\n",
        "        yf.Ticker(ticker).history: ['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
        "        yf.download(ticker, ...): ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
        "    2.  [\"Close\"]: Selects the \"Close\" column from the historical stock data.\n",
        "        .resample('Y'): Resamples the time series data annually ('Y').\n",
        "        .ffill(): Forward fills missing values, ensuring that each annual period has a value.\n",
        "        .pct_change(): Calculates the percentage change between the current and previous values, representing the annual returns.\n",
        "        .dropna(): Removes any rows with missing values (which may occur after calculating percentage changes).\n",
        "    '''\n",
        "    annual_returns = stock.history(period=\"max\")[\"Close\"].resample('Y').ffill().pct_change().dropna()\n",
        "    annual_returns_df = pd.DataFrame(annual_returns, columns=['Close'])\n",
        "    annual_returns_df.rename(columns={'Close': ticker}, inplace=True)\n",
        "    return annual_returns_df\n",
        "# Create an empty DataFrame to store all tickers' total returns\n",
        "all_tickers_returns_df = pd.DataFrame()\n",
        "\n",
        "# Loop through each ticker in the list\n",
        "for ticker in tickers_list:\n",
        "    ticker_returns_df = get_annual_returns_df(ticker)\n",
        "    if not ticker_returns_df.empty:\n",
        "        if all_tickers_returns_df.empty:\n",
        "            all_tickers_returns_df = ticker_returns_df\n",
        "        else:\n",
        "            all_tickers_returns_df = pd.concat([all_tickers_returns_df, ticker_returns_df], axis=1)  # Concatenate DataFrames\n",
        "\n",
        "# Display the results if the DataFrame is not empty\n",
        "print(\"\\nAnnual Total Return (%) History:\")\n",
        "if not all_tickers_returns_df.empty:\n",
        "    # keep the date portion of index only - stripping time portion\n",
        "    #all_tickers_returns_df.index=all_tickers_returns_df.index.date\n",
        "\n",
        "    # Format the DataFrame to display percentage\n",
        "    all_tickers_returns_df_copy = all_tickers_returns_df * 100\n",
        "    all_tickers_returns_df_copy=all_tickers_returns_df_copy.round(2)\n",
        "    all_tickers_returns_df_copy.index=all_tickers_returns_df_copy.index.date\n",
        "    print(all_tickers_returns_df_copy)\n",
        "else:\n",
        "    print(\"No data available for the specified tickers.\")\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 2: Remove the row of the current year for the later steps\n",
        "# Define a list of years to calculate the trailing returns, cumulative returns, and so on\n",
        "years_list = [1, 2, 3, 5, 10, 15, 20, 25, 30]\n",
        "current_year=all_tickers_returns_df.index.year.max()\n",
        "all_tickers_returns_df['Year']=all_tickers_returns_df.index.year\n",
        "all_tickers_returns_df=all_tickers_returns_df[all_tickers_returns_df['Year'] < current_year]\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 3: calculate the annualized trailing total return from the data generated in step 1 & display\n",
        "# Define a function to calculate the annualized trailing total return for a given number of years\n",
        "def get_trailing_return(ticker, data, years):\n",
        "    # Get the total return values for the last n years\n",
        "    trailing_data = data[ticker].tail(years)\n",
        "\n",
        "    # Check if there are valid total return values for all years\n",
        "    if len(trailing_data) == years:\n",
        "        # Convert the percentage strings to numeric values\n",
        "        trailing_data = trailing_data.astype(str).str.replace('%', '').astype(float)\n",
        "\n",
        "        \"\"\" Calculate the annualized trailing total return using the formula from Investopedia[^1^][1]:\n",
        "            Annualized Return = [(1 + r1) * (1 + r2) * ... * (1 + rn)]^(1/n) - 1\n",
        "            Where r1, r2, ..., rn are the total return values for each year                    \"\"\"\n",
        "        annualized_trailing_return = (trailing_data + 1).prod() ** (1 / years) - 1\n",
        "\n",
        "        # Format the result as a percentage with two decimal places\n",
        "        annualized_trailing_return = annualized_trailing_return * 100\n",
        "        annualized_trailing_return = annualized_trailing_return.round(2)\n",
        "        return annualized_trailing_return\n",
        "    else:\n",
        "        return \"N/A\"\n",
        "\n",
        "# Create an empty DataFrame with years_list as the index for trailing total returns\n",
        "all_tickers_trailing_returns_df = pd.DataFrame(index=years_list)\n",
        "\n",
        "# Define a function to Loop through the list and print the trailing returns for each num_years\n",
        "def get_trailing_return_column(ticker):\n",
        "    trailing_return_column = {}\n",
        "    for num_years in years_list:\n",
        "        # Check if the ticker data is available in all_tickers_returns_df\n",
        "        if ticker in all_tickers_returns_df.columns:\n",
        "            # using data from step 1, avoiding get_annual_returns_df(ticker) for less traffic from yahoo server\n",
        "            data = all_tickers_returns_df[[ticker]]\n",
        "            trailing_return = get_trailing_return(ticker, data, num_years)\n",
        "            trailing_return_column[f\"{num_years}-Year\"] = trailing_return\n",
        "        else:\n",
        "            print(f\"Data not available for {ticker}. Skipping.\")\n",
        "            trailing_return_column[f\"{num_years}-Year\"] = \"N/A\"\n",
        "    return trailing_return_column\n",
        "\n",
        "# Create an empty DataFrame to store all tickers' trailing returns\n",
        "all_tickers_trailing_returns_df = pd.DataFrame(index=years_list)\n",
        "\n",
        "# Loop through each ticker in the list\n",
        "for ticker in tickers_list:\n",
        "    trailing_returns = get_trailing_return_column(ticker)\n",
        "    # Add the trailing returns to the DataFrame\n",
        "    all_tickers_trailing_returns_df[ticker] = pd.Series(trailing_returns).values\n",
        "\n",
        "# Display the trailing returns DataFrame\n",
        "print(\"\\nAnnualized Trailing Returns as end of year\", current_year-1, \":\")\n",
        "print(\"years\")\n",
        "print(all_tickers_trailing_returns_df)\n",
        "\n",
        "# print an indicator to mark the end of execution result\n",
        "print(f\"The result of version-{script_version} script  ends here.\\n {result_marker}\")\n",
        "### CODE end (for AI tool)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbtQ2jr4UBPT"
      },
      "source": [
        "# Example 2 EndOfYear- AdjPrice, dividendSum, the yearly total return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_AVFvzktjYJ",
        "outputId": "bacf12d2-c8c8-4f4a-8e87-1f8bcc8878fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     LastTradingDate  Adj Close  DividendSum TotalReturn\n",
            "Year                                                    \n",
            "1995      1995-12-29   0.375843       0.3100        nan%\n",
            "1996      1996-12-31   0.649846       0.2475      72.90%\n",
            "1997      1997-12-31   1.057006       0.3700      62.65%\n",
            "1998      1998-12-31   1.172340       0.5050      10.91%\n",
            "1999      1999-12-31   1.176476       0.4500       0.35%\n",
            "2000      2000-12-29   1.810161       0.5200      53.86%\n",
            "2001      2001-12-31   2.272631       0.6500      25.55%\n",
            "2002      2002-12-31   2.648307       0.5550      16.53%\n",
            "2003      2003-12-31   3.658473       0.8400      38.14%\n",
            "2004      2004-12-31   4.948505       1.4200      35.26%\n",
            "2005      2005-12-30   6.224385       1.3600      25.78%\n",
            "2006      2006-12-29   7.792041       1.5600      25.19%\n",
            "2007      2007-12-31   8.365834       1.7900       7.36%\n",
            "2008      2008-12-31   6.086138       1.4500     -27.25%\n",
            "2009      2009-12-31  10.791874       2.4500      77.32%\n",
            "2010      2010-12-31  13.926376       1.9600      29.05%\n",
            "2011      2011-12-30  13.778359       2.0800      -1.06%\n",
            "2012      2012-12-31  17.390566       2.2400      26.22%\n",
            "2013      2013-12-31  21.855124       1.8200      25.67%\n",
            "2014      2014-12-31  24.089823       2.5600      10.23%\n",
            "2015      2015-12-31  23.406115       3.4200      -2.84%\n",
            "2016      2016-12-30  34.742153       2.9200      48.43%\n",
            "2017      2017-12-29  41.375111       3.1000      19.09%\n",
            "2018      2018-12-31  38.557125       3.3400      -6.81%\n",
            "2019      2019-12-31  45.181755       2.6400      17.18%\n",
            "2020      2020-12-31  48.554295       3.6000       7.46%\n",
            "2021      2021-12-31  71.662102       4.6000      47.59%\n",
            "2022      2022-12-30  56.207729       2.0300     -21.57%\n",
            "2023      2023-12-29  62.380001       4.1800      10.98%\n",
            "2024      2024-01-18  61.349998       1.0600      -1.65%\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "\n",
        "def get_yearly_data(ticker):\n",
        "    # Get the historical data for the given ticker\n",
        "    stock = yf.Ticker(ticker)\n",
        "\n",
        "    history = stock.history(period=\"max\").reset_index()\n",
        "    # Extract the year from the Date column\n",
        "    history['Year'] = history['Date'].dt.year\n",
        "\n",
        "    # Group the data by year and get the last trading date, Adj Close, and sum of dividends for each year\n",
        "    yearly_data = history.groupby('Year').agg({'Date': 'last', 'Close': 'last', 'Dividends': 'sum'})\n",
        "    yearly_data.rename(columns={'Date': 'LastTradingDate', 'Close': 'Adj Close', 'Dividends': 'DividendSum'}, inplace=True)\n",
        "\n",
        "    # Calculate the total return for each year\n",
        "    yearly_data['TotalReturn'] = yearly_data['Adj Close'] / yearly_data['Adj Close'].shift(1) - 1\n",
        "    yearly_data['TotalReturn'] = yearly_data['TotalReturn'] * 100\n",
        "    yearly_data['TotalReturn'] = yearly_data['TotalReturn'].map(\"{:.2f}%\".format)\n",
        "\n",
        "    # Format the \"Last Trading Date\" column to display only the date portion\n",
        "    yearly_data['LastTradingDate'] = yearly_data['LastTradingDate'].dt.date\n",
        "    return yearly_data\n",
        "\n",
        "# Main program\n",
        "ticker = 'BNS.TO'\n",
        "data = get_yearly_data(ticker)\n",
        "\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ru1HenbAXbcZ",
        "outputId": "f516ecc3-6ad6-4e51-9984-93d1b1c0bf5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     LastTradingDate  Adj Close  DividendSum TotalReturn\n",
            "Year                                                    \n",
            "2001      2001-12-31   7.318615       0.1875        nan%\n",
            "2002      2002-12-31   7.094312       0.2825      -3.06%\n",
            "2003      2003-12-31   8.948480       0.3455      26.14%\n",
            "2004      2004-12-31  10.610480       0.3805      18.57%\n",
            "2005      2005-12-30  13.040280       0.4635      22.90%\n",
            "2006      2006-12-29  15.360328       0.5420      17.79%\n",
            "2007      2007-12-31  15.138770       0.6590      -1.44%\n",
            "2008      2008-12-31   9.691955       0.8115     -35.98%\n",
            "2009      2009-12-31  14.012818       0.8150      44.58%\n",
            "2010      2010-12-31  15.120352       0.7440       7.90%\n",
            "2011      2011-12-30  14.453518       0.7970      -4.41%\n",
            "2012      2012-12-31  16.829203       0.8220      16.44%\n",
            "2013      2013-12-31  21.204639       0.8320      26.00%\n",
            "2014      2014-12-31  23.722937       0.8830      11.88%\n",
            "2015      2015-12-31  22.843807       0.9390      -3.71%\n",
            "2016      2016-12-30  28.184969       1.0000      23.38%\n",
            "2017      2017-12-29  31.719797       1.0560      12.54%\n",
            "2018      2018-12-31  28.622864       1.1590      -9.76%\n",
            "2019      2019-12-31  34.536385       1.1850      20.66%\n",
            "2020      2020-12-31  34.877777       1.2870       0.99%\n",
            "2021      2021-12-31  47.284092       1.3520      35.57%\n",
            "2022      2022-12-30  42.594910       1.5330      -9.92%\n",
            "2023      2023-12-20  47.150002       1.5660      10.69%\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "\n",
        "def get_yearly_data(ticker):\n",
        "    # Get the historical data for the given ticker\n",
        "    stock = yf.Ticker(ticker)\n",
        "\n",
        "    history = stock.history(period=\"max\").reset_index()\n",
        "    # Extract the year from the Date column\n",
        "    history['Year'] = history['Date'].dt.year\n",
        "\n",
        "    # Group the data by year and get the last trading date, Adj Close, and sum of dividends for each year\n",
        "    yearly_data = history.groupby('Year').agg({'Date': 'last', 'Close': 'last', 'Dividends': 'sum'})\n",
        "    yearly_data.rename(columns={'Date': 'LastTradingDate', 'Close': 'Adj Close', 'Dividends': 'DividendSum'}, inplace=True)\n",
        "\n",
        "    # Calculate the total return for each year\n",
        "    yearly_data['TotalReturn'] = yearly_data['Adj Close'] / yearly_data['Adj Close'].shift(1) - 1\n",
        "    yearly_data['TotalReturn'] = yearly_data['TotalReturn'] * 100\n",
        "    yearly_data['TotalReturn'] = yearly_data['TotalReturn'].map(\"{:.2f}%\".format)\n",
        "\n",
        "    # Format the \"Last Trading Date\" column to display only the date portion\n",
        "    yearly_data['LastTradingDate'] = yearly_data['LastTradingDate'].dt.date\n",
        "    return yearly_data\n",
        "\n",
        "# Main program\n",
        "ticker = 'XFN.TO'\n",
        "data = get_yearly_data(ticker)\n",
        "\n",
        "print(data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWBFEcGys5LM"
      },
      "source": [
        "## backup Example 2 EndOfYear- AdjPrice, dividendSum, the yearly total return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrYkbGLYtUU6",
        "outputId": "2bc5fee0-31b1-4a1f-d733-17829b886827"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     LastTradingDate  Adj Close  DividendSum TotalReturn\n",
            "Year                                                    \n",
            "2001      2001-12-31   7.318619       0.1875        nan%\n",
            "2002      2002-12-31   7.094314       0.2825      -3.06%\n",
            "2003      2003-12-31   8.948478       0.3455      26.14%\n",
            "2004      2004-12-31  10.610483       0.3805      18.57%\n",
            "2005      2005-12-30  13.040282       0.4635      22.90%\n",
            "2006      2006-12-29  15.360314       0.5420      17.79%\n",
            "2007      2007-12-31  15.138775       0.6590      -1.44%\n",
            "2008      2008-12-31   9.691957       0.8115     -35.98%\n",
            "2009      2009-12-31  14.012822       0.8150      44.58%\n",
            "2010      2010-12-31  15.120358       0.7440       7.90%\n",
            "2011      2011-12-30  14.453508       0.7970      -4.41%\n",
            "2012      2012-12-31  16.829201       0.8220      16.44%\n",
            "2013      2013-12-31  21.204636       0.8320      26.00%\n",
            "2014      2014-12-31  23.722931       0.8830      11.88%\n",
            "2015      2015-12-31  22.843813       0.9390      -3.71%\n",
            "2016      2016-12-30  28.184965       1.0000      23.38%\n",
            "2017      2017-12-29  31.719814       1.0560      12.54%\n",
            "2018      2018-12-31  28.622869       1.1590      -9.76%\n",
            "2019      2019-12-31  34.536362       1.1850      20.66%\n",
            "2020      2020-12-31  34.877773       1.2870       0.99%\n",
            "2021      2021-12-31  47.284081       1.3520      35.57%\n",
            "2022      2022-12-30  42.594910       1.5330      -9.92%\n",
            "2023      2023-12-22  47.810001       1.5660      12.24%\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "\n",
        "def get_yearly_data(ticker):\n",
        "    # Get the historical data for the given ticker\n",
        "    stock = yf.Ticker(ticker)\n",
        "\n",
        "    history = stock.history(period=\"max\").reset_index()\n",
        "    # Extract the year from the Date column\n",
        "    history['Year'] = history['Date'].dt.year\n",
        "\n",
        "    # Group the data by year and get the last trading date, Adj Close, and sum of dividends for each year\n",
        "    yearly_data = history.groupby('Year').agg({'Date': 'last', 'Close': 'last', 'Dividends': 'sum'})\n",
        "    yearly_data.rename(columns={'Date': 'LastTradingDate', 'Close': 'Adj Close', 'Dividends': 'DividendSum'}, inplace=True)\n",
        "\n",
        "    # Calculate the total return for each year\n",
        "    yearly_data['TotalReturn'] = yearly_data['Adj Close'] / yearly_data['Adj Close'].shift(1) - 1\n",
        "    yearly_data['TotalReturn'] = yearly_data['TotalReturn'] * 100\n",
        "    yearly_data['TotalReturn'] = yearly_data['TotalReturn'].map(\"{:.2f}%\".format)\n",
        "\n",
        "    # Format the \"Last Trading Date\" column to display only the date portion\n",
        "    yearly_data['LastTradingDate'] = yearly_data['LastTradingDate'].dt.date\n",
        "    return yearly_data\n",
        "\n",
        "# Main program\n",
        "ticker = 'XFN.TO'\n",
        "data = get_yearly_data(ticker)\n",
        "\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOzk2Ug18kfk"
      },
      "source": [
        "# Example 1   Close, Adj Close, dividendSum, yearly total return, yearly total return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eepIxIrz8vZb",
        "outputId": "cb7e62f0-788f-44ca-9868-42057918373b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n",
            "           Close   Adj Close  DivSum DivRatio   Return TotalReturn CalReturn\n",
            "Year                                                                        \n",
            "1993   46.593750   27.004082   1.134    2.43%     nan%        nan%      nan%\n",
            "1994   45.562500   27.111387   1.227    2.69%   -2.21%       0.40%     0.42%\n",
            "1995   61.484375   37.426991   1.278    2.08%   34.95%      38.05%    37.75%\n",
            "1996   73.843750   45.847099   1.355    1.83%   20.10%      22.50%    22.31%\n",
            "1997   97.062500   61.194511   1.377    1.42%   31.44%      33.48%    33.31%\n",
            "1998  123.312500   78.752670   1.416    1.15%   27.04%      28.69%    28.50%\n",
            "1999  146.875000   94.809868   1.445    0.98%   19.11%      20.39%    20.28%\n",
            "2000  131.187500   85.573944   1.505    1.15%  -10.68%      -9.74%    -9.66%\n",
            "2001  114.300003   75.511703   1.424    1.25%  -12.87%     -11.76%   -11.79%\n",
            "2002   88.230003   59.212761   1.498    1.70%  -22.81%     -21.58%   -21.50%\n",
            "2003  111.279999   75.899895   1.630    1.46%   26.12%      28.18%    27.97%\n",
            "2004  120.870003   84.019615   2.197    1.82%    8.62%      10.70%    10.59%\n",
            "2005  124.510002   88.076309   2.149    1.73%    3.01%       4.83%     4.79%\n",
            "2006  141.619995  102.032219   2.446    1.73%   13.74%      15.85%    15.71%\n",
            "2007  146.210007  107.282990   2.701    1.85%    3.24%       5.15%     5.15%\n",
            "2008   90.239998   67.808205   2.721    3.02%  -38.28%     -36.80%   -36.42%\n",
            "2009  111.440002   85.676903   2.177    1.95%   23.49%      26.35%    25.91%\n",
            "2010  125.750000   98.576530   2.266    1.80%   12.84%      15.06%    14.87%\n",
            "2011  125.500000  100.444534   2.576    2.05%   -0.20%       1.89%     1.85%\n",
            "2012  142.410004  116.505959   3.103    2.18%   13.47%      15.99%    15.95%\n",
            "2013  184.690002  154.146423   3.351    1.81%   29.69%      32.31%    32.04%\n",
            "2014  205.539993  174.900421   3.836    1.87%   11.29%      13.46%    13.37%\n",
            "2015  203.869995  177.059143   4.206    2.06%   -0.81%       1.23%     1.23%\n",
            "2016  223.529999  198.302551   4.539    2.03%    9.64%      12.00%    11.87%\n",
            "2017  266.859985  241.344894   4.802    1.80%   19.38%      21.71%    21.53%\n",
            "2018  249.919998  230.317810   5.101    2.04%   -6.35%      -4.57%    -4.44%\n",
            "2019  321.859985  302.231934   5.619    1.75%   28.79%      31.22%    31.03%\n",
            "2020  373.880005  357.636017   5.691    1.52%   16.16%      18.33%    17.93%\n",
            "2021  474.959991  460.380371   5.715    1.20%   27.04%      28.73%    28.56%\n",
            "2022  382.429993  376.704590   6.320    1.65%  -19.48%     -18.18%   -18.15%\n",
            "2023  475.309998  475.309998   6.633    1.40%   24.29%      26.18%    26.02%\n",
            "2024  476.350006  476.350006   0.000    0.00%    0.22%       0.22%     0.22%\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "script_version = '(2024-01-10.1)'\n",
        "\n",
        "def get_yearly_data(ticker):\n",
        "    stock = yf.Ticker(ticker)\n",
        "    #-------- mainly for downloading 'Dividends'\n",
        "    history = stock.history(period=\"max\")\n",
        "    dividend_history=history['Dividends']\n",
        "    dividend_history.index=dividend_history.index.date\n",
        "\n",
        "    #-------- mainly for downloading 'Close','Adj Close'\n",
        "    dld_history=yf.download(ticker, period=\"max\")\n",
        "    dld_history=dld_history[['Close','Adj Close']]\n",
        "    date_range = pd.date_range(start=dld_history.index.min(), end=dld_history.index.max(), freq='D')\n",
        "    complete_history = pd.DataFrame(index=date_range)\n",
        "\n",
        "    # Merge the complete DataFrame with the original stock_history\n",
        "    complete_history = complete_history.merge(dld_history, how='left', left_index=True, right_index=True)\n",
        "    complete_history[['Close','Adj Close']] = complete_history[['Close','Adj Close']].ffill()\n",
        "\n",
        "    # Merge dividend into complete_history\n",
        "    complete_history = complete_history.merge(dividend_history, how='left', left_index=True, right_index=True)\n",
        "    # replace all NaN values in the 'Dividends' column with 0.0\n",
        "    complete_history['Dividends'] = complete_history['Dividends'].fillna(0.0)\n",
        "\n",
        "    complete_history['Year']=complete_history.index.year\n",
        "    complete_history['Date']=complete_history.index\n",
        "    yearly_data = complete_history.groupby('Year').agg({'Date': 'last', 'Close': 'last', 'Adj Close': 'last','Dividends': 'sum'})\n",
        "    yearly_data.rename(columns={'Dividends': 'DivSum'}, inplace=True)\n",
        "\n",
        "    # calculating 'Return' and 'TotalReturn'\n",
        "    yearly_data['DivRatio']=yearly_data['DivSum'] / yearly_data['Close']\n",
        "    yearly_data['Return']=yearly_data['Close'].pct_change()\n",
        "    yearly_data['TotalReturn']=yearly_data['Adj Close'].pct_change()\n",
        "\n",
        "    '''\n",
        "    The CalReturn column is the yearly total return calculated from un-adjusted \"Close\" prices and yearly \"dividend sum\",\n",
        "    which is expected to be equal to the total return that is calculated from \"Adj Close\" prices\n",
        "    '''\n",
        "    yearly_data['CalReturn'] = (yearly_data['Close'] + yearly_data['DivSum']) / yearly_data['Close'].shift(1) - 1\n",
        "    # set the display format\n",
        "    yearly_data[['DivRatio','Return','TotalReturn','CalReturn']] = yearly_data[['DivRatio','Return','TotalReturn','CalReturn']].mul(100).round(2)\n",
        "    yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']] = yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']].applymap(\"{:.2f}%\".format)\n",
        "    # 'Date' column is no longer required\n",
        "    yearly_data.drop('Date', axis=1, inplace=True)\n",
        "    return yearly_data\n",
        "\n",
        "# Main program\n",
        "ticker = 'spy'\n",
        "data = get_yearly_data(ticker)\n",
        "print(data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0eSXU3OT8Nq"
      },
      "source": [
        "## Backup Example 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xz_mQUhgtDK",
        "outputId": "a60f4a97-1c40-49e0-81b6-efd755da4e61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n",
            "Int64Index([1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005,\n",
            "            2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016,\n",
            "            2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024],\n",
            "           dtype='int64', name='Year')\n",
            "          Close  Adj Close  DivSum DivRatio   Return TotalReturn CalReturn\n",
            "Year                                                                      \n",
            "1995   2.521655   0.375843  0.3100   12.29%     nan%        nan%      nan%\n",
            "1996   4.001173   0.649847  0.2475    6.19%   58.67%      72.90%    68.49%\n",
            "1997   6.034898   1.057006  0.3700    6.13%   50.83%      62.65%    60.08%\n",
            "1998   6.240640   1.172339  0.5050    8.09%    3.41%      10.91%    11.78%\n",
            "1999   5.906535   1.176476  0.4500    7.62%   -5.35%       0.35%     1.86%\n",
            "2000   8.449734   1.810161  0.5200    6.15%   43.06%      53.86%    51.86%\n",
            "2001   9.857067   2.272631  0.6500    6.59%   16.66%      25.55%    24.35%\n",
            "2002  10.849034   2.648309  0.5550    5.12%   10.06%      16.53%    15.69%\n",
            "2003  13.960698   3.658474  0.8400    6.02%   28.68%      38.14%    36.42%\n",
            "2004  17.896240   4.948505  1.4200    7.93%   28.19%      35.26%    38.36%\n",
            "2005  20.945824   6.224387  1.3600    6.49%   17.04%      25.78%    24.64%\n",
            "2006  24.429447   7.792041  1.5600    6.39%   16.63%      25.19%    24.08%\n",
            "2007  24.396732   8.365835  1.7900    7.34%   -0.13%       7.36%     7.19%\n",
            "2008  16.666161   6.086138  1.4500    8.70%  -31.69%     -27.25%   -25.74%\n",
            "2009  26.189634  10.791875  2.4500    9.35%   57.14%      77.32%    71.84%\n",
            "2010  31.534714  13.926373  1.9600    6.22%   20.41%      29.04%    27.89%\n",
            "2011  29.154375  13.778358  2.0800    7.13%   -7.55%      -1.06%    -0.95%\n",
            "2012  34.318264  17.390564  2.2400    6.53%   17.71%      26.22%    25.40%\n",
            "2013  40.938728  21.855120  1.8200    4.45%   19.29%      25.67%    24.59%\n",
            "2014  42.450718  24.089825  2.5600    6.03%    3.69%      10.23%     9.95%\n",
            "2015  37.878754  23.406111  3.4200    9.03%  -10.77%      -2.84%    -2.71%\n",
            "2016  52.814129  34.742161  2.9200    5.53%   39.43%      48.43%    47.14%\n",
            "2017  59.575417  41.375114  3.1000    5.20%   12.80%      19.09%    18.67%\n",
            "2018  52.271996  38.557133  3.3400    6.39%  -12.26%      -6.81%    -6.65%\n",
            "2019  58.438301  45.181747  2.6400    4.52%   11.80%      17.18%    16.85%\n",
            "2020  58.262184  48.554295  3.6000    6.18%   -0.30%       7.46%     5.86%\n",
            "2021  80.388626  71.662102  4.6000    5.72%   37.98%      47.59%    45.87%\n",
            "2022  61.188591  56.207729  2.0300    3.32%  -23.88%     -21.57%   -21.36%\n",
            "2023  63.439999  62.380001  4.1800    6.59%    3.68%      10.98%    10.51%\n",
            "2024  63.275002  63.275002  1.0600    1.68%   -0.26%       1.43%     1.41%\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "script_version = '(2024-01-10.1)'\n",
        "\n",
        "def get_yearly_data(ticker):\n",
        "    stock = yf.Ticker(ticker)\n",
        "    #-------- mainly for downloading 'Dividends'\n",
        "    history = stock.history(period=\"max\")\n",
        "    dividend_history=history['Dividends']\n",
        "    dividend_history.index=dividend_history.index.date\n",
        "\n",
        "    #-------- mainly for downloading 'Close','Adj Close'\n",
        "    dld_history=yf.download(ticker, period=\"max\")\n",
        "    dld_history=dld_history[['Close','Adj Close']]\n",
        "    date_range = pd.date_range(start=dld_history.index.min(), end=dld_history.index.max(), freq='D')\n",
        "    complete_history = pd.DataFrame(index=date_range)\n",
        "\n",
        "    # Merge the complete DataFrame with the original stock_history\n",
        "    complete_history = complete_history.merge(dld_history, how='left', left_index=True, right_index=True)\n",
        "    complete_history[['Close','Adj Close']] = complete_history[['Close','Adj Close']].ffill()\n",
        "\n",
        "    # Merge dividend into complete_history\n",
        "    complete_history = complete_history.merge(dividend_history, how='left', left_index=True, right_index=True)\n",
        "    # replace all NaN values in the 'Dividends' column with 0.0\n",
        "    complete_history['Dividends'] = complete_history['Dividends'].fillna(0.0)\n",
        "\n",
        "    complete_history['Year']=complete_history.index.year\n",
        "    complete_history['Date']=complete_history.index\n",
        "    yearly_data = complete_history.groupby('Year').agg({'Date': 'last', 'Close': 'last', 'Adj Close': 'last','Dividends': 'sum'})\n",
        "    yearly_data.rename(columns={'Dividends': 'DivSum'}, inplace=True)\n",
        "\n",
        "    # calculating 'Return' and 'TotalReturn'\n",
        "    yearly_data['DivRatio']=yearly_data['DivSum'] / yearly_data['Close']\n",
        "    yearly_data['Return']=yearly_data['Close'].pct_change()\n",
        "    yearly_data['TotalReturn']=yearly_data['Adj Close'].pct_change()\n",
        "\n",
        "    '''\n",
        "    The CalReturn column is the yearly total return calculated from un-adjusted \"Close\" prices and yearly \"dividend sum\",\n",
        "    which is expected to be equal to the total return that is calculated from \"Adj Close\" prices\n",
        "    '''\n",
        "    yearly_data['CalReturn'] = (yearly_data['Close'] + yearly_data['DivSum']) / yearly_data['Close'].shift(1) - 1\n",
        "    # set the display format\n",
        "    yearly_data[['DivRatio','Return','TotalReturn','CalReturn']] = yearly_data[['DivRatio','Return','TotalReturn','CalReturn']].mul(100).round(2)\n",
        "    yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']] = yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']].applymap(\"{:.2f}%\".format)\n",
        "    # 'Date' column is no longer required\n",
        "    yearly_data.drop('Date', axis=1, inplace=True)\n",
        "    print(yearly_data.index)\n",
        "    return yearly_data\n",
        "\n",
        "# Main program\n",
        "ticker = 'BNS.TO'\n",
        "data = get_yearly_data(ticker)\n",
        "print(data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2G0THy3U9BS"
      },
      "source": [
        "# Example 3: retrieve  current last stock price from yahoo finance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxmycH3ZRKf3",
        "outputId": "fdef7833-1cff-4b2a-c909-779c8f3cea9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Market last price from Yahoo Finance (Current time: 2023-12-21 02:41:31)\n",
            "   spy  vfv.to  xiu.to  xic.to  xfn.to  ry.to  enb.to\n",
            "468.26  111.66   31.42   32.93   47.15 132.33   47.28\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "def get_current_prices(tickers_list):\n",
        "    # Create an empty dictionary to store data\n",
        "    data = {}\n",
        "    # Get current prices for each ticker\n",
        "    for ticker in tickers_list:\n",
        "        # Create a ticker object\n",
        "        stock = yf.Ticker(ticker)\n",
        "        # Get the current market last price\n",
        "        last_price = stock.basic_info['last_price']\n",
        "        # Store the price in the dictionary\n",
        "        data[ticker] = [last_price]\n",
        "    # Create a DataFrame from the dictionary\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "# Define the list of tickers\n",
        "tickers_list = [\"spy\", \"vfv.to\", \"xiu.to\", \"xic.to\", \"xfn.to\", \"ry.to\", \"enb.to\"]\n",
        "# Call the function to get the DataFrame\n",
        "current_prices_df = get_current_prices(tickers_list)\n",
        "\n",
        "current_datetime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "print(f\"Market last price from Yahoo Finance (Current time: {current_datetime})\")\n",
        "# Print the returned DataFrame with only 2 digit after dot, without index\n",
        "print(current_prices_df.round(2).to_string(index=False))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cMF7seJRPlI"
      },
      "source": [
        "# a simple example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-jpv38gxMh3",
        "outputId": "40442aba-a49e-4e6a-c6dc-320c64e13bb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The last_price price of XFN.TO is $48.3000\n"
          ]
        }
      ],
      "source": [
        "#!pip install yfinance\n",
        "import yfinance as yf\n",
        "ticker = \"XFN.TO\"\n",
        "# Create a ticker object\n",
        "stock = yf.Ticker(ticker)\n",
        "# Get the current market price\n",
        "price = stock.basic_info['last_price']\n",
        "print(f\"The last_price price of {ticker} is ${price:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdAP5TphNLjK"
      },
      "source": [
        "# trailing total return from hard-coded data input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8bTSNjzncS5"
      },
      "source": [
        "\n",
        "Certainly! To convert the provided data into a 2-dimensional array in Python, you can use a list of lists. Here's how you can represent the data:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "data_array = [\n",
        "    [\"Year\", \"Total Return %\"],\n",
        "    [2013, 26.00],\n",
        "    [2014, 11.89],\n",
        "    [2015, -3.71],\n",
        "    [2016, 23.36],\n",
        "    [2017, 12.54],\n",
        "    [2018, -9.76],\n",
        "    [2019, 20.66],\n",
        "    [2020, 0.98],\n",
        "    [2021, 35.56],\n",
        "    [2022, -9.93],\n",
        "    [\"YTD\", None]  # Assuming YTD is a placeholder, set to None or provide the actual value\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2cBD4i7DDPa",
        "outputId": "41433735-e2a8-4c4f-f20f-854f770c3bf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Year          2013   2014  2015   2016   2017  2018   2019  2020   2021  2022\n",
            "Total Return  26.0  11.89 -3.71  23.36  12.54 -9.76  20.66  0.98  35.56 -9.93\n",
            "1-Year -9.93%\n",
            "3-Year 7.23%\n",
            "5-Year 6.07%\n",
            "10-Year 9.73%\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "\n",
        "ticker = 'XFN.TO'\n",
        "# data from Ishare web site\n",
        "# xfn_yearly_total_return as input\n",
        "xfn_yearly_total_return = [\n",
        "    ['Year', 'Total Return'],\n",
        "    [2013, 26.0],\n",
        "    [2014, 11.89],\n",
        "    [2015, -3.71],\n",
        "    [2016, 23.36],\n",
        "    [2017, 12.54],\n",
        "    [2018, -9.76],\n",
        "    [2019, 20.66],\n",
        "    [2020, 0.98],\n",
        "    [2021, 35.56],\n",
        "    [2022, -9.93],\n",
        "]\n",
        "# expect output according Ishare web\n",
        "xfn_trailing_return_At_2022_END = [\n",
        "    [\"years\", \"1y\", \"3y\", \"5y\", \"10y\"],\n",
        "    [\"Total Return %\", -9.90, 7.24, 6.07, 9.73]\n",
        "]\n",
        "\n",
        "# Define a function to calculate the annualized trailing total return for a given number of years\n",
        "def get_trailing_return(data, years):\n",
        "    # Get the total return values for the last n years\n",
        "    trailing_data = data['Total Return'].tail(years)\n",
        "\n",
        "    # Convert the percentage strings to numeric values\n",
        "    #trailing_data = trailing_data.str.replace('%', '').astype(float)\n",
        "    trailing_data = trailing_data.astype(str).str.replace('%', '').astype(float)\n",
        "\n",
        "    # Calculate the annualized trailing total return using the formula from Investopedia[^1^][1]:\n",
        "    # Annualized Return = [(1 + r1) * (1 + r2) * ... * (1 + rn)]^(1/n) - 1\n",
        "    # Where r1, r2, ..., rn are the total return values for each year\n",
        "    annualized_return = (trailing_data / 100 + 1).prod() ** (1 / years) - 1\n",
        "\n",
        "    # Format the result as a percentage with two decimal places\n",
        "    annualized_return = \"{:.2f}%\".format(annualized_return * 100)\n",
        "    return annualized_return\n",
        "\n",
        "TRAIL_RETURN_AS_YEAR=2022\n",
        "\n",
        "# Define a list of years to calculate the trailing returns\n",
        "years_list = [1, 3, 5, 10]\n",
        "\n",
        "# please add a code section to convert variable 'xfn_yearly_total_return'\n",
        "# to variable 'data' for get_trailing_return(data, years)\n",
        "# Convert the list of lists to a pandas dataframe\n",
        "import pandas as pd\n",
        "data = pd.DataFrame(xfn_yearly_total_return[1:], columns=xfn_yearly_total_return[0])\n",
        "# Set the index to the year column\n",
        "data.set_index('Year', inplace=True)\n",
        "#print(data.transpose())\n",
        "print(data.T)\n",
        "\n",
        "# Loop through the list and print the trailing returns for each year\n",
        "for years in years_list:\n",
        "    trailing_return = get_trailing_return(data, years)\n",
        "    print(f\"{years}-Year {trailing_return}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEQhgbR-gyeb"
      },
      "source": [
        "# Example 5: non-calender year/single stock - calculate  the trailing total returns (used in my article in google site)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCIZH_lOqUyX",
        "outputId": "63ff1794-43c3-42a5-9df3-e46b2b544e8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The annualized trailing return for XFN.to \n",
            " as 2023-12-15\n",
            "       XFN.to\n",
            "years        \n",
            "1      10.65%\n",
            "3      10.56%\n",
            "5      10.49%\n",
            "10      8.31%\n",
            "15     11.12%\n",
            "20      8.66%\n",
            "25        N/A\n",
            "30        N/A\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Import libraries\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "# Define the stock ticker and the time periods\n",
        "ticker = \"XFN.to\"\n",
        "stock = yf.Ticker(ticker)\n",
        "# Define the stock ticker and the time periods\n",
        "periods = [1, 3, 5, 10, 15, 20, 25, 30] # in years\n",
        "\n",
        "calculation_start_day=\"1990-01-01\"\n",
        "calculation_end_day=\"2023-12-15\"\n",
        "#calculation_end_day=\"2022-12-31\"\n",
        "\n",
        "#--------------------------------------------------------------------------------------------\n",
        "# Step 1: Fetch the historical data, Calculate annual returns based on the any last trading day of each year\n",
        "# Check if the variable 'last_trading_day' is defined in the local scope\n",
        "# \"Close\" price in history is actually Adj Close in download, taking account of dividends and splits\n",
        "# Get the historical data for the given ticker\n",
        "stock = yf.Ticker(ticker)\n",
        "''' Get annual total return data.\n",
        "   .resample('Y'): Resamples the time series data annually ('Y'), based on the last trading day of each year.\n",
        "   .resample('A'): Resamples the time series data annually ('A'), based on the any trading day of each year.\n",
        "'''\n",
        "annual_returns = stock.history(period=\"max\", start=calculation_start_day,\n",
        "  end=calculation_end_day)[\"Close\"].resample('A').ffill().pct_change().dropna()\n",
        "annual_returns_df = pd.DataFrame(annual_returns, columns=['Close'])\n",
        "annual_returns_df.rename(columns={'Close': ticker}, inplace=True)\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------------------------------------\n",
        "# Step 2: Calculate the annualized trailing return for each period\n",
        "# Create a DataFrame to store the annualized trailing return information\n",
        "trailing_return_data = []\n",
        "for period in periods:\n",
        "    data=annual_returns_df[ticker].tail(period)\n",
        "    if (len(data) != period):\n",
        "       trailing_return_data.append(\"NaN\")\n",
        "       continue;\n",
        "    # Calculate the annualized trailing return\n",
        "    \"\"\" Calculate the annualized trailing total return using the formula from Investopedia[^1^][1]:\n",
        "        Annualized Return = [(1 + r1) * (1 + r2) * ... * (1 + rn)]^(1/n) - 1\n",
        "        Where r1, r2, ..., rn are the total return values for each year                    \"\"\"\n",
        "    atr = (1 + data).prod() ** (1 / period) - 1\n",
        "    trailing_return_data.append(atr)\n",
        "\n",
        "# Create an  DataFrame with years_list as the index for trailing total returns\n",
        "trailing_return_column = pd.DataFrame(trailing_return_data, index=periods, columns=[ticker])\n",
        "# Print or display the DataFrame\n",
        "print(f\"The annualized trailing return for {ticker} \\n as\", calculation_end_day)\n",
        "trailing_return_column_percent = trailing_return_column.astype(float) * 100\n",
        "trailing_return_column_formatted = trailing_return_column_percent.applymap(lambda x: f\"{x:.2f}%\" if not pd.isna(x) else \"N/A\")\n",
        "trailing_return_column_formatted.index.name=\"years\"\n",
        "print(trailing_return_column_formatted)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqPycCuApdA9"
      },
      "source": [
        "## backup Example 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jm3lU2e7R4Y",
        "outputId": "59324986-0f8b-4cac-fd84-29596e83dbf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The annualized trailing return for XFN.to \n",
            " as 2023-12-15\n",
            "    XFN.to\n",
            "1   10.65%\n",
            "3   10.56%\n",
            "5   10.49%\n",
            "10   8.31%\n",
            "15  11.12%\n",
            "20   8.66%\n",
            "25     N/A\n",
            "30     N/A\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Import libraries\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "# Define the stock ticker and the time periods\n",
        "ticker = \"XFN.to\"\n",
        "stock = yf.Ticker(ticker)\n",
        "# Define the stock ticker and the time periods\n",
        "periods = [1, 3, 5, 10, 15, 20, 25, 30] # in years\n",
        "\n",
        "calculation_start_day=\"1990-01-01\"\n",
        "calculation_end_day=\"2023-12-15\"\n",
        "#calculation_end_day=\"2022-12-31\"\n",
        "\n",
        "#--------------------------------------------------------------------------------------------\n",
        "# Step 1: Fetch the historical data, Calculate annual returns based on the any last trading day of each year\n",
        "# Check if the variable 'last_trading_day' is defined in the local scope\n",
        "# \"Close\" price in history is actually Adj Close in download, taking account of dividends and splits\n",
        "# Get the historical data for the given ticker\n",
        "stock = yf.Ticker(ticker)\n",
        "''' Get annual total return data.\n",
        "   .resample('Y'): Resamples the time series data annually ('Y'), based on the last trading day of each year.\n",
        "   .resample('A'): Resamples the time series data annually ('A'), based on the any trading day of each year.\n",
        "'''\n",
        "annual_returns = stock.history(period=\"max\", start=calculation_start_day,\n",
        "  end=calculation_end_day)[\"Close\"].resample('A').ffill().pct_change().dropna()\n",
        "annual_returns_df = pd.DataFrame(annual_returns, columns=['Close'])\n",
        "annual_returns_df.rename(columns={'Close': ticker}, inplace=True)\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------------------------------------\n",
        "# Step 2: Calculate the annualized trailing return for each period\n",
        "# Create a DataFrame to store the annualized trailing return information\n",
        "trailing_return_data = []\n",
        "for period in periods:\n",
        "    data=annual_returns_df[ticker].tail(period)\n",
        "    if (len(data) != period):\n",
        "       trailing_return_data.append(\"NaN\")\n",
        "       continue;\n",
        "    # Calculate the annualized trailing return\n",
        "    \"\"\" Calculate the annualized trailing total return using the formula from Investopedia[^1^][1]:\n",
        "        Annualized Return = [(1 + r1) * (1 + r2) * ... * (1 + rn)]^(1/n) - 1\n",
        "        Where r1, r2, ..., rn are the total return values for each year                    \"\"\"\n",
        "    atr = (1 + data).prod() ** (1 / period) - 1\n",
        "    trailing_return_data.append(atr)\n",
        "\n",
        "# Create an  DataFrame with years_list as the index for trailing total returns\n",
        "trailing_return_column = pd.DataFrame(trailing_return_data, index=periods, columns=[ticker])\n",
        "# Print or display the DataFrame\n",
        "print(f\"The annualized trailing return for {ticker} \\n as\", calculation_end_day)\n",
        "trailing_return_column_percent = trailing_return_column.astype(float) * 100\n",
        "trailing_return_column_formatted = trailing_return_column_percent.applymap(lambda x: f\"{x:.2f}%\" if not pd.isna(x) else \"N/A\")\n",
        "print(trailing_return_column_formatted)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiSyOQulOQM2"
      },
      "source": [
        "# ! Example 6 non-calender year (multiple stocks)  the trailing total returns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1UMhsVGOVbA",
        "outputId": "50180838-41ab-437d-9754-f95cf8afeb16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The result of version-(2023.1224.1) script  start:\n",
            " ###\n",
            "\n",
            "Annual Total Return (%) as  2023-12-28\n",
            "              spy  vfv.to  vgg.to  zlu.to  xiu.to  xfn.to  ry.to  td.to  \\\n",
            "date                                                                      \n",
            "1994-12-28   0.40     NaN     NaN     NaN     NaN     NaN    NaN    NaN   \n",
            "1995-12-28  38.05     NaN     NaN     NaN     NaN     NaN    NaN    NaN   \n",
            "1996-12-28  22.50     NaN     NaN     NaN     NaN     NaN  59.20  52.30   \n",
            "1997-12-28  33.48     NaN     NaN     NaN     NaN     NaN  61.23  56.87   \n",
            "1998-12-28  28.69     NaN     NaN     NaN     NaN     NaN   3.58   2.50   \n",
            "1999-12-28  20.39     NaN     NaN     NaN     NaN     NaN -14.82  46.56   \n",
            "2000-12-28  -9.74     NaN     NaN     NaN    8.02     NaN  65.34  14.84   \n",
            "2001-12-28 -11.76     NaN     NaN     NaN  -14.24     NaN   4.90  -2.81   \n",
            "2002-12-28 -21.58     NaN     NaN     NaN  -14.02   -3.06  14.85 -14.56   \n",
            "2003-12-28  28.18     NaN     NaN     NaN   24.82   26.14   9.13  31.37   \n",
            "2004-12-28  10.70     NaN     NaN     NaN   13.28   18.57   7.38  18.83   \n",
            "2005-12-28   4.83     NaN     NaN     NaN   25.47   22.90  45.87  26.19   \n",
            "2006-12-28  15.85     NaN     NaN     NaN   19.12   17.79  26.02  16.55   \n",
            "2007-12-28   5.15     NaN     NaN     NaN   10.83   -1.44  -5.57   2.66   \n",
            "2008-12-28 -36.80     NaN     NaN     NaN  -31.09  -35.98 -25.70 -35.15   \n",
            "2009-12-28  26.35     NaN     NaN     NaN   31.35   44.58  63.73  59.16   \n",
            "2010-12-28  15.06     NaN     NaN     NaN   13.85    7.90  -3.85  16.52   \n",
            "2011-12-28   1.89     NaN     NaN     NaN   -9.31   -4.41   3.31   6.22   \n",
            "2012-12-28  15.99     NaN     NaN     NaN    7.92   16.44  20.06  13.80   \n",
            "2013-12-28  32.31   40.91     NaN     NaN   13.06   26.00  24.05  24.13   \n",
            "2014-12-28  13.46   24.05   21.49   37.61   11.94   11.88  16.64  14.83   \n",
            "2015-12-28   1.23   20.29   14.58   24.17   -7.80   -3.71  -3.81   1.42   \n",
            "2016-12-28  12.00    7.63    7.28    5.11   20.32   23.38  27.84  26.92   \n",
            "2017-12-28  21.71   13.67   13.99    5.06    9.58   12.54  17.12  15.15   \n",
            "2018-12-28  -4.57    2.94    5.20    8.39   -7.82   -9.76  -5.50  -4.57   \n",
            "2019-12-28  31.22   25.15   23.32   20.48   21.81   20.66  14.33  11.66   \n",
            "2020-12-28  18.33   15.61   12.67    1.56    5.27    0.99   6.52   3.72   \n",
            "2021-12-28  28.73   27.51   22.23   20.72   28.06   35.57  33.09  40.15   \n",
            "2022-12-28 -18.18  -12.58   -4.21    7.94   -6.35   -9.92  -1.52  -6.01   \n",
            "2023-12-28  26.49   23.13   11.26   -3.98   11.99   12.95   9.99   1.08   \n",
            "\n",
            "             na.to  bmo.to  bns.to  slf.to  gwo.to  bce.to   t.to  rci-b.to  \\\n",
            "date                                                                          \n",
            "1994-12-28     NaN     NaN     NaN     NaN     NaN     NaN    NaN       NaN   \n",
            "1995-12-28     NaN     NaN     NaN     NaN     NaN     NaN    NaN       NaN   \n",
            "1996-12-28   29.73   45.09   58.67     NaN     NaN     NaN  24.41    -33.77   \n",
            "1997-12-28   75.97   48.63   50.83     NaN     NaN   52.22  56.17    -31.68   \n",
            "1998-12-28    7.92   -0.14    2.80     NaN     NaN   24.40  -4.06     97.83   \n",
            "1999-12-28  -22.65  -17.50   -5.97     NaN     NaN  130.73 -12.46    158.61   \n",
            "2000-12-28   43.78   65.00   43.06     NaN     NaN   42.94  21.36    -28.22   \n",
            "2001-12-28   11.65   -5.86   16.66  -13.63     NaN  -14.16 -39.27      7.19   \n",
            "2002-12-28    8.75   19.99   10.06  -19.87     NaN  -17.56 -25.07    -45.94   \n",
            "2003-12-28   35.63   32.34   28.68   23.78   25.64    5.65  52.83     46.26   \n",
            "2004-12-28   18.76   11.08   26.60   27.27   20.62    4.44  42.95     47.75   \n",
            "2005-12-28   25.57   16.21   17.04   19.14   18.24    0.79  34.88     56.94   \n",
            "2006-12-28   12.71    9.85   16.63    8.15   13.56   17.88  14.49     41.45   \n",
            "2007-12-28  -17.21  -14.97   -0.13   15.88    8.41   31.36  -4.93     30.88   \n",
            "2008-12-28  -36.68  -41.27  -31.69  -46.96  -39.47  -34.98 -21.45    -15.97   \n",
            "2009-12-28  101.42   90.94   57.14   12.47   37.32   22.58  -2.85     -7.15   \n",
            "2010-12-28   18.31    7.83   20.41    4.70    3.02   28.68  39.93      9.64   \n",
            "2011-12-28    9.41    1.82   -7.55  -33.66  -18.54   26.82  32.22     18.00   \n",
            "2012-12-28   11.61   14.28   17.71   48.51   26.08    5.77  17.54     19.77   \n",
            "2013-12-28   19.48   21.63   19.29   48.78   40.18   13.57  16.74     10.49   \n",
            "2014-12-28   16.48   20.79    3.69   14.75    6.64   21.76  18.98     -2.06   \n",
            "2015-12-28  -14.56   -0.88  -10.77    6.77    6.64    5.28  -4.95     10.31   \n",
            "2016-12-28   41.68   28.95   39.43   23.87    6.04   13.66  16.77     12.57   \n",
            "2017-12-28   19.77    7.99   12.80    4.39    4.08    9.18  16.35     27.57   \n",
            "2018-12-28   -6.92   -7.94  -12.26   -9.44  -15.76   -5.65  -0.66     12.53   \n",
            "2019-12-28   34.04   17.51   11.80   35.86   24.53   17.39  16.30     -5.06   \n",
            "2020-12-28    2.65    1.29   -0.30   -0.52   -2.64   -3.92   5.23     -4.94   \n",
            "2021-12-28   39.02   45.89   37.98   28.82   31.45   27.90  23.58      5.03   \n",
            "2022-12-28   -1.45   -6.19  -22.84   -6.73  -12.58   -4.33  -8.27      8.69   \n",
            "2023-12-28   14.97   12.51    0.96   13.09   45.71   -7.44  -5.22      0.76   \n",
            "\n",
            "            enb.to  trp.to  zlb.to  \n",
            "date                                \n",
            "1994-12-28     NaN     NaN     NaN  \n",
            "1995-12-28     NaN     NaN     NaN  \n",
            "1996-12-28   32.52   30.92     NaN  \n",
            "1997-12-28   71.09   37.26     NaN  \n",
            "1998-12-28   11.59  -27.43     NaN  \n",
            "1999-12-28  -15.71  -40.61     NaN  \n",
            "2000-12-28   58.66   44.57     NaN  \n",
            "2001-12-28    2.82   19.65     NaN  \n",
            "2002-12-28    1.48   19.25     NaN  \n",
            "2003-12-28   30.48   25.88     NaN  \n",
            "2004-12-28   15.17   10.31     NaN  \n",
            "2005-12-28   25.51   27.54     NaN  \n",
            "2006-12-28   14.40   14.94     NaN  \n",
            "2007-12-28    2.63    3.49     NaN  \n",
            "2008-12-28    2.01  -14.92     NaN  \n",
            "2009-12-28   27.48   14.28     NaN  \n",
            "2010-12-28   19.66    9.54     NaN  \n",
            "2011-12-28   39.75   22.03     NaN  \n",
            "2012-12-28   16.23    9.89     NaN  \n",
            "2013-12-28   10.92    7.38   20.71  \n",
            "2014-12-28   32.31   21.94   28.36  \n",
            "2015-12-28  -20.43  -17.44    2.73  \n",
            "2016-12-28   28.05   39.37   13.03  \n",
            "2017-12-28   -8.84    5.23   11.07  \n",
            "2018-12-28   -8.30  -16.01   -2.76  \n",
            "2019-12-28   29.43   48.49   21.92  \n",
            "2020-12-28  -15.30  -20.74    0.66  \n",
            "2021-12-28   29.98   20.34   22.93  \n",
            "2022-12-28   13.96   -2.76   -0.35  \n",
            "2023-12-28   -2.83    4.42    8.73  \n",
            "\n",
            "Annualized Trailing Returns as  2023-12-28 :\n",
            "         spy vfv.to vgg.to zlu.to xiu.to xfn.to  ry.to  td.to  na.to bmo.to  \\\n",
            "Years                                                                         \n",
            "1      26.49  23.13  11.26  -3.98  11.99  12.95   9.99   1.08  14.97  12.51   \n",
            "2       1.74   3.75   3.23   1.81   2.41   0.87   4.08  -2.53   6.44   2.73   \n",
            "3      10.04  11.13   9.21   7.76  10.33  11.32  12.97  10.01  16.35  15.47   \n",
            "5      15.65  14.71   12.6   8.89  11.49  10.94  11.91   9.05  16.73  12.88   \n",
            "10     11.95  14.07  12.48  12.09   8.01   8.54  10.79   9.61  13.04   10.9   \n",
            "15     13.88    N/A    N/A    N/A   8.86  11.27  13.58  13.82  17.91  15.06   \n",
            "20      9.62    N/A    N/A    N/A   7.96   8.77  11.82  11.03  12.44   9.19   \n",
            "25      7.47    N/A    N/A    N/A    N/A    N/A  12.08  11.41  12.53  10.38   \n",
            "30     10.04    N/A    N/A    N/A    N/A    N/A    N/A    N/A    N/A    N/A   \n",
            "\n",
            "      bns.to slf.to gwo.to bce.to   t.to rci-b.to enb.to trp.to zlb.to  \n",
            "Years                                                                   \n",
            "1       0.96  13.09  45.71  -7.44  -5.22     0.76  -2.83   4.42   8.73  \n",
            "2     -11.74    2.7  12.86  -5.89  -6.76     4.65   5.23   0.76   4.09  \n",
            "3       2.43  10.76  18.75   4.24   2.42     4.78  12.91   6.91  10.02  \n",
            "5       3.68  12.93  15.21   5.02   5.63     0.75   9.55   7.54  10.33  \n",
            "10      4.34  10.17   7.94   6.73   7.22     6.13   5.92   5.96  10.16  \n",
            "15      9.23  10.62  10.33  10.72  11.25     7.31  11.16    8.1    N/A  \n",
            "20      7.73   7.91   7.98   8.25  11.07    12.42  11.27    7.9    N/A  \n",
            "25      9.58    N/A    N/A  10.46   7.45    11.83  11.56   8.13    N/A  \n",
            "30       N/A    N/A    N/A    N/A    N/A      N/A    N/A    N/A    N/A  \n",
            "\n",
            "Cumulative Returns as end of year 2023-12-28 :\n",
            "           spy  vfv.to  vgg.to  zlu.to  xiu.to  xfn.to    ry.to    td.to  \\\n",
            "Years                                                                      \n",
            "1        26.49   23.13   11.26   -3.98   11.99   12.95     9.99     1.08   \n",
            "2         3.50    7.63    6.57    3.65    4.88    1.75     8.32    -5.00   \n",
            "3        33.24   37.24   30.26   25.13   34.31   37.94    44.16    33.14   \n",
            "5       106.89   98.57   80.98   53.11   72.22   68.08    75.55    54.19   \n",
            "10      209.13  273.14  224.10  213.17  116.03  126.88   178.67   150.43   \n",
            "15      602.73     NaN     NaN     NaN  257.50  396.39   574.92   596.88   \n",
            "20      527.81     NaN     NaN     NaN  362.31  437.63   834.73   710.81   \n",
            "25      505.07     NaN     NaN     NaN     NaN     NaN  1630.86  1388.69   \n",
            "30     1664.58     NaN     NaN     NaN     NaN     NaN      NaN      NaN   \n",
            "\n",
            "         na.to   bmo.to  bns.to  slf.to  gwo.to   bce.to    t.to  rci-b.to  \\\n",
            "Years                                                                        \n",
            "1        14.97    12.51    0.96   13.09   45.71    -7.44   -5.22      0.76   \n",
            "2        13.30     5.54  -22.10    5.48   27.38   -11.44  -13.05      9.52   \n",
            "3        57.52    53.97    7.48   35.89   67.44    13.26    7.45     15.02   \n",
            "5       116.72    83.26   19.80   83.64  103.00    27.75   31.50      3.80   \n",
            "10      240.64   181.28   52.97  163.46  114.63    91.74  100.71     81.22   \n",
            "15     1084.31   719.60  275.74  354.78  337.11   360.73  394.96    188.11   \n",
            "20      943.55   480.33  342.99  358.43  364.57   388.21  716.04    939.26   \n",
            "25     1811.47  1081.09  884.49     NaN     NaN  1103.83  502.92   1535.07   \n",
            "30         NaN      NaN     NaN     NaN     NaN      NaN     NaN       NaN   \n",
            "\n",
            "        enb.to  trp.to  zlb.to  \n",
            "Years                           \n",
            "1        -2.83    4.42    8.73  \n",
            "2        10.74    1.53    8.34  \n",
            "3        43.94   22.18   33.18  \n",
            "5        57.78   43.81   63.45  \n",
            "10       77.80   78.33  163.09  \n",
            "15      388.65  221.47     NaN  \n",
            "20      746.03  357.70     NaN  \n",
            "25     1440.39  605.74     NaN  \n",
            "30         NaN     NaN     NaN  \n",
            "\n",
            "Compound Annual Growth Rates (GAGRs) (%) as end of year 2023-12-28 :\n",
            "         spy  vfv.to  vgg.to  zlu.to  xiu.to  xfn.to  ry.to  td.to  na.to  \\\n",
            "Years                                                                       \n",
            "1      26.49   23.13   11.26   -3.98   11.99   12.95   9.99   1.08  14.97   \n",
            "2       1.74    3.75    3.23    1.81    2.41    0.87   4.08  -2.53   6.44   \n",
            "3      10.04   11.13    9.21    7.76   10.33   11.32  12.97  10.01  16.35   \n",
            "5      15.65   14.71   12.60    8.89   11.49   10.94  11.91   9.05  16.73   \n",
            "10     11.95   14.07   12.48   12.09    8.01    8.54  10.79   9.61  13.04   \n",
            "15     13.88     NaN     NaN     NaN    8.86   11.27  13.58  13.82  17.91   \n",
            "20      9.62     NaN     NaN     NaN    7.96    8.77  11.82  11.03  12.44   \n",
            "25      7.47     NaN     NaN     NaN     NaN     NaN  12.08  11.41  12.53   \n",
            "30     10.04     NaN     NaN     NaN     NaN     NaN    NaN    NaN    NaN   \n",
            "\n",
            "       bmo.to  bns.to  slf.to  gwo.to  bce.to   t.to  rci-b.to  enb.to  \\\n",
            "Years                                                                    \n",
            "1       12.51    0.96   13.09   45.71   -7.44  -5.22      0.76   -2.83   \n",
            "2        2.73  -11.74    2.70   12.86   -5.89  -6.76      4.65    5.23   \n",
            "3       15.47    2.43   10.76   18.75    4.24   2.42      4.78   12.91   \n",
            "5       12.88    3.68   12.93   15.21    5.02   5.63      0.75    9.55   \n",
            "10      10.90    4.34   10.17    7.94    6.73   7.22      6.13    5.92   \n",
            "15      15.06    9.23   10.62   10.33   10.72  11.25      7.31   11.16   \n",
            "20       9.19    7.73    7.91    7.98    8.25  11.07     12.42   11.27   \n",
            "25      10.38    9.58     NaN     NaN   10.46   7.45     11.83   11.56   \n",
            "30        NaN     NaN     NaN     NaN     NaN    NaN       NaN     NaN   \n",
            "\n",
            "       trp.to  zlb.to  \n",
            "Years                  \n",
            "1        4.42    8.73  \n",
            "2        0.76    4.09  \n",
            "3        6.91   10.02  \n",
            "5        7.54   10.33  \n",
            "10       5.96   10.16  \n",
            "15       8.10     NaN  \n",
            "20       7.90     NaN  \n",
            "25       8.13     NaN  \n",
            "30        NaN     NaN  \n",
            "The result of version-(2023.1224.1) script  ends here.\n",
            " ###\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "### CODE start (for AI tool)\n",
        "\"\"\"\n",
        "result_marker='###'\n",
        "script_version = '(2023.1224.1)'\n",
        "print(f\"The result of version-{script_version} script  start:\\n {result_marker}\")\n",
        "# Import libraries\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "#!pip install pytz\n",
        "import pytz\n",
        "print_yearly_total_return = True\n",
        "\n",
        "# Define the stock ticker and the time periods\n",
        "periods = [1, 3, 5, 10, 15, 20, 25, 30] # in years\n",
        "tickers_list1=[\"spy\", \"vfv.to\",\"vgg.to\", \"zlu.to\", \"xiu.to\", \"xfn.to\", \"ry.to\", \"td.to\", \"na.to\",\"bmo.to\",\n",
        "\"bns.to\", \"slf.to\", \"gwo.to\", \"bce.to\", \"t.to\", \"rci-b.to\", \"enb.to\", \"trp.to\", \"zlb.to\"]\n",
        "tickers_list2=[\"xfn.to\", \"xiu.to\", \"ry.to\", \"vfv.to\", \"spy\"]\n",
        "tickers_list3=[\"spy\", \"vfv.to\", \"goog\", \"msft\", \"meta\", \"tsla\", \"shop.to\", \"amzn\", \"abnb\", \"ibm\"]\n",
        "tickers_list=tickers_list1\n",
        "\n",
        "calculation_start_day=\"1993-01-01\"\n",
        "#calculation_end_day=\"2022-12-31\"\n",
        "# Get today's date, use .strftime(\"%Y-%m-%d\") to convert to a string\n",
        "calculation_end_day=datetime.now(pytz.timezone('America/New_York')).date().strftime(\"%Y-%m-%d\") # Get today's date\n",
        "#-------------------------------------------------------------------\n",
        "# step 1: fetch retrieve yearly total returns by yfinance & display\n",
        "# Function to fetch data from yfinance and extract yearly total returns\n",
        "def get_annual_returns_df(ticker):\n",
        "    # Get the historical data for the given ticker\n",
        "    stock = yf.Ticker(ticker)\n",
        "    ''' Get annual total return data.\n",
        "        .resample('Y'): Resamples the time series data annually ('Y'), based on the last trading day of each year.\n",
        "        .resample('A'): Resamples the time series data annually ('A'), based on the any trading day of each year.\n",
        "    '''\n",
        "    annual_returns = stock.history(period=\"max\", start=calculation_start_day,\n",
        "      end=calculation_end_day)[\"Close\"].resample('A').ffill().pct_change().dropna()\n",
        "    annual_returns_df = pd.DataFrame(annual_returns, columns=['Close'])\n",
        "    annual_returns_df.rename(columns={'Close': ticker}, inplace=True)\n",
        "    return annual_returns_df\n",
        "# Create an empty DataFrame to store all tickers' total returns\n",
        "all_tickers_returns_df = pd.DataFrame()\n",
        "\n",
        "# Loop through each ticker in the list\n",
        "for ticker in tickers_list:\n",
        "    ticker_returns_df = get_annual_returns_df(ticker)\n",
        "    if not ticker_returns_df.empty:\n",
        "        if all_tickers_returns_df.empty:\n",
        "            all_tickers_returns_df = ticker_returns_df\n",
        "        else:\n",
        "            # Concatenate DataFrames\n",
        "            all_tickers_returns_df = pd.concat([all_tickers_returns_df, ticker_returns_df], axis=1)\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 2:\n",
        "# Define a list of years to calculate the trailing returns, cumulative returns, and so on\n",
        "# remove the row of current year row since it is not a full year.\n",
        "years_list = [1, 2, 3, 5, 10, 15, 20, 25, 30]\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 3: calculate the annualized trailing total return from the data generated in step 1 & display\n",
        "# Define a function to calculate the annualized trailing total return for a given number of years\n",
        "def get_trailing_return(ticker, data, years):\n",
        "    # Get the total return values for the last n years\n",
        "    trailing_data = data[ticker].tail(years)\n",
        "    # Check if there are empty values within years\n",
        "    if trailing_data.isna().any():\n",
        "        return \"N/A\"\n",
        "    # Check if there are valid total return values for all years\n",
        "    if len(trailing_data) == years:\n",
        "        # Convert the percentage strings to numeric values\n",
        "        trailing_data = trailing_data.astype(str).str.replace('%', '').astype(float)\n",
        "        \"\"\" Calculate the annualized trailing total return using the formula from Investopedia[^1^][1]:\n",
        "            Annualized Return = [(1 + r1) * (1 + r2) * ... * (1 + rn)]^(1/n) - 1\n",
        "            Where r1, r2, ..., rn are the total return values for each year                    \"\"\"\n",
        "        annualized_trailing_return = (trailing_data + 1).prod() ** (1 / years) - 1\n",
        "\n",
        "        # Format the result as a percentage with two decimal places\n",
        "        annualized_trailing_return = annualized_trailing_return * 100\n",
        "        annualized_trailing_return = annualized_trailing_return.round(2)\n",
        "        return annualized_trailing_return\n",
        "    else:\n",
        "        return \"N/A\"\n",
        "\n",
        "# Define a function to Loop through the list and print the trailing returns for each num_years\n",
        "def get_trailing_return_column(ticker):\n",
        "    trailing_return_column = {}\n",
        "    for num_years in years_list:\n",
        "        # Check if the ticker data is available in all_tickers_returns_df\n",
        "        if ticker in all_tickers_returns_df.columns:\n",
        "            # using data from step 1, avoiding get_annual_returns_df(ticker) for less traffic from yahoo server\n",
        "            data = all_tickers_returns_df[[ticker]]\n",
        "            trailing_return = get_trailing_return(ticker, data, num_years)\n",
        "            trailing_return_column[f\"{num_years}-Year\"] = trailing_return\n",
        "        else:\n",
        "            print(f\"Data not available for {ticker}. Skipping.\")\n",
        "            trailing_return_column[f\"{num_years}-Year\"] = \"N/A\"\n",
        "    return trailing_return_column\n",
        "\n",
        "# Create an empty DataFrame to store all tickers' trailing returns\n",
        "all_tickers_trailing_returns_df = pd.DataFrame(index=years_list)\n",
        "\n",
        "# Loop through each ticker in the list\n",
        "for ticker in tickers_list:\n",
        "    trailing_returns = get_trailing_return_column(ticker)\n",
        "    # Add the trailing returns to the DataFrame\n",
        "    all_tickers_trailing_returns_df[ticker] = pd.Series(trailing_returns).values\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 4: calculate the cumulative return from the data (all_tickers_returns_df) generated in step 1 & display\n",
        "# 4.1 Define a function to calculate the cumulative return for a given number of years from a ticker\n",
        "def get_cumulative_return(ticker, data, years):\n",
        "    # Calculate the cumulative return\n",
        "    cumulative_return = (1 + data[ticker]).rolling(window=years).apply(lambda x: x.prod(), raw=True) - 1\n",
        "    return cumulative_return\n",
        "\n",
        "# Create an empty DataFrame with years_list as the index for cumulative  returns\n",
        "all_tickers_cumulative_returns_df = pd.DataFrame(index=years_list)\n",
        "\n",
        "# Define a function to Loop through the list and return the cumulative returns for each num_years\n",
        "def get_cumulative_return_column(ticker):\n",
        "    cumulative_returns = {}\n",
        "    for years in years_list:\n",
        "        # Calculate the cumulative return for the given number of years\n",
        "        cumulative_return = get_cumulative_return(ticker, all_tickers_returns_df, years)\n",
        "        # Get the last value, which is the cumulative return up to the current year\n",
        "        cumulative_returns[years] = cumulative_return.iloc[-1]\n",
        "    return cumulative_returns\n",
        "\n",
        "# Loop through each ticker in the list\n",
        "for ticker in tickers_list:\n",
        "    cumulative_returns = get_cumulative_return_column(ticker)\n",
        "    # Add the trailing returns to the DataFrame\n",
        "    all_tickers_cumulative_returns_df[ticker] = pd.Series(cumulative_returns).values\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 5: calculate the  CAGR from the data (all_tickers_cumulative_returns_df) generated earlier & display\n",
        "# Define a function to calculate the CAGR from the cumulative value and the years\n",
        "import numpy as np\n",
        "def calculate_cagr(value, years):\n",
        "    # Otherwise, calculate the CAGR using the formula\n",
        "    cagr = (value + 1) ** (1 / np.array(years)) - 1\n",
        "    #print(\"debug-cagr\\n\", cagr, \"end\")\n",
        "    return cagr\n",
        "\n",
        "# Define a function to format the Float64Index values into percentage strings\n",
        "def format_to_percentage(value):\n",
        "    # If any element in the value array is not null, format it as a percentage string with two decimal places\n",
        "    if np.any(pd.notnull(value)):\n",
        "        return f\"{value:.2f}%\"\n",
        "    # Otherwise, return None\n",
        "    return None\n",
        "\n",
        "# Apply the calculate_cagr function to each column of the DataFrame\n",
        "all_tickers_cagrs_df = all_tickers_cumulative_returns_df.apply(lambda x: calculate_cagr(x, x.index), axis=0)\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Display the formatted DataFrame  all_tickers_returns_df\n",
        "if (print_yearly_total_return):\n",
        "    all_tickers_returns_df.index=all_tickers_returns_df.index.date\n",
        "    all_tickers_returns_df.index.name='date'\n",
        "    # Convert calculation_end_day to a datetime object, replace the index's mon/day portion of date\n",
        "    calculation_end_day_datetime_obj = datetime.strptime(calculation_end_day, \"%Y-%m-%d\")\n",
        "    all_tickers_returns_df.index = all_tickers_returns_df.index.map(\\\n",
        "      lambda x: x.replace(month=calculation_end_day_datetime_obj.month,\\\n",
        "      day=calculation_end_day_datetime_obj.day))\n",
        "    print(\"\\nAnnual Total Return (%) as \", calculation_end_day)\n",
        "    print(all_tickers_returns_df.round(4) * 100)\n",
        "\n",
        "# Display the trailing returns DataFrame\n",
        "print(\"\\nAnnualized Trailing Returns as \", calculation_end_day, \":\")\n",
        "all_tickers_trailing_returns_df.index.name = 'Years'\n",
        "print(all_tickers_trailing_returns_df)\n",
        "\n",
        "# Display the cumulative returns DataFrame\n",
        "print(\"\\nCumulative Returns as end of year\", calculation_end_day, \":\")\n",
        "all_tickers_cumulative_returns_df.index.name = 'Years'\n",
        "print(all_tickers_cumulative_returns_df.round(4) * 100)\n",
        "\n",
        "# Display the formatted DataFrame  all_tickers_cagrs_df\n",
        "print(\"\\nCompound Annual Growth Rates (GAGRs) (%) as end of year\", calculation_end_day, \":\")\n",
        "all_tickers_cagrs_df.index.name = 'Years'\n",
        "print(all_tickers_cagrs_df.round(4) * 100)\n",
        "\n",
        "print(f\"The result of version-{script_version} script  ends here.\\n {result_marker}\")\n",
        "### CODE end (for AI tool)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74DxptLyGxtm"
      },
      "source": [
        "## Backup Example 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ehKATtW9mKN",
        "outputId": "f550e2fb-71e4-41df-c653-f1bcd9a22b5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The result of version-(2023.1224.1) script  start:\n",
            " ###\n",
            "\n",
            "Annual Total Return (%) as  2023-12-25\n",
            "              spy  vfv.to    goog    msft    meta    tsla  shop.to    amzn  \\\n",
            "date                                                                         \n",
            "1994-12-25   0.40     NaN     NaN   51.63     NaN     NaN      NaN     NaN   \n",
            "1995-12-25  38.05     NaN     NaN   43.56     NaN     NaN      NaN     NaN   \n",
            "1996-12-25  22.50     NaN     NaN   88.32     NaN     NaN      NaN     NaN   \n",
            "1997-12-25  33.48     NaN     NaN   56.43     NaN     NaN      NaN     NaN   \n",
            "1998-12-25  28.69     NaN     NaN  114.60     NaN     NaN      NaN  966.39   \n",
            "1999-12-25  20.39     NaN     NaN   68.36     NaN     NaN      NaN   42.18   \n",
            "2000-12-25  -9.74     NaN     NaN  -62.85     NaN     NaN      NaN  -79.56   \n",
            "2001-12-25 -11.76     NaN     NaN   52.74     NaN     NaN      NaN  -30.47   \n",
            "2002-12-25 -21.58     NaN     NaN  -21.96     NaN     NaN      NaN   74.58   \n",
            "2003-12-25  28.18     NaN     NaN    6.82     NaN     NaN      NaN  178.56   \n",
            "2004-12-25  10.70     NaN     NaN    9.13     NaN     NaN      NaN  -15.83   \n",
            "2005-12-25   4.83     NaN  115.19   -0.94     NaN     NaN      NaN    6.46   \n",
            "2006-12-25  15.85     NaN   11.00   15.84     NaN     NaN      NaN  -16.31   \n",
            "2007-12-25   5.15     NaN   50.17   20.84     NaN     NaN      NaN  134.77   \n",
            "2008-12-25 -36.79     NaN  -55.51  -44.39     NaN     NaN      NaN  -44.65   \n",
            "2009-12-25  26.35     NaN  101.52   60.47     NaN     NaN      NaN  162.32   \n",
            "2010-12-25  15.06     NaN   -4.20   -6.52     NaN     NaN      NaN   33.81   \n",
            "2011-12-25   1.89     NaN    8.74   -4.52     NaN    7.25      NaN   -3.83   \n",
            "2012-12-25  15.99     NaN    9.52    5.80     NaN   18.59      NaN   44.93   \n",
            "2013-12-25  32.31   40.91   58.43   44.30  105.30  344.14      NaN   58.96   \n",
            "2014-12-25  13.46   24.05   -5.97   27.56   42.76   47.85      NaN  -22.18   \n",
            "2015-12-25   1.23   20.29   44.56   22.69   34.15    7.91      NaN  117.78   \n",
            "2016-12-25  12.00    7.63    1.71   15.08    9.93  -10.97    62.08   10.95   \n",
            "2017-12-25  21.71   13.67   35.58   40.73   53.38   45.70   120.29   55.96   \n",
            "2018-12-25  -4.57    2.94   -1.03   20.80  -25.71    6.89    48.52   28.43   \n",
            "2019-12-25  31.22   25.15   29.10   57.56   56.57   25.70   173.48   23.03   \n",
            "2020-12-25  18.33   15.61   31.03   42.53   33.09  743.44   178.39   76.26   \n",
            "2021-12-25  28.73   27.51   65.17   52.48   23.13   49.76    21.18    2.38   \n",
            "2022-12-25 -18.18  -12.58  -38.67  -28.02  -64.22  -65.03   -73.01  -49.62   \n",
            "2023-12-25  25.74   22.81   60.85   57.58  193.66  105.02   116.70   82.64   \n",
            "\n",
            "             abnb    ibm  \n",
            "date                      \n",
            "1994-12-25    NaN  32.22  \n",
            "1995-12-25    NaN  25.68  \n",
            "1996-12-25    NaN  67.70  \n",
            "1997-12-25    NaN  39.31  \n",
            "1998-12-25    NaN  77.47  \n",
            "1999-12-25    NaN  17.58  \n",
            "2000-12-25    NaN -20.84  \n",
            "2001-12-25    NaN  43.00  \n",
            "2002-12-25    NaN -35.46  \n",
            "2003-12-25    NaN  20.50  \n",
            "2004-12-25    NaN   7.19  \n",
            "2005-12-25    NaN -15.83  \n",
            "2006-12-25    NaN  19.77  \n",
            "2007-12-25    NaN  12.84  \n",
            "2008-12-25    NaN -20.78  \n",
            "2009-12-25    NaN  58.64  \n",
            "2010-12-25    NaN  14.26  \n",
            "2011-12-25    NaN  27.41  \n",
            "2012-12-25    NaN   5.92  \n",
            "2013-12-25    NaN  -0.18  \n",
            "2014-12-25    NaN -12.39  \n",
            "2015-12-25    NaN -11.42  \n",
            "2016-12-25    NaN  25.21  \n",
            "2017-12-25    NaN  -3.99  \n",
            "2018-12-25    NaN -22.56  \n",
            "2019-12-25    NaN  23.58  \n",
            "2020-12-25    NaN  -1.16  \n",
            "2021-12-25  13.41  16.65  \n",
            "2022-12-25 -48.65  10.64  \n",
            "2023-12-25  64.68  20.80  \n",
            "\n",
            "Annualized Trailing Returns as  2023-12-25 :\n",
            "         spy vfv.to   goog   msft    meta    tsla shop.to   amzn   abnb    ibm\n",
            "Years                                                                         \n",
            "1      25.74  22.81  60.85  57.58  193.66  105.02   116.7  82.64  64.68  20.80\n",
            "2       1.43   3.61  -0.68   6.50     2.5  -15.33  -23.52  -4.07  -8.04  15.61\n",
            "3       9.82  11.03  17.67  20.03    8.96     2.4  -10.84  -1.97  -1.38  15.95\n",
            "5      15.51  14.65  22.48  31.17   21.94   62.65   40.09  15.36    N/A  13.75\n",
            "10     11.88  14.04  17.72  28.09   20.52   38.07     N/A  22.64    N/A   3.24\n",
            "15     13.84    N/A  21.53  24.26     N/A     N/A     N/A  31.36    N/A   8.41\n",
            "20      9.59    N/A    N/A  16.68     N/A     N/A     N/A  22.54    N/A   6.06\n",
            "25      7.44    N/A    N/A  12.11     N/A     N/A     N/A  17.58    N/A   4.97\n",
            "30     10.02    N/A    N/A  20.04     N/A     N/A     N/A    N/A    N/A  11.04\n",
            "\n",
            "Cumulative Returns as end of year 2023-12-25 :\n",
            "           spy  vfv.to     goog      msft    meta     tsla  shop.to     amzn  \\\n",
            "Years                                                                          \n",
            "1        25.74   22.81    60.85     57.58  193.66   105.02   116.70    82.64   \n",
            "2         2.88    7.36    -1.35     13.42    5.07   -28.31   -41.51    -7.98   \n",
            "3        32.44   36.89    62.93     72.93   29.37     7.36   -29.13    -5.79   \n",
            "5       105.65   98.06   175.63    288.36  169.58  1038.25   439.59   104.29   \n",
            "10      207.27  272.18   411.30   1089.09  546.64  2418.18      NaN   669.43   \n",
            "15      598.51     NaN  1762.57   2499.99     NaN      NaN      NaN  5883.62   \n",
            "20      524.05     NaN      NaN   2088.16     NaN      NaN      NaN  5731.24   \n",
            "25      501.44     NaN      NaN   1642.61     NaN      NaN      NaN  5630.86   \n",
            "30     1653.99     NaN      NaN  23880.52     NaN      NaN      NaN      NaN   \n",
            "\n",
            "        abnb      ibm  \n",
            "Years                  \n",
            "1      64.68    20.80  \n",
            "2     -15.43    33.65  \n",
            "3      -4.09    55.90  \n",
            "5        NaN    90.42  \n",
            "10       NaN    37.58  \n",
            "15       NaN   235.97  \n",
            "20       NaN   224.50  \n",
            "25       NaN   235.91  \n",
            "30       NaN  2214.21  \n",
            "\n",
            "Compound Annual Growth Rates (GAGRs) (%) as end of year 2023-12-25 :\n",
            "         spy  vfv.to   goog   msft    meta    tsla  shop.to   amzn   abnb  \\\n",
            "Years                                                                       \n",
            "1      25.74   22.81  60.85  57.58  193.66  105.02   116.70  82.64  64.68   \n",
            "2       1.43    3.61  -0.68   6.50    2.50  -15.33   -23.52  -4.07  -8.04   \n",
            "3       9.82   11.03  17.67  20.03    8.96    2.40   -10.84  -1.97  -1.38   \n",
            "5      15.51   14.65  22.48  31.17   21.94   62.65    40.09  15.36    NaN   \n",
            "10     11.88   14.04  17.72  28.09   20.52   38.07      NaN  22.64    NaN   \n",
            "15     13.84     NaN  21.53  24.26     NaN     NaN      NaN  31.36    NaN   \n",
            "20      9.59     NaN    NaN  16.68     NaN     NaN      NaN  22.54    NaN   \n",
            "25      7.44     NaN    NaN  12.11     NaN     NaN      NaN  17.58    NaN   \n",
            "30     10.02     NaN    NaN  20.04     NaN     NaN      NaN    NaN    NaN   \n",
            "\n",
            "         ibm  \n",
            "Years         \n",
            "1      20.80  \n",
            "2      15.61  \n",
            "3      15.95  \n",
            "5      13.75  \n",
            "10      3.24  \n",
            "15      8.41  \n",
            "20      6.06  \n",
            "25      4.97  \n",
            "30     11.04  \n",
            "The result of version-(2023.1224.1) script  ends here.\n",
            " ###\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "### CODE start (for AI tool)\n",
        "\"\"\"\n",
        "result_marker='###'\n",
        "script_version = '(2023.1224.1)'\n",
        "print(f\"The result of version-{script_version} script  start:\\n {result_marker}\")\n",
        "# Import libraries\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "print_yearly_total_return = True\n",
        "\n",
        "# Define the stock ticker and the time periods\n",
        "periods = [1, 3, 5, 10, 15, 20, 25, 30] # in years\n",
        "tickers_list1=[\"spy\", \"vfv.to\",\"vgg.to\", \"zlu.to\", \"xiu.to\", \"xfn.to\", \"ry.to\", \"td.to\", \"na.to\",\n",
        "    \"slf.to\", \"gwo.to\", \"bce.to\", \"t.to\", \"rci-b.to\", \"enb.to\", \"trp.to\", \"zlb.to\"]\n",
        "tickers_list2=[\"xfn.to\", \"xiu.to\", \"ry.to\", \"vfv.to\", \"spy\"]\n",
        "tickers_list3=[\"spy\", \"vfv.to\", \"goog\", \"msft\", \"meta\", \"tsla\", \"shop.to\", \"amzn\", \"abnb\", \"ibm\"]\n",
        "tickers_list=tickers_list3\n",
        "\n",
        "calculation_start_day=\"1993-01-01\"\n",
        "#calculation_end_day=\"2022-12-31\"\n",
        "# Get today's date, use .strftime(\"%Y-%m-%d\") to convert to a string\n",
        "calculation_end_day=datetime.now().date().strftime(\"%Y-%m-%d\") # Get today's date\n",
        "#-------------------------------------------------------------------\n",
        "# step 1: fetch retrieve yearly total returns by yfinance & display\n",
        "# Function to fetch data from yfinance and extract yearly total returns\n",
        "def get_annual_returns_df(ticker):\n",
        "    # Get the historical data for the given ticker\n",
        "    stock = yf.Ticker(ticker)\n",
        "    ''' Get annual total return data.\n",
        "        .resample('Y'): Resamples the time series data annually ('Y'), based on the last trading day of each year.\n",
        "        .resample('A'): Resamples the time series data annually ('A'), based on the any trading day of each year.\n",
        "    '''\n",
        "    annual_returns = stock.history(period=\"max\", start=calculation_start_day,\n",
        "      end=calculation_end_day)[\"Close\"].resample('A').ffill().pct_change().dropna()\n",
        "    annual_returns_df = pd.DataFrame(annual_returns, columns=['Close'])\n",
        "    annual_returns_df.rename(columns={'Close': ticker}, inplace=True)\n",
        "    return annual_returns_df\n",
        "# Create an empty DataFrame to store all tickers' total returns\n",
        "all_tickers_returns_df = pd.DataFrame()\n",
        "\n",
        "# Loop through each ticker in the list\n",
        "for ticker in tickers_list:\n",
        "    ticker_returns_df = get_annual_returns_df(ticker)\n",
        "    if not ticker_returns_df.empty:\n",
        "        if all_tickers_returns_df.empty:\n",
        "            all_tickers_returns_df = ticker_returns_df\n",
        "        else:\n",
        "            # Concatenate DataFrames\n",
        "            all_tickers_returns_df = pd.concat([all_tickers_returns_df, ticker_returns_df], axis=1)\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 2:\n",
        "# Define a list of years to calculate the trailing returns, cumulative returns, and so on\n",
        "# remove the row of current year row since it is not a full year.\n",
        "years_list = [1, 2, 3, 5, 10, 15, 20, 25, 30]\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 3: calculate the annualized trailing total return from the data generated in step 1 & display\n",
        "# Define a function to calculate the annualized trailing total return for a given number of years\n",
        "def get_trailing_return(ticker, data, years):\n",
        "    # Get the total return values for the last n years\n",
        "    trailing_data = data[ticker].tail(years)\n",
        "    # Check if there are empty values within years\n",
        "    if trailing_data.isna().any():\n",
        "        return \"N/A\"\n",
        "    # Check if there are valid total return values for all years\n",
        "    if len(trailing_data) == years:\n",
        "        # Convert the percentage strings to numeric values\n",
        "        trailing_data = trailing_data.astype(str).str.replace('%', '').astype(float)\n",
        "        \"\"\" Calculate the annualized trailing total return using the formula from Investopedia[^1^][1]:\n",
        "            Annualized Return = [(1 + r1) * (1 + r2) * ... * (1 + rn)]^(1/n) - 1\n",
        "            Where r1, r2, ..., rn are the total return values for each year                    \"\"\"\n",
        "        annualized_trailing_return = (trailing_data + 1).prod() ** (1 / years) - 1\n",
        "\n",
        "        # Format the result as a percentage with two decimal places\n",
        "        annualized_trailing_return = annualized_trailing_return * 100\n",
        "        annualized_trailing_return = annualized_trailing_return.round(2)\n",
        "        return annualized_trailing_return\n",
        "    else:\n",
        "        return \"N/A\"\n",
        "\n",
        "# Define a function to Loop through the list and print the trailing returns for each num_years\n",
        "def get_trailing_return_column(ticker):\n",
        "    trailing_return_column = {}\n",
        "    for num_years in years_list:\n",
        "        # Check if the ticker data is available in all_tickers_returns_df\n",
        "        if ticker in all_tickers_returns_df.columns:\n",
        "            # using data from step 1, avoiding get_annual_returns_df(ticker) for less traffic from yahoo server\n",
        "            data = all_tickers_returns_df[[ticker]]\n",
        "            trailing_return = get_trailing_return(ticker, data, num_years)\n",
        "            trailing_return_column[f\"{num_years}-Year\"] = trailing_return\n",
        "        else:\n",
        "            print(f\"Data not available for {ticker}. Skipping.\")\n",
        "            trailing_return_column[f\"{num_years}-Year\"] = \"N/A\"\n",
        "    return trailing_return_column\n",
        "\n",
        "# Create an empty DataFrame to store all tickers' trailing returns\n",
        "all_tickers_trailing_returns_df = pd.DataFrame(index=years_list)\n",
        "\n",
        "# Loop through each ticker in the list\n",
        "for ticker in tickers_list:\n",
        "    trailing_returns = get_trailing_return_column(ticker)\n",
        "    # Add the trailing returns to the DataFrame\n",
        "    all_tickers_trailing_returns_df[ticker] = pd.Series(trailing_returns).values\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 4: calculate the cumulative return from the data (all_tickers_returns_df) generated in step 1 & display\n",
        "# 4.1 Define a function to calculate the cumulative return for a given number of years from a ticker\n",
        "def get_cumulative_return(ticker, data, years):\n",
        "    # Calculate the cumulative return\n",
        "    cumulative_return = (1 + data[ticker]).rolling(window=years).apply(lambda x: x.prod(), raw=True) - 1\n",
        "    return cumulative_return\n",
        "\n",
        "# Create an empty DataFrame with years_list as the index for cumulative  returns\n",
        "all_tickers_cumulative_returns_df = pd.DataFrame(index=years_list)\n",
        "\n",
        "# Define a function to Loop through the list and return the cumulative returns for each num_years\n",
        "def get_cumulative_return_column(ticker):\n",
        "    cumulative_returns = {}\n",
        "    for years in years_list:\n",
        "        # Calculate the cumulative return for the given number of years\n",
        "        cumulative_return = get_cumulative_return(ticker, all_tickers_returns_df, years)\n",
        "        # Get the last value, which is the cumulative return up to the current year\n",
        "        cumulative_returns[years] = cumulative_return.iloc[-1]\n",
        "    return cumulative_returns\n",
        "\n",
        "# Loop through each ticker in the list\n",
        "for ticker in tickers_list:\n",
        "    cumulative_returns = get_cumulative_return_column(ticker)\n",
        "    # Add the trailing returns to the DataFrame\n",
        "    all_tickers_cumulative_returns_df[ticker] = pd.Series(cumulative_returns).values\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 5: calculate the  CAGR from the data (all_tickers_cumulative_returns_df) generated earlier & display\n",
        "# Define a function to calculate the CAGR from the cumulative value and the years\n",
        "import numpy as np\n",
        "def calculate_cagr(value, years):\n",
        "    # Otherwise, calculate the CAGR using the formula\n",
        "    cagr = (value + 1) ** (1 / np.array(years)) - 1\n",
        "    #print(\"debug-cagr\\n\", cagr, \"end\")\n",
        "    return cagr\n",
        "\n",
        "# Define a function to format the Float64Index values into percentage strings\n",
        "def format_to_percentage(value):\n",
        "    # If any element in the value array is not null, format it as a percentage string with two decimal places\n",
        "    if np.any(pd.notnull(value)):\n",
        "        return f\"{value:.2f}%\"\n",
        "    # Otherwise, return None\n",
        "    return None\n",
        "\n",
        "# Apply the calculate_cagr function to each column of the DataFrame\n",
        "all_tickers_cagrs_df = all_tickers_cumulative_returns_df.apply(lambda x: calculate_cagr(x, x.index), axis=0)\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Display the formatted DataFrame  all_tickers_returns_df\n",
        "if (print_yearly_total_return):\n",
        "    all_tickers_returns_df.index=all_tickers_returns_df.index.date\n",
        "    all_tickers_returns_df.index.name='date'\n",
        "    # Convert calculation_end_day to a datetime object, replace the index's mon/day portion of date\n",
        "    calculation_end_day_datetime_obj = datetime.strptime(calculation_end_day, \"%Y-%m-%d\")\n",
        "    all_tickers_returns_df.index = all_tickers_returns_df.index.map(\\\n",
        "      lambda x: x.replace(month=calculation_end_day_datetime_obj.month,\\\n",
        "      day=calculation_end_day_datetime_obj.day))\n",
        "    print(\"\\nAnnual Total Return (%) as \", calculation_end_day)\n",
        "    print(all_tickers_returns_df.round(4) * 100)\n",
        "\n",
        "# Display the trailing returns DataFrame\n",
        "print(\"\\nAnnualized Trailing Returns as \", calculation_end_day, \":\")\n",
        "all_tickers_trailing_returns_df.index.name = 'Years'\n",
        "print(all_tickers_trailing_returns_df)\n",
        "\n",
        "# Display the cumulative returns DataFrame\n",
        "print(\"\\nCumulative Returns as end of year\", calculation_end_day, \":\")\n",
        "all_tickers_cumulative_returns_df.index.name = 'Years'\n",
        "print(all_tickers_cumulative_returns_df.round(4) * 100)\n",
        "\n",
        "# Display the formatted DataFrame  all_tickers_cagrs_df\n",
        "print(\"\\nCompound Annual Growth Rates (GAGRs) (%) as end of year\", calculation_end_day, \":\")\n",
        "all_tickers_cagrs_df.index.name = 'Years'\n",
        "print(all_tickers_cagrs_df.round(4) * 100)\n",
        "\n",
        "print(f\"The result of version-{script_version} script  ends here.\\n {result_marker}\")\n",
        "### CODE end (for AI tool)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3QoizNLiMXo"
      },
      "source": [
        "# library test & misc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWJtohe5lqzL",
        "outputId": "40c3ab9d-e6c0-43e3-b47a-093f5db185bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Today's Date: 2023-12-23\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Get today's date\n",
        "calculation_end_day_str = datetime.now().date()\n",
        "calculation_end_day_str = calculation_end_day.strftime(\"%Y-%m-%d\")\n",
        "calculation_end_day_str = datetime.now().date().strftime(\"%Y-%m-%d\")\n",
        "# Print or use the date as needed\n",
        "print(\"Today's Date:\", calculation_end_day_str)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGhTceUMhxdo"
      },
      "source": [
        "## Pandas  test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCu11-zxV7gt"
      },
      "source": [
        "### resample   BAS, BAS-JAN,  ... BAS-DEC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIOQicJsj5KB"
      },
      "source": [
        "pandas DataFrame resampling annualy with anchored-offsets, unexpected behavior?\n",
        "\n",
        "Pandas provides annual frequency options with anchored offsets, allowing users to resample time series data according to specific annual patterns. As stated in the user guide (https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#anchored-offsets), the (B)A(S)-DEC frequency represents an annual frequency anchored to the end of December. The guide indicates that (BAS-DEC) is expected to be equivalent to ‘A’.\n",
        "\n",
        "However, users may observe unexpected behavior with (BAS-DEC) not being equivalent to ‘A’.\n",
        "\n",
        "This discrepancy could potentially be an issue in the pandas library?\n",
        "\n",
        "On the other hand, (BA-DEC) appears to match the behavior of ‘A’."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvG0wIudWGYk",
        "outputId": "7c039fb6-8b4c-49c2-cda1-76dda1468285"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Date\n",
            "2016-12-30 00:00:00-05:00    0.119979\n",
            "2017-12-29 00:00:00-05:00    0.217054\n",
            "2018-12-31 00:00:00-05:00   -0.045690\n",
            "2019-12-31 00:00:00-05:00    0.312239\n",
            "2020-12-31 00:00:00-05:00    0.183316\n",
            "2021-12-31 00:00:00-05:00    0.287287\n",
            "2022-12-30 00:00:00-05:00   -0.181754\n",
            "2023-12-29 00:00:00-05:00    0.261758\n",
            "2024-12-31 00:00:00-05:00   -0.015548\n",
            "Freq: BA-DEC, Name: Close, dtype: float64\n",
            "pandas version: 1.5.3\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "pandas DataFrame resampling annualy with anchored-offsets, unexpected behavior?\n",
        "\n",
        "According to user_guide (https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#anchored-offsets):\n",
        "the (B)A(S)-DEC  annual frequency, anchored end of December. Same as ‘A’\n",
        "1.  However, 'BAS-DEC' looks not to be the same as ‘A’.  Is this an error in pandas library?\n",
        "2. 'BA-DEC' looks  to be the same as ‘A’.\n",
        "\n",
        "'''\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "stock = yf.Ticker(\"spy\")\n",
        "stock_history=stock.history(period=\"max\", start='2015-06-01')[\"Close\"]\n",
        "#annual_returns = stock_history.resample('A').ffill().pct_change().dropna() #1 ok\n",
        "#annual_returns = stock_history.resample('BAS-DEC').ffill().pct_change().dropna() #2 not correct\n",
        "#annual_returns = stock_history.resample('BA-DEC').ffill().pct_change().dropna() #3 same as 'A' - correct\n",
        "#annual_returns = stock_history.resample('AS-DEC').ffill().pct_change().dropna() #4 not correct\n",
        "#annual_returns = stock_history.resample('BY-DEC').ffill().pct_change().dropna() #5  execution error\n",
        "#annual_returns = stock_history.resample('BA').ffill().pct_change().dropna()\n",
        "annual_returns = stock_history.resample('BA', origin=\"start_day\").ffill().pct_change().dropna()\n",
        "\n",
        "print(annual_returns)\n",
        "print(\"pandas version:\", pd.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEJEgsxkcA8_"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "pandas version: 1.5.3\n",
        "\n",
        ".resample('A') result(correct):\n",
        "Date\n",
        "2016-12-31 00:00:00-05:00    0.119979\n",
        "2017-12-31 00:00:00-05:00    0.217054\n",
        "2018-12-31 00:00:00-05:00   -0.045690\n",
        "2019-12-31 00:00:00-05:00    0.312239\n",
        "2020-12-31 00:00:00-05:00    0.183316\n",
        "2021-12-31 00:00:00-05:00    0.287288\n",
        "2022-12-31 00:00:00-05:00   -0.181754\n",
        "2023-12-31 00:00:00-05:00    0.261758\n",
        "2024-12-31 00:00:00-05:00   -0.016894\n",
        "Freq: A-DEC, Name: Close, dtype: float64\n",
        "\n",
        "\n",
        "resample('BAS-DEC') result(incorrect, which is not identical to .resample('A') ):\n",
        "Date\n",
        "2016-12-01 00:00:00-05:00    0.064638\n",
        "2017-12-01 00:00:00-05:00    0.228817\n",
        "2018-12-03 00:00:00-05:00    0.075396\n",
        "2019-12-02 00:00:00-05:00    0.137962\n",
        "2020-12-01 00:00:00-05:00    0.197208\n",
        "2021-12-01 00:00:00-05:00    0.248145\n",
        "2022-12-01 00:00:00-05:00   -0.082032\n",
        "2023-12-01 00:00:00-05:00    0.144698\n",
        "Freq: BAS-DEC, Name: Close, dtype: float64\n",
        "\n",
        "Date\n",
        "2016-12-30 00:00:00-05:00    0.119979\n",
        "2017-12-29 00:00:00-05:00    0.217054\n",
        "2018-12-31 00:00:00-05:00   -0.045690\n",
        "2019-12-31 00:00:00-05:00    0.312239\n",
        "2020-12-31 00:00:00-05:00    0.183316\n",
        "2021-12-31 00:00:00-05:00    0.287288\n",
        "2022-12-30 00:00:00-05:00   -0.181754\n",
        "2023-12-29 00:00:00-05:00    0.261758\n",
        "2024-12-31 00:00:00-05:00   -0.016894\n",
        "Freq: BA-DEC, Name: Close, dtype: float64\n",
        "\n",
        "Date\n",
        "2016-12-01 00:00:00-05:00    0.064638\n",
        "2017-12-01 00:00:00-05:00    0.228817\n",
        "2018-12-01 00:00:00-05:00    0.061342\n",
        "2019-12-01 00:00:00-05:00    0.162909\n",
        "2020-12-01 00:00:00-05:00    0.187039\n",
        "2021-12-01 00:00:00-05:00    0.248145\n",
        "2022-12-01 00:00:00-05:00   -0.082032\n",
        "2023-12-01 00:00:00-05:00    0.144699\n",
        "Freq: AS-DEC, Name: Close, dtype: float64\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtb1IhvrWIkn"
      },
      "source": [
        "#### by chatGpt failed  cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "irGrYxpeIqed",
        "outputId": "bb344dc4-9772-4f6d-be1c-4511e30b77f8"
      },
      "outputs": [
        {
          "ename": "OutOfBoundsDatetime",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfBoundsDatetime\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-a63760f171f5>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Shift the resampled data to align with the custom starting date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mshift_amount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDateOffset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdayofyear\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mdf_year_start_custom_shifted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_year_start_custom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshift_amount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# TODO: avoid this kludge.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minfer_datetime_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0mutc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtz\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"utc\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m     result, tz_parsed = objects_to_datetime64ns(\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0mdayfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdayfirst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arrays/datetimes.py\u001b[0m in \u001b[0;36mobjects_to_datetime64ns\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[1;32m   2175\u001b[0m     \u001b[0morder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"F\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"C\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"F\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"C\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m         result, tz_parsed = tslib.array_to_datetime(\n\u001b[0m\u001b[1;32m   2178\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"K\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslibs/conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion.convert_datetime_to_tsobject\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslibs/np_datetime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.np_datetime.check_dts_bounds\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOutOfBoundsDatetime\u001b[0m: Out of bounds nanosecond timestamp: 1-03-15 00:00:00 present at position 0"
          ]
        }
      ],
      "source": [
        "'''\n",
        " If you want to resample annually with a specific starting date in a year,\n",
        " you can use the 'BAS' frequency string (Business Year Start frequency).\n",
        "\n",
        "In this example, 'BAS' stands for Business Year Start frequency, and you can append the specific starting date to\n",
        "it using the format BAS{month}-{day}. This will resample the data annually with a business year starting on March 15th.\n",
        "You can adjust the start_date variable to your desired date.\n",
        "\n",
        "'''\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a sample DataFrame with daily data\n",
        "date_rng = pd.date_range(start='2022-01-01', end='2023-12-31', freq='D')\n",
        "df = pd.DataFrame(index=date_rng, data={'value': np.random.rand(len(date_rng))})\n",
        "\n",
        "# Specify the custom starting date\n",
        "start_date = '03-15'  # March 15th\n",
        "\n",
        "# Resample to business year start frequency\n",
        "df_year_start_custom = df.resample('BAS').sum()\n",
        "\n",
        "# Shift the resampled data to align with the custom starting date\n",
        "shift_amount = pd.DateOffset(days=pd.to_datetime(start_date).dayofyear - 1)\n",
        "df_year_start_custom_shifted = df_year_start_custom.shift(freq=shift_amount)\n",
        "\n",
        "print(\"Business Year Start Frequency with Custom Starting Date:\")\n",
        "print(df_year_start_custom_shifted.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "3fZ8qv0hJqOs",
        "outputId": "f59d41c5-541a-4862-97d7-1b052af1f6cc"
      },
      "outputs": [
        {
          "ename": "OutOfBoundsDatetime",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfBoundsDatetime\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-359e19f13b4e>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Shift the resampled data to align with the custom starting date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mshift_amount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDateOffset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdayofyear\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m365\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mdf_year_start_custom_shifted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_year_start_custom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshift_amount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# TODO: avoid this kludge.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minfer_datetime_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0mutc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtz\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"utc\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m     result, tz_parsed = objects_to_datetime64ns(\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0mdayfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdayfirst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arrays/datetimes.py\u001b[0m in \u001b[0;36mobjects_to_datetime64ns\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[1;32m   2175\u001b[0m     \u001b[0morder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"F\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"C\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"F\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"C\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m         result, tz_parsed = tslib.array_to_datetime(\n\u001b[0m\u001b[1;32m   2178\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"K\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslibs/conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion.convert_datetime_to_tsobject\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslibs/np_datetime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.np_datetime.check_dts_bounds\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOutOfBoundsDatetime\u001b[0m: Out of bounds nanosecond timestamp: 1-03-15 00:00:00 present at position 0"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a sample DataFrame with daily data\n",
        "date_rng = pd.date_range(start='2022-01-01', end='2023-12-31', freq='D')\n",
        "df = pd.DataFrame(index=date_rng, data={'value': np.random.rand(len(date_rng))})\n",
        "\n",
        "# Specify the custom starting date\n",
        "start_date = '03-15'  # March 15th\n",
        "\n",
        "# Resample to business year start frequency\n",
        "df_year_start_custom = df.resample('BAS').sum()\n",
        "\n",
        "# Shift the resampled data to align with the custom starting date\n",
        "shift_amount = pd.DateOffset(days=(pd.to_datetime(start_date).dayofyear - 1) % 365)\n",
        "df_year_start_custom_shifted = df_year_start_custom.shift(freq=shift_amount)\n",
        "\n",
        "print(\"Business Year Start Frequency with Custom Starting Date:\")\n",
        "print(df_year_start_custom_shifted.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "tbsw3S6FK-39",
        "outputId": "33da749a-4e4c-4e56-98fe-1555926aa4e2"
      },
      "outputs": [
        {
          "ename": "OutOfBoundsDatetime",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfBoundsDatetime\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-595e5ff1931f>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Shift the resampled data to align with the custom starting date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mshift_amount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdayofyear\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m24\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3600\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1e9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ns'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mdf_year_start_custom_shifted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_year_start_custom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshift_amount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# TODO: avoid this kludge.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minfer_datetime_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0mutc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtz\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"utc\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m     result, tz_parsed = objects_to_datetime64ns(\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0mdayfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdayfirst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arrays/datetimes.py\u001b[0m in \u001b[0;36mobjects_to_datetime64ns\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[1;32m   2175\u001b[0m     \u001b[0morder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"F\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"C\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"F\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"C\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m         result, tz_parsed = tslib.array_to_datetime(\n\u001b[0m\u001b[1;32m   2178\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"K\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslibs/conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion.convert_datetime_to_tsobject\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslibs/np_datetime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.np_datetime.check_dts_bounds\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOutOfBoundsDatetime\u001b[0m: Out of bounds nanosecond timestamp: 1-03-15 00:00:00 present at position 0"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a sample DataFrame with daily data\n",
        "date_rng = pd.date_range(start='2022-01-01', end='2023-12-31', freq='D')\n",
        "df = pd.DataFrame(index=date_rng, data={'value': np.random.rand(len(date_rng))})\n",
        "\n",
        "# Specify the custom starting date\n",
        "start_date = '03-15'  # March 15th\n",
        "\n",
        "# Resample to business year start frequency\n",
        "df_year_start_custom = df.resample('BAS').sum()\n",
        "\n",
        "# Shift the resampled data to align with the custom starting date\n",
        "shift_amount = np.timedelta64((pd.to_datetime(start_date).dayofyear - 1) * 24 * 3600 * 1e9, 'ns')\n",
        "df_year_start_custom_shifted = df_year_start_custom.shift(freq=shift_amount)\n",
        "\n",
        "print(\"Business Year Start Frequency with Custom Starting Date:\")\n",
        "print(df_year_start_custom_shifted.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "2p0lW1o0Lajt",
        "outputId": "f3f3b384-647b-4595-a531-ba4a9abd0eb7"
      },
      "outputs": [
        {
          "ename": "OutOfBoundsDatetime",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfBoundsDatetime\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-d297c3238714>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Manually shift the resampled data to align with the custom starting date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mstart_date_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mshift_amount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstart_date_index\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf_year_start_custom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mdf_year_start_custom_shifted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_year_start_custom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'{shift_amount}D'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# TODO: avoid this kludge.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minfer_datetime_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0mutc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtz\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"utc\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m     result, tz_parsed = objects_to_datetime64ns(\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0mdayfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdayfirst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arrays/datetimes.py\u001b[0m in \u001b[0;36mobjects_to_datetime64ns\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[1;32m   2175\u001b[0m     \u001b[0morder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"F\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"C\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"F\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"C\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m         result, tz_parsed = tslib.array_to_datetime(\n\u001b[0m\u001b[1;32m   2178\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"K\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslibs/conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion.convert_datetime_to_tsobject\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslibs/np_datetime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.np_datetime.check_dts_bounds\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOutOfBoundsDatetime\u001b[0m: Out of bounds nanosecond timestamp: 1-03-15 00:00:00 present at position 0"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a sample DataFrame with daily data\n",
        "date_rng = pd.date_range(start='2022-01-01', end='2023-12-31', freq='D')\n",
        "df = pd.DataFrame(index=date_rng, data={'value': np.random.rand(len(date_rng))})\n",
        "\n",
        "# Specify the custom starting date\n",
        "start_date = '03-15'  # March 15th\n",
        "\n",
        "# Resample to business year start frequency\n",
        "df_year_start_custom = df.resample('BAS').sum()\n",
        "\n",
        "# Manually shift the resampled data to align with the custom starting date\n",
        "start_date_index = pd.to_datetime(start_date)\n",
        "shift_amount = (start_date_index - df_year_start_custom.index[0]).days\n",
        "df_year_start_custom_shifted = df_year_start_custom.shift(freq=f'{shift_amount}D')\n",
        "\n",
        "print(\"Business Year Start Frequency with Custom Starting Date:\")\n",
        "print(df_year_start_custom_shifted.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "xcqmJFLTL0-n",
        "outputId": "5e88d6a5-0826-4179-c532-fbca22402e53"
      },
      "outputs": [
        {
          "ename": "OutOfBoundsDatetime",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfBoundsDatetime\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-ff6d4b738f7c>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Calculate the custom offset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mstart_date_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDateOffset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonth\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mday\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Manually shift the resampled data to align with the custom starting date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# TODO: avoid this kludge.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minfer_datetime_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0mutc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtz\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"utc\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m     result, tz_parsed = objects_to_datetime64ns(\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0mdayfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdayfirst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arrays/datetimes.py\u001b[0m in \u001b[0;36mobjects_to_datetime64ns\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[1;32m   2175\u001b[0m     \u001b[0morder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"F\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"C\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"F\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"C\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m         result, tz_parsed = tslib.array_to_datetime(\n\u001b[0m\u001b[1;32m   2178\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"K\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslibs/conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion.convert_datetime_to_tsobject\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslibs/np_datetime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.np_datetime.check_dts_bounds\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOutOfBoundsDatetime\u001b[0m: Out of bounds nanosecond timestamp: 1-03-15 00:00:00 present at position 0"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a sample DataFrame with daily data\n",
        "date_rng = pd.date_range(start='2022-01-01', end='2023-12-31', freq='D')\n",
        "df = pd.DataFrame(index=date_rng, data={'value': np.random.rand(len(date_rng))})\n",
        "\n",
        "# Specify the custom starting date\n",
        "start_date = '03-15'  # March 15th\n",
        "\n",
        "# Resample to business year start frequency\n",
        "df_year_start_custom = df.resample('BAS').sum()\n",
        "\n",
        "# Calculate the custom offset\n",
        "start_date_offset = pd.DateOffset(months=pd.to_datetime(start_date).month - 1, day=1)\n",
        "\n",
        "# Manually shift the resampled data to align with the custom starting date\n",
        "df_year_start_custom_shifted = df_year_start_custom.shift(freq=start_date_offset)\n",
        "\n",
        "print(\"Business Year Start Frequency with Custom Starting Date:\")\n",
        "print(df_year_start_custom_shifted.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "MbTdBSUwMQuQ",
        "outputId": "39744164-3b29-4d96-948b-3c37ebf4a35d"
      },
      "outputs": [
        {
          "ename": "OutOfBoundsDatetime",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfBoundsDatetime\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-109d13ce1795>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Calculate the custom offset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mstart_date_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDateOffset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonth\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mday\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mstart_date_offset_custom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffsets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDateOffset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstart_date_offset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# TODO: avoid this kludge.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minfer_datetime_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0mutc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtz\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"utc\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m     result, tz_parsed = objects_to_datetime64ns(\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0mdayfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdayfirst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arrays/datetimes.py\u001b[0m in \u001b[0;36mobjects_to_datetime64ns\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[1;32m   2175\u001b[0m     \u001b[0morder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"F\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"C\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"F\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"C\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m         result, tz_parsed = tslib.array_to_datetime(\n\u001b[0m\u001b[1;32m   2178\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"K\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslibs/conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion.convert_datetime_to_tsobject\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslibs/np_datetime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.np_datetime.check_dts_bounds\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOutOfBoundsDatetime\u001b[0m: Out of bounds nanosecond timestamp: 1-03-15 00:00:00 present at position 0"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a sample DataFrame with daily data\n",
        "date_rng = pd.date_range(start='2022-01-01', end='2023-12-31', freq='D')\n",
        "df = pd.DataFrame(index=date_rng, data={'value': np.random.rand(len(date_rng))})\n",
        "\n",
        "# Specify the custom starting date\n",
        "start_date = '03-15'  # March 15th\n",
        "\n",
        "# Resample to business year start frequency\n",
        "df_year_start_custom = df.resample('BAS').sum()\n",
        "\n",
        "# Calculate the custom offset\n",
        "start_date_offset = pd.DateOffset(months=(pd.to_datetime(start_date).month - 1), day=1)\n",
        "start_date_offset_custom = pd.offsets.DateOffset(n=0, normalize=True) + start_date_offset\n",
        "\n",
        "# Manually shift the resampled data to align with the custom starting date\n",
        "df_year_start_custom_shifted = df_year_start_custom.shift(freq=start_date_offset_custom)\n",
        "\n",
        "print(\"Business Year Start Frequency with Custom Starting Date:\")\n",
        "print(df_year_start_custom_shifted.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENmNV7noAvUn"
      },
      "source": [
        "### resample A, AS, AS-JAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Szi5Ve6AlxD",
        "outputId": "99154259-2a2c-4ab5-be5e-f9fc64d147f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Year End Frequency:\n",
            "                 value\n",
            "2020-12-31  187.290611\n",
            "2021-12-31  186.791401\n",
            "2022-12-31  183.520457\n",
            "2023-12-31  180.929612\n",
            "\n",
            "Year Start Frequency:\n",
            "                 value\n",
            "2020-01-01  187.290611\n",
            "2021-01-01  186.791401\n",
            "2022-01-01  183.520457\n",
            "2023-01-01  180.929612\n",
            "\n",
            "Year Start Frequency with January as Starting Month:\n",
            "                 value\n",
            "2020-01-01  187.290611\n",
            "2021-01-01  186.791401\n",
            "2022-01-01  183.520457\n",
            "2023-01-01  180.929612\n"
          ]
        }
      ],
      "source": [
        "# Resample Year end frequency, Year start frequency, Year start frequency with January as the starting month\n",
        "'''\n",
        "In pandas, when using the resample method with a frequency string for yearly frequency,\n",
        "you can use various format codes to specify the starting month of the year. Some common options include:\n",
        "\n",
        "'A': Year end frequency\n",
        "'AS': Year start frequency\n",
        "'AS-JAN', 'AS-FEB', ..., 'AS-DEC': Year start frequency with the specified starting month\n",
        "Here's an example of how you can use these:\n",
        "'''\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a sample DataFrame with daily data\n",
        "date_rng = pd.date_range(start='2020-01-01', end='2023-12-31', freq='D')\n",
        "df = pd.DataFrame(index=date_rng, data={'value': np.random.rand(len(date_rng))})\n",
        "\n",
        "# Resample to different yearly frequencies\n",
        "df_year_end = df.resample('A').sum()  # Year end frequency\n",
        "df_year_start = df.resample('AS').sum()  # Year start frequency\n",
        "df_year_start_jan = df.resample('AS-JAN').sum()  # Year start frequency with January as the starting month\n",
        "\n",
        "print(\"Year End Frequency:\")\n",
        "print(df_year_end.head())\n",
        "\n",
        "print(\"\\nYear Start Frequency:\")\n",
        "print(df_year_start.head())\n",
        "\n",
        "print(\"\\nYear Start Frequency with January as Starting Month:\")\n",
        "print(df_year_start_jan.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDsxbvjB0Hhg"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "# Display all column names of DataFrame\n",
        "print(history.columns)\n",
        "print(history.columns.tolist())\n",
        "print(history.head)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGwERTvBhzPy",
        "outputId": "969b6828-e146-4f4b-f6f0-13b68f809b97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      XFN.to\n",
            "1   0.106470\n",
            "3   0.105562\n",
            "5   0.104884\n",
            "10  0.083145\n",
            "15  0.111200\n",
            "20  0.086619\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "ticker=\"SPY\"\n",
        "stock=yf.Ticker(\"SPY\")\n",
        "history=stock.history(period=\"max\")\n",
        "\n",
        "periods = [1, 3, 5, 10, 15, 20] # in years, length = 8\n",
        "trailing_return_data = [0.10647016778880825, 0.10556152327764257, 0.10488446528717588,\\\n",
        "                        0.08314514086640723, 0.11120038296103063, 0.08661932862864385]\n",
        "trailing_return_column = pd.DataFrame(trailing_return_data, index=periods, columns=[\"XFN.to\"])\n",
        "\n",
        "\n",
        "print(trailing_return_column)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jP2C7-4GilZg"
      },
      "source": [
        "## yfinace test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEYDCsk3W1AB",
        "outputId": "1e5a2a6a-74d8-4b30-9471-9515bc2dc8eb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:yfinance:SHOP.TO: Data doesn't exist for startDate = 32418000, endDate = 1356930000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            shop.to\n",
            "2012-12-31        0\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# step 1: fetch retrieve yearly total returns by yfinance & display\n",
        "# Function to fetch data from yfinance and extract yearly total returns\n",
        "def get_annual_returns_df(ticker, calculation_end_date):\n",
        "    # Get the historical data for the given ticker\n",
        "    stock = yf.Ticker(ticker)\n",
        "    ''' Get annual total return data.\n",
        "        .resample('Y'): Resamples the time series data annually ('Y'), based on the last trading day of each year.\n",
        "        .resample('A'): Resamples the time series data annually ('A'), based on the any trading day of each year.\n",
        "    '''\n",
        "    calculation_start_date = (datetime.strptime(calculation_end_date, \"%Y-%m-%d\")\n",
        "                - timedelta(days=num_years_calculation * 365)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    ''' yfinance_BUG_1 NOTE:\n",
        "    There is bug for  when using end=\"2024-01-02\" on 2024-01-02 which is the first trading of the year on 8:10pm\n",
        "     (tried tickers: \"^GSPC\",\"spy\" for stock = yf.Ticker(ticker)) that 2024-01-02 data is not returned.\n",
        "     however, when end parameter, it is fine for returning  2024-01-02 data as below\n",
        "     annual_returns_history=stock.history(start=calculation_start_date)[\"Close\"]\n",
        "    annual_returns_history=stock.history(start=calculation_start_date,end=calculation_end_date)[\"Close\"]\n",
        "    '''\n",
        "    try:\n",
        "        annual_returns_history=stock.history(start=calculation_start_date,end=calculation_end_date)[\"Close\"]\n",
        "        # need to handle the exception error that a ticker is not yet at stock market, \"shop.to\" is not there in 2012\n",
        "        annual_returns = annual_returns_history.resample('A').ffill().pct_change().dropna()\n",
        "    except Exception as e:\n",
        "        annual_returns_df=pd.DataFrame({ticker: [0] }, index=pd.to_datetime([calculation_end_date]))\n",
        "    else:\n",
        "        #print(\"debug get_annual_returns_df \", ticker, annual_returns_history)\n",
        "        print(\"debug get_annual_returns_df after resample('A').ffill().pct_change().dropna()\", ticker, \"\\n\", annual_returns)\n",
        "        annual_returns_df = pd.DataFrame(annual_returns, columns=['Close'])\n",
        "        annual_returns_df.rename(columns={'Close': ticker}, inplace=True)\n",
        "    return annual_returns_df\n",
        "\n",
        "t_annual_returns_df=get_annual_returns_df(\"shop.to\", \"2012-12-31\")\n",
        "print(t_annual_returns_df)\n",
        "\n",
        "# need to handle the exception error that a ticker is not yet at stock market, \"shop.to\" is not there in 2012\n",
        "#annual_returns_history=stock.history(start=calculation_start_date,end=calculation_end_date)[\"Close\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eBl5-uXoLhc"
      },
      "source": [
        "### New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1zvRcusqxSL",
        "outputId": "b8f66f0f-7a38-4ff4-93a0-08e10535c010"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:yfinance:SHOP.TO: Data doesn't exist for startDate = 1199250000, endDate = 1356930000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "An error occurred while fetching data for shop.to: name 'error_message' is not defined\n",
            "t_annual_returns_df             shop.to\n",
            "2012-12-31        0\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "from yfinance import shared\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Function to fetch data from yfinance and extract yearly total returns\n",
        "def get_annual_returns_df(ticker, calculation_end_date, num_years_calculation=5):\n",
        "    # Get the historical data for the given ticker\n",
        "    stock = yf.Ticker(ticker)\n",
        "    calculation_start_date = (datetime.strptime(calculation_end_date, \"%Y-%m-%d\")\n",
        "                - timedelta(days=num_years_calculation * 365)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    try:\n",
        "        annual_returns_history = stock.history(start=calculation_start_date, end=calculation_end_date)[\"Close\"]\n",
        "\n",
        "        if error_message:\n",
        "            print(f\"An error occurred while fetching data for {ticker}: {error_message}\")\n",
        "        else:\n",
        "            print(f\"Data for {ticker} was successfully fetched\")\n",
        "\n",
        "        if len(annual_returns_history) == 0:\n",
        "            raise ValueError(\"No data available for the specified period\")\n",
        "\n",
        "        # Continue with the normal processing\n",
        "        #annual_returns = annual_returns_history.resample('A').ffill().pct_change().dropna()\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while fetching data for {ticker}: {e}\")\n",
        "        annual_returns_df = pd.DataFrame({ticker: [0]}, index=pd.to_datetime([calculation_end_date]))\n",
        "    else:\n",
        "        print(\"debug get_annual_returns_df after resample('A').ffill().pct_change().dropna()\", ticker, \"\\n\", annual_returns)\n",
        "        annual_returns_df = pd.DataFrame(annual_returns, columns=['Close'])\n",
        "        annual_returns_df.rename(columns={'Close': ticker}, inplace=True)\n",
        "    return annual_returns_df\n",
        "\n",
        "t_annual_returns_df = get_annual_returns_df(\"shop.to\", \"2012-12-31\")\n",
        "print(\"t_annual_returns_df\", t_annual_returns_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zG7hF4SiyQr",
        "outputId": "d9d3b515-c072-47fa-c37c-70ea9a9bc24d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "###\n",
            "\n",
            "###\n",
            "                                  Open        High         Low       Close  \\\n",
            "Date                                                                        \n",
            "1980-12-12 00:00:00-05:00    0.099319    0.099750    0.099319    0.099319   \n",
            "1980-12-15 00:00:00-05:00    0.094569    0.094569    0.094137    0.094137   \n",
            "1980-12-16 00:00:00-05:00    0.087659    0.087659    0.087228    0.087228   \n",
            "1980-12-17 00:00:00-05:00    0.089387    0.089818    0.089387    0.089387   \n",
            "1980-12-18 00:00:00-05:00    0.091978    0.092410    0.091978    0.091978   \n",
            "...                               ...         ...         ...         ...   \n",
            "2023-12-18 00:00:00-05:00  196.089996  196.630005  194.389999  195.889999   \n",
            "2023-12-19 00:00:00-05:00  196.160004  196.949997  195.889999  196.940002   \n",
            "2023-12-20 00:00:00-05:00  196.899994  197.679993  194.830002  194.830002   \n",
            "2023-12-21 00:00:00-05:00  196.100006  197.080002  193.500000  194.679993   \n",
            "2023-12-22 00:00:00-05:00  195.179993  195.410004  192.970001  193.600006   \n",
            "\n",
            "                              Volume  Dividends  Stock Splits  \n",
            "Date                                                           \n",
            "1980-12-12 00:00:00-05:00  469033600        0.0           0.0  \n",
            "1980-12-15 00:00:00-05:00  175884800        0.0           0.0  \n",
            "1980-12-16 00:00:00-05:00  105728000        0.0           0.0  \n",
            "1980-12-17 00:00:00-05:00   86441600        0.0           0.0  \n",
            "1980-12-18 00:00:00-05:00   73449600        0.0           0.0  \n",
            "...                              ...        ...           ...  \n",
            "2023-12-18 00:00:00-05:00   55751900        0.0           0.0  \n",
            "2023-12-19 00:00:00-05:00   40714100        0.0           0.0  \n",
            "2023-12-20 00:00:00-05:00   52242800        0.0           0.0  \n",
            "2023-12-21 00:00:00-05:00   46482500        0.0           0.0  \n",
            "2023-12-22 00:00:00-05:00   37122800        0.0           0.0  \n",
            "\n",
            "[10849 rows x 7 columns]\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "stock=yf.Ticker(\"SPY\")\n",
        "\n",
        "# .index.year,  index.year.max()\n",
        "#history=stock.history(period=\"1mo\")\n",
        "#print(history.index.year)\n",
        "#print(history.index.year.max())\n",
        "\n",
        "# multiple tickers\n",
        "tickers = yf.Tickers('msft aapl goog')\n",
        "\n",
        "# access each ticker using (example)\n",
        "#tickers.tickers['MSFT'].info\n",
        "print(\"###\\n\")\n",
        "tickers_history=tickers.tickers['AAPL'].history(period=\"max\")\n",
        "print(\"###\\n\",tickers_history)\n",
        "#tickers.tickers['GOOG'].actions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVJl7epmQOQW"
      },
      "source": [
        "##  Template of markers for marking CODE start and end Marker for AI  debug\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anH8O-uDQbv-",
        "outputId": "9e3b47a3-dac3-4e63-f5cb-13b467c8f103"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The result of version-(2023.1222.1) script  start:\n",
            " ###\n",
            "The result of version-(2023.1222.1) script  ends here.\n",
            " ###\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "### CODE start (for AI tool)\n",
        ".....\n",
        "History:\n",
        "Versions:\n",
        " * 2023.1222.1:\n",
        "Author: Gang Luo\n",
        "\"\"\"\n",
        "result_marker='###'\n",
        "script_version = '(2023.1222.1)'\n",
        "print(f\"The result of version-{script_version} script  start:\\n {result_marker}\")\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "print_yearly_total_return = True\n",
        "\n",
        "# Set the stock tickers list\n",
        "tickers_list1 = [\"spy\", \"vfv.to\", \"zlu.to\", \"xiu.to\", \"xfn.to\", \"ry.to\", \"td.to\", \"na.to\",\\\n",
        "                \"slf.to\", \"gwo.to\", \"bce.to\", \"t.to\", \"rci-b.to\", \"enb.to\", \"trp.to\", \"zlb.to\"]\n",
        "tickers_list2 = [\"vfv.to\", \"xiu.to\", \"xic.to\", \"xfn.to\", \"ry.to\", \"td.to\", \"na.to\",\\\n",
        "                \"bns.to\", \"bmo.to\", \"cm.to\", \"cwb.to\", \"slf.to\", \"gwo.to\"]\n",
        "tickers_list3 = [\"spy\", \"vfv.to\", \"xfn.to\", \"ry.to\"]\n",
        "tickers_list = tickers_list1\n",
        "\n",
        "\n",
        "# print an indicator to mark the end of execution result\n",
        "print(f\"The result of version-{script_version} script  ends here.\\n {result_marker}\")\n",
        "### CODE end (for AI tool)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jx5s_I1Ee761"
      },
      "source": [
        "# Graphical line diagram of stock cumulative returns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "jUVHMdVu1rWq",
        "outputId": "89a5a6b3-8766-47a4-e87a-b10b7632a507"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://5c94a02b22d28bc483.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://5c94a02b22d28bc483.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "graphical line diagram of stock cumulative returns\n",
        "\n",
        "Note: Raw Data is from Yahoo Finance using python yfinance\n",
        "'''\n",
        "script_version = '(2024-01-28.1)'\n",
        "# Import the libraries\n",
        "import gradio as gr\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "def stock_return_df(tickers, start, end):\n",
        "  # Download the historical data\n",
        "  data = yf.download(tickers, start=start, end=end)\n",
        "  # Calculate the daily and cumulative percentage change\n",
        "  data_adj_close = data['Adj Close']\n",
        "  data_adj_close_pct = data_adj_close.pct_change()\n",
        "  data_adj_close_pct_cum = (data_adj_close_pct + 1).cumprod(axis=0) - 1\n",
        "  return data_adj_close_pct_cum\n",
        "\n",
        "def plot_graph(tickers, start, end):\n",
        "  data_adj_close_pct_cum=stock_return_df(tickers, start, end)\n",
        "  # Plot a line chart of the salary by name\n",
        "  #ax = data_adj_close_pct_cum.plot.line(x=\"Name\", y=\"Salary\", rot=0, legend=False, style=\"-o\", markersize=10, color=\"green\")\n",
        "  ax = data_adj_close_pct_cum.plot()\n",
        "  ax.set_ylabel(\"Percentage\")\n",
        "  ax.set_title(\"Cumulative Returns\")\n",
        "  # Return the plot as a matplotlib figure\n",
        "  return ax.get_figure()\n",
        "\n",
        "# Create a gradio.Interface object with the DataFrame component as input and the Matplotlib component as output\n",
        "interface = gr.Interface(\n",
        "    fn=plot_graph, # The function to call\n",
        "    inputs=[gr.Textbox(label=\"Tickers\", value=\"qqq,spy,vfv.to,xiu.to,xfn.to,ry.to\", scale=0,  min_width=150),\n",
        "        gr.Textbox(label=\"Start Date\", value=\"2014-01-01\", scale=0, min_width=150),\n",
        "        gr.Textbox(label=\"End Date\", value=\"2023-12-30\", scale=0, min_width=150)],\n",
        "    outputs=gr.Plot(label=\"Output Plot\", scale=2, min_width=250), # The Matplotlib component as output\n",
        "    title=\"Stock cumulative returns - DataFrame Line Plot by Gradio\" # The title of the interface\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "interface.launch(debug=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iO13eRwIHF5A"
      },
      "source": [
        "## backup - Graphical line diagram of stock cumulative returns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "OJYeQuKrHJrq",
        "outputId": "055b6d56-b44c-40c2-ffc8-0c0ab3ce62f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://008eab34382b4350da.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://008eab34382b4350da.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "graphical line diagram of stock cumulative returns\n",
        "\n",
        "Note: Raw Data is from Yahoo Finance using python yfinance\n",
        "'''\n",
        "script_version = '(2024-01-28.1)'\n",
        "# Import the libraries\n",
        "import gradio as gr\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "def stock_return_df(tickers, start, end):\n",
        "  # Download the historical data\n",
        "  data = yf.download(tickers, start=start, end=end)\n",
        "  # Calculate the daily and cumulative percentage change\n",
        "  data_adj_close = data['Adj Close']\n",
        "  data_adj_close_pct = data_adj_close.pct_change()\n",
        "  data_adj_close_pct_cum = (data_adj_close_pct + 1).cumprod(axis=0) - 1\n",
        "  return data_adj_close_pct_cum\n",
        "\n",
        "def plot_graph(tickers, start, end):\n",
        "  data_adj_close_pct_cum=stock_return_df(tickers, start, end)\n",
        "  # Plot a line chart of the salary by name\n",
        "  #ax = data_adj_close_pct_cum.plot.line(x=\"Name\", y=\"Salary\", rot=0, legend=False, style=\"-o\", markersize=10, color=\"green\")\n",
        "  ax = data_adj_close_pct_cum.plot()\n",
        "  ax.set_ylabel(\"Percentage\")\n",
        "  ax.set_title(\"Cumulative Returns\")\n",
        "  # Return the plot as a matplotlib figure\n",
        "  return ax.get_figure()\n",
        "\n",
        "# Create a gradio.Interface object with the DataFrame component as input and the Matplotlib component as output\n",
        "interface = gr.Interface(\n",
        "    fn=plot_graph, # The function to call\n",
        "    inputs=[gr.Textbox(label=\"Tickers\", value=\"qqq,spy,vfv.to,xiu.to,xfn.to,ry.to\"),\n",
        "        gr.Textbox(label=\"Start Date\", value=\"2014-01-01\"),\n",
        "        gr.Textbox(label=\"End Date\", value=\"2023-12-30\")],\n",
        "    outputs=gr.Plot(label=\"Output Plot\"), # The Matplotlib component as output\n",
        "    title=\"Stock cumulative returns - DataFrame Line Plot by Gradio\" # The title of the interface\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "interface.launch(debug=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbvufP0j4iH7"
      },
      "source": [
        "# plot by using gr.Blocks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "2QRpHM4v4t8w",
        "outputId": "64c37d36-3874-46a9-a2cc-6ac08302c85c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/yfinance/base.py:48: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  _empty_series = pd.Series()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://7327a226d13620528a.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://7327a226d13620528a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import the libraries\n",
        "import gradio as gr\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "def stock_return_df(tickers, start, end):\n",
        "  # Download the historical data\n",
        "  data = yf.download(tickers, start=start, end=end)\n",
        "  # Calculate the daily and cumulative percentage change\n",
        "  data_adj_close = data['Adj Close']\n",
        "  data_adj_close_pct = data_adj_close.pct_change()\n",
        "  data_adj_close_pct_cum = (data_adj_close_pct + 1).cumprod(axis=0) - 1\n",
        "  return data_adj_close_pct_cum\n",
        "\n",
        "def plot_graph(tickers, start, end):\n",
        "  data_adj_close_pct_cum=stock_return_df(tickers, start, end)\n",
        "  # Plot a line chart of the salary by name\n",
        "  #ax = data_adj_close_pct_cum.plot.line(x=\"Name\", y=\"Salary\", rot=0, legend=False, style=\"-o\", markersize=10, color=\"green\")\n",
        "  ax = data_adj_close_pct_cum.plot()\n",
        "  ax.set_ylabel(\"Percentage\")\n",
        "  ax.set_title(\"Cumulative Returns\")\n",
        "  # Return the plot as a matplotlib figure\n",
        "  return ax.get_figure()\n",
        "\n",
        "# Create a gr.Blocks() object and use it as a context\n",
        "with gr.Blocks() as demo:\n",
        "    # Define the input and output components within the gr.Blocks() context\n",
        "    tickers = gr.Textbox(label=\"Tickers\", value=\"qqq,spy,vfv.to,xiu.to,xfn.to,ry.to\")\n",
        "    start_date = gr.Textbox(label=\"Start Date\", value=\"2014-01-01\")\n",
        "    end_date = gr.Textbox(label=\"End Date\", value=\"2023-12-30\")\n",
        "    output_plot = gr.Plot(label=\"Output Plot\")\n",
        "    # Define an event listener that calls the plot_graph function when the input components are changed\n",
        "    tickers.change(plot_graph, # The function to call\n",
        "                   inputs=[tickers, start_date, end_date], # The inputs of the function\n",
        "                   outputs=output_plot, # The output of the function\n",
        "                   api_name=\"plot_graph\" # The API name of the function\n",
        "                   )\n",
        "    start_date.change(plot_graph, # The function to call\n",
        "                      inputs=[tickers, start_date, end_date], # The inputs of the function\n",
        "                      outputs=output_plot, # The output of the function\n",
        "                      api_name=\"plot_graph\" # The API name of the function\n",
        "                      )\n",
        "    end_date.change(plot_graph, # The function to call\n",
        "                    inputs=[tickers, start_date, end_date], # The inputs of the function\n",
        "                    outputs=output_plot, # The output of the function\n",
        "                    api_name=\"plot_graph\" # The API name of the function\n",
        "                    )\n",
        "    # Set the title of the demo\n",
        "    demo.title = \"Stock cumulative returns - DataFrame Line Plot by Gradio\"\n",
        "# Launch the demo\n",
        "demo.launch(debug=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aQT2MPp6HlV"
      },
      "source": [
        "## New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eGgYP9Dm6Kkr",
        "outputId": "e3653b40-3de3-4beb-bf02-dbe5f78d7231"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Button.__init__() got an unexpected keyword argument 'label'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c4629e2a32a2>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0moutput_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPlot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Output Plot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Create a submit button\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0msubmit_btn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mButton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Submit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Define an event listener that calls the plot_graph function when the submit button is clicked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     submit_btn.click(plot_graph, # The function to call\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/component_meta.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Button.__init__() got an unexpected keyword argument 'label'"
          ]
        }
      ],
      "source": [
        "# Import the libraries\n",
        "import gradio as gr\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "def stock_return_df(tickers, start, end):\n",
        "  # Download the historical data\n",
        "  data = yf.download(tickers, start=start, end=end)\n",
        "  # Calculate the daily and cumulative percentage change\n",
        "  data_adj_close = data['Adj Close']\n",
        "  data_adj_close_pct = data_adj_close.pct_change()\n",
        "  data_adj_close_pct_cum = (data_adj_close_pct + 1).cumprod(axis=0) - 1\n",
        "  return data_adj_close_pct_cum\n",
        "\n",
        "def plot_graph(tickers, start, end):\n",
        "  data_adj_close_pct_cum=stock_return_df(tickers, start, end)\n",
        "  # Plot a line chart of the salary by name\n",
        "  #ax = data_adj_close_pct_cum.plot.line(x=\"Name\", y=\"Salary\", rot=0, legend=False, style=\"-o\", markersize=10, color=\"green\")\n",
        "  ax = data_adj_close_pct_cum.plot()\n",
        "  ax.set_ylabel(\"Percentage\")\n",
        "  ax.set_title(\"Cumulative Returns\")\n",
        "  # Return the plot as a matplotlib figure\n",
        "  return ax.get_figure()\n",
        "\n",
        "# Create a gr.Blocks() object and use it as a context\n",
        "with gr.Blocks() as demo:\n",
        "    # Define the input and output components within the gr.Blocks() context\n",
        "    tickers = gr.Textbox(label=\"Tickers\", value=\"qqq,spy,vfv.to,xiu.to,xfn.to,ry.to\")\n",
        "    start_date = gr.Textbox(label=\"Start Date\", value=\"2014-01-01\")\n",
        "    end_date = gr.Textbox(label=\"End Date\", value=\"2023-12-30\")\n",
        "    output_plot = gr.Plot(label=\"Output Plot\")\n",
        "    # Create a submit button\n",
        "    submit_btn = gr.Button(label=\"Submit\")\n",
        "    # Define an event listener that calls the plot_graph function when the submit button is clicked\n",
        "    submit_btn.click(plot_graph, # The function to call\n",
        "                     inputs=[tickers, start_date, end_date], # The inputs of the function\n",
        "                     outputs=output_plot, # The output of the function\n",
        "                     api_name=\"plot_graph\" # The API name of the function\n",
        "                     )\n",
        "    # Set the title of the demo\n",
        "    demo.title = \"Stock cumulative returns - DataFrame Line Plot by Gradio\"\n",
        "# Launch the demo\n",
        "demo.launch(debug=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBip2lsGX_kC"
      },
      "source": [
        "# a list of end-of year stock prices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lu6HGT-YB2T",
        "outputId": "f56b352c-6ba2-4c15-c35e-07000f2e2ae3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%%**********************]  3 of 3 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n",
            "               ^ixic     qqq   tqqq\n",
            "1971-12-31    114.12     NaN    NaN\n",
            "1972-12-31    133.73     NaN    NaN\n",
            "1973-12-31     92.19     NaN    NaN\n",
            "1974-12-31     59.82     NaN    NaN\n",
            "1975-12-31     77.62     NaN    NaN\n",
            "1976-12-31     97.88     NaN    NaN\n",
            "1977-12-31    105.05     NaN    NaN\n",
            "1978-12-31    117.98     NaN    NaN\n",
            "1979-12-31    151.14     NaN    NaN\n",
            "1980-12-31    202.34     NaN    NaN\n",
            "1981-12-31    195.84     NaN    NaN\n",
            "1982-12-31    232.41     NaN    NaN\n",
            "1983-12-31    278.60     NaN    NaN\n",
            "1984-12-31    247.10     NaN    NaN\n",
            "1985-12-31    324.90     NaN    NaN\n",
            "1986-12-31    348.80     NaN    NaN\n",
            "1987-12-31    330.50     NaN    NaN\n",
            "1988-12-31    381.40     NaN    NaN\n",
            "1989-12-31    454.80     NaN    NaN\n",
            "1990-12-31    373.80     NaN    NaN\n",
            "1991-12-31    586.34     NaN    NaN\n",
            "1992-12-31    676.95     NaN    NaN\n",
            "1993-12-31    776.80     NaN    NaN\n",
            "1994-12-31    751.96     NaN    NaN\n",
            "1995-12-31   1052.13     NaN    NaN\n",
            "1996-12-31   1291.03     NaN    NaN\n",
            "1997-12-31   1570.35     NaN    NaN\n",
            "1998-12-31   2192.69     NaN    NaN\n",
            "1999-12-31   4069.31   78.03    NaN\n",
            "2000-12-31   2470.52   49.85    NaN\n",
            "2001-12-31   1950.40   33.23    NaN\n",
            "2002-12-31   1335.51   20.81    NaN\n",
            "2003-12-31   2003.37   31.15    NaN\n",
            "2004-12-31   2175.44   34.43    NaN\n",
            "2005-12-31   2205.32   34.97    NaN\n",
            "2006-12-31   2415.29   37.47    NaN\n",
            "2007-12-31   2652.28   44.60    NaN\n",
            "2008-12-31   1577.03   25.99    NaN\n",
            "2009-12-31   2269.15   40.20    NaN\n",
            "2010-12-31   2652.87   48.30   0.75\n",
            "2011-12-31   2605.15   49.97   0.69\n",
            "2012-12-31   3019.51   59.03   1.05\n",
            "2013-12-31   4176.59   80.65   2.52\n",
            "2014-12-31   4736.05   96.12   3.96\n",
            "2015-12-31   5007.41  105.19   4.65\n",
            "2016-12-31   5383.12  112.66   5.17\n",
            "2017-12-31   6903.39  149.45  11.28\n",
            "2018-12-31   6635.28  149.26   9.05\n",
            "2019-12-31   8972.60  207.42  21.17\n",
            "2020-12-31  12888.28  307.82  44.46\n",
            "2021-12-31  15644.97  392.23  81.35\n",
            "2022-12-31  10466.48  264.45  17.01\n",
            "2023-12-31  15011.35  409.52  50.70\n",
            "2024-02-09  15947.74  435.27  58.94\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Import the libraries\n",
        "import gradio as gr\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "tickers_list2=[\"qqq\",\"spy\",\"vfv.to\",\"xiu.to\",\"xfn.to\",\"ry.to\"]\n",
        "tickers_list1=[\"^IXIC\",\"^DJI\",\"^GSPC\",\"^GSPTSE\"]\n",
        "tickers_list0=[\"qqq\",\"tqqq\",\"QLD\", \"spy\",\"upro\", \"sso\", \"spxl\"]\n",
        "tickers_list3=[\"iwy\",\"nvda\"]\n",
        "tickers_list=[\"^IXIC\", \"qqq\",\"tqqq\"]\n",
        "start_date=\"2014-01-01\"\n",
        "calculation_end_date_str=\"2024-02-09\"\n",
        "\n",
        "def stock_close_prices_df(tickers_list, end_date_str):\n",
        "  tickers_list_upper = [ticker.upper() for ticker in tickers_list]\n",
        "  # Download the historical data\n",
        "  tickers_str = \", \".join(tickers_list_upper)\n",
        "  #tickers_str = \", \".join(f'\"{ticker}\"' for ticker in tickers_list) # maintain the same order of tickers\n",
        "  data = yf.download(tickers_str, period=\"max\")\n",
        "  data_adj_close = data['Adj Close']\n",
        "\n",
        "  # Rearrange columns based on the order in tickers_list\n",
        "  if len(tickers_list)>1:\n",
        "      data_adj_close = data_adj_close.reindex(columns=tickers_list_upper)\n",
        "  #data_adj_close = data_adj_close.reindex(index=tickers_list_upper)\n",
        "  #data_adj_close.columns = tickers_list_upper\n",
        "\n",
        "  data_adj_close = data_adj_close.resample('A').ffill().round(2)\n",
        "  data_adj_close.index=data_adj_close.index.date\n",
        "  last_date = data_adj_close.index[-1]\n",
        "  data_adj_close = data_adj_close.rename(index={last_date: end_date_str})\n",
        "  return data_adj_close\n",
        "\n",
        "output_dataframe= stock_close_prices_df(tickers_list, calculation_end_date_str)\n",
        "#output_html0=output_dataframe.to_html()\n",
        "output_dataframe.columns = map(str.lower, output_dataframe.columns)\n",
        "print(\" \")\n",
        "print( output_dataframe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8THNzFmo7zDL"
      },
      "source": [
        "# Maximum price drop & a list of tickers' daily adj close :prices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oV_1A66R8RQ9",
        "outputId": "3c8628bc-4862-4efe-a9a0-047515f92ec6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%%**********************]  7 of 7 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n",
            "Ticker         QQQ   TQQQ    QLD     SPY   UPRO    SSO    SPXL\n",
            "1993-01-29     NaN    NaN    NaN   24.84    NaN    NaN     NaN\n",
            "1993-02-01     NaN    NaN    NaN   25.02    NaN    NaN     NaN\n",
            "1993-02-02     NaN    NaN    NaN   25.07    NaN    NaN     NaN\n",
            "1993-02-03     NaN    NaN    NaN   25.34    NaN    NaN     NaN\n",
            "1993-02-04     NaN    NaN    NaN   25.44    NaN    NaN     NaN\n",
            "...            ...    ...    ...     ...    ...    ...     ...\n",
            "2024-02-05  428.45  56.95  82.44  492.55  59.91  69.29  113.82\n",
            "2024-02-06  427.59  56.62  82.14  493.98  60.40  69.66  114.74\n",
            "2024-02-07  431.99  58.31  83.79  498.10  61.88  70.80  117.57\n",
            "2024-02-08  432.79  58.55  84.06  498.32  61.95  70.86  117.71\n",
            "2024-02-09  437.05  60.27  85.68  501.20  62.97  71.67  119.62\n",
            "\n",
            "[7814 rows x 7 columns]\n",
            "        HighPrice HighPriceDate  LowPrice LowPriceDate  PriceDrop%  \\\n",
            "Ticker                                                               \n",
            "QQQ        437.05    2024-02-09    437.05   2024-02-09    0.000000   \n",
            "TQQQ        86.64    2021-11-19     15.89   2022-12-28   81.659741   \n",
            "QLD         91.76    2021-11-19     33.32   2022-12-28   63.687881   \n",
            "SPY        501.20    2024-02-09    501.20   2024-02-09    0.000000   \n",
            "UPRO        76.58    2022-01-03     27.61   2022-10-12   63.946200   \n",
            "SSO         73.58    2022-01-03     39.19   2022-10-12   46.738244   \n",
            "SPXL       143.72    2022-01-03     52.02   2022-10-12   63.804620   \n",
            "\n",
            "        InceptDate InceptPrice     CurDate  CurPrice  PriceChange%  \n",
            "Ticker                                                              \n",
            "QQQ     1999-03-10        43.6  2024-02-09    437.05        902.41  \n",
            "TQQQ    2010-02-11        0.42  2024-02-09     60.27      14250.00  \n",
            "QLD     2006-06-21        1.98  2024-02-09     85.68       4227.27  \n",
            "SPY     1993-01-29       24.84  2024-02-09    501.20       1917.71  \n",
            "UPRO    2009-06-25        1.16  2024-02-09     62.97       5328.45  \n",
            "SSO     2006-06-21        7.45  2024-02-09     71.67        862.01  \n",
            "SPXL    2008-11-05        3.34  2024-02-09    119.62       3481.44  \n"
          ]
        }
      ],
      "source": [
        "# Import the libraries\n",
        "import gradio as gr\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "tickers_list2=[\"qqq\",\"spy\",\"vfv.to\",\"xiu.to\",\"xfn.to\",\"ry.to\"]\n",
        "tickers_list1=[\"^IXIC\",\"^DJI\",\"^GSPC\",\"^GSPTSE\"]\n",
        "tickers_list=[\"qqq\",\"tqqq\",\"QLD\", \"spy\",\"upro\", \"sso\", \"spxl\"]\n",
        "tickers_list3=[\"tqqq\"]\n",
        "#start_date=\"2014-01-01\"\n",
        "calculation_end_date_str=\"2024-02-10\"\n",
        "\n",
        "def stock_close_prices_df(tickers_list, end_date_str):\n",
        "  tickers_list_upper = [ticker.upper() for ticker in tickers_list]\n",
        "  # Download the historical data\n",
        "  tickers_str = \", \".join(tickers_list_upper)\n",
        "  #tickers_str = \", \".join(f'\"{ticker}\"' for ticker in tickers_list) # maintain the same order of tickers\n",
        "  data = yf.download(tickers_str, period=\"max\", end=end_date_str)\n",
        "  data_adj_close = data['Adj Close']\n",
        "\n",
        "  # Rearrange columns based on the order in tickers_list\n",
        "  if len(tickers_list_upper)>1:\n",
        "      data_adj_close = data_adj_close.reindex(columns=tickers_list_upper)\n",
        "  #data_adj_close.columns = tickers_list_upper\n",
        "\n",
        "  data_adj_close = data_adj_close.round(2)\n",
        "  data_adj_close.index=data_adj_close.index.date\n",
        "\n",
        "  return data_adj_close\n",
        "\n",
        "output_dataframe= stock_close_prices_df(tickers_list, calculation_end_date_str)\n",
        "#output_html0=output_dataframe.to_html()\n",
        "print(\" \")\n",
        "print( output_dataframe)\n",
        "# convert to datafranme sicne output_dataframe could become series when having a single ticker\n",
        "output_dataframe=pd.DataFrame(output_dataframe)\n",
        "\n",
        "# find the highest price and corresponding date for each column\n",
        "high_price = output_dataframe.max() # get the maximum value for each column\n",
        "high_price_date = output_dataframe.idxmax() # get the index of the maximum value for each column\n",
        "\n",
        "# create a DataFrame to store the results\n",
        "high_price_df = pd.DataFrame(\n",
        "    {\n",
        "        \"Ticker\": output_dataframe.columns,\n",
        "        \"HighPrice\": high_price,\n",
        "        \"HighPriceDate\": high_price_date,\n",
        "    }\n",
        ")\n",
        "\n",
        "# display the DataFrame\n",
        "#print(high_price_df)\n",
        "\n",
        "# find the lowest price and corresponding date after the high price date for each column\n",
        "# create an empty list to store the results\n",
        "low_price_list = []\n",
        "\n",
        "# loop through each column\n",
        "for ticker in output_dataframe.columns:\n",
        "    # get the high price date for the current column\n",
        "    high_date = high_price_date[ticker]\n",
        "    # get the subset of the output_dataframe after the high price date\n",
        "    sub_df = output_dataframe.loc[high_date:, ticker]\n",
        "    # get the minimum value and the index of the minimum value for the subset\n",
        "    low_price = sub_df.min()\n",
        "    low_price_date = sub_df.idxmin()\n",
        "    # append the results to the list\n",
        "    low_price_list.append([ticker, low_price, low_price_date])\n",
        "\n",
        "# create a DataFrame from the list\n",
        "low_price_df = pd.DataFrame(\n",
        "    low_price_list, columns=[\"Ticker\", \"LowPrice\", \"LowPriceDate\"]\n",
        ")\n",
        "\n",
        "# display the DataFrame\n",
        "#print(low_price_df)\n",
        "\n",
        "# set the index of high_price_df and low_price_df to be the Ticker column\n",
        "high_price_df = high_price_df.set_index('Ticker')\n",
        "low_price_df = low_price_df.set_index('Ticker')\n",
        "\n",
        "# create a single DataFrame by concatenating the two DataFrames along the columns\n",
        "combined_df = pd.concat([high_price_df, low_price_df], axis=1)\n",
        "\n",
        "# define a function to calculate the percentage of price drop\n",
        "def price_drop(row):\n",
        "    # get the high price and low price from the row\n",
        "    high_price = row['HighPrice']\n",
        "    low_price = row['LowPrice']\n",
        "    # calculate the percentage of price drop\n",
        "    drop = (high_price - low_price) / high_price * 100\n",
        "    # return the result\n",
        "    return drop\n",
        "\n",
        "# apply the function to each row of the combined_df and store the result in a new column\n",
        "combined_df['PriceDrop%'] = combined_df.apply(price_drop, axis=1)\n",
        "\n",
        "\n",
        "'''\n",
        "# This version let NaN be the price of inception\n",
        "#-------------------------------------------------\n",
        "# find the earliest date and the price of that day for each column\n",
        "inceptionDate = output_dataframe.first_valid_index() # get the first valid index for the DataFrame\n",
        "inceptPrice = output_dataframe.loc[inceptionDate] # get the values at the first valid index\n",
        "\n",
        "# find the latest date and the price of that day for each column\n",
        "currentDate = output_dataframe.last_valid_index() # get the last valid index for the DataFrame\n",
        "curPrice = output_dataframe.loc[currentDate] # get the values at the last valid index\n",
        "\n",
        "# calculate the price change percentage from the earliest date to the latest date\n",
        "priceChange = (curPrice - inceptPrice) / inceptPrice * 100 # calculate the percentage change\n",
        "\n",
        "# add these three new columns to the combined_df\n",
        "combined_df = pd.concat([high_price_df, low_price_df], axis=1) # create the combined_df from the previous task\n",
        "combined_df['Inception Date'] = inceptionDate # add the inceptionDate column\n",
        "combined_df['Inception Price'] = inceptPrice # add the inceptPrice column\n",
        "combined_df['Current Date'] = currentDate # add the currentDate column\n",
        "combined_df['Current Price'] = curPrice # add the curPrice column\n",
        "combined_df['Price Change (%)'] = priceChange # add the priceChange column\n",
        "'''\n",
        "\n",
        "'''\n",
        "#-----------------------------------------------\n",
        "# This version drop the whole row that has NaN be the price of inception\n",
        "# drop any rows with missing values\n",
        "output_dataframe = output_dataframe.dropna()\n",
        "\n",
        "# find the earliest date and the price of that day for each column\n",
        "inceptionDate = output_dataframe.first_valid_index() # get the first valid index for the DataFrame\n",
        "inceptPrice = output_dataframe.loc[inceptionDate] # get the values at the first valid index\n",
        "\n",
        "# find the latest date and the price of that day for each column\n",
        "currentDate = output_dataframe.last_valid_index() # get the last valid index for the DataFrame\n",
        "curPrice = output_dataframe.loc[currentDate] # get the values at the last valid index\n",
        "\n",
        "# calculate the price change percentage from the earliest date to the latest date\n",
        "priceChange = (curPrice - inceptPrice) / inceptPrice * 100 # calculate the percentage change\n",
        "\n",
        "# add these five new columns to the combined_df\n",
        "combined_df = pd.concat([high_price_df, low_price_df], axis=1) # create the combined_df from the previous task\n",
        "combined_df['Inception Date'] = inceptionDate # add the inceptionDate column\n",
        "combined_df['Inception Price'] = inceptPrice # add the inceptPrice column\n",
        "combined_df['Current Date'] = currentDate # add the currentDate column\n",
        "combined_df['Current Price'] = curPrice # add the curPrice column\n",
        "combined_df['Price Change (%)'] = priceChange # add the priceChange column\n",
        "'''\n",
        "\n",
        "# define a function to return the first valid value and index for a Series\n",
        "def first_valid(series):\n",
        "    # get the first valid value\n",
        "    value = series.dropna().iloc[0]\n",
        "    # get the index of the first valid value\n",
        "    index = series.first_valid_index()\n",
        "    # return a tuple of value and index\n",
        "    return (value, index)\n",
        "\n",
        "# apply the function to each column and get the inception price and date\n",
        "inceptPrice, inceptionDate = output_dataframe.apply(first_valid).apply(pd.Series).values\n",
        "\n",
        "# convert the arrays to pandas Series\n",
        "inceptPrice = pd.Series(inceptPrice, index=output_dataframe.columns)\n",
        "inceptionDate = pd.Series(inceptionDate, index=output_dataframe.columns)\n",
        "\n",
        "# find the latest date and the price of that day for each column\n",
        "currentDate = output_dataframe.last_valid_index() # get the last valid index for the DataFrame\n",
        "curPrice = output_dataframe.loc[currentDate] # get the values at the last valid index\n",
        "\n",
        "# calculate the price change percentage from the earliest date to the latest date\n",
        "priceChange = (curPrice - inceptPrice) / inceptPrice * 100 # calculate the percentage change\n",
        "\n",
        "# add these  new columns to the combined_df\n",
        "combined_df['InceptDate'] = inceptionDate # add the inceptionDate column\n",
        "combined_df['InceptPrice'] = inceptPrice # add the inceptPrice column\n",
        "combined_df['CurDate'] = currentDate # add the currentDate column\n",
        "combined_df['CurPrice'] = curPrice # add the curPrice column\n",
        "combined_df['PriceChange%'] = priceChange # add the priceChange column\n",
        "\n",
        "# round the PriceChange% column to two decimal places\n",
        "combined_df['PriceChange%'] = combined_df['PriceChange%'].astype(float).round(2)\n",
        "combined_df['PriceChange%'] = combined_df['PriceChange%'].apply(lambda x: round(x, 2))\n",
        "\n",
        "\n",
        "\n",
        "# display the DataFrame\n",
        "print(combined_df)\n",
        "\n",
        "#combined_tranpose_df=combined_df.transpose()\n",
        "#print(combined_tranpose_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHJu3VT1Hkw8"
      },
      "source": [
        "## prompt for generating script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dn7K9cIHHlZo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "N2rRYjlQHlzD",
        "outputId": "35348134-bac6-4129-c7c9-6efd606de154"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers (<ipython-input-5-1ac6a6f9bc9e>, line 4)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-1ac6a6f9bc9e>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    1993-01-29     NaN    NaN    NaN   24.84    NaN    NaN     NaN\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers\n"
          ]
        }
      ],
      "source": [
        "output_dataframe is a Pandas DataFrame in python, where the index is dates.  The names of Columns are stock tickers.\n",
        "Each column contains historic daily close prices for a ticker.\n",
        "print( output_dataframe) has the following result:\n",
        "\n",
        "Ticker         QQQ   TQQQ    QLD     SPY   UPRO    SSO    SPXL\n",
        "1993-01-29     NaN    NaN    NaN   24.84    NaN    NaN     NaN\n",
        "1993-02-01     NaN    NaN    NaN   25.02    NaN    NaN     NaN\n",
        "1993-02-02     NaN    NaN    NaN   25.07    NaN    NaN     NaN\n",
        "1993-02-03     NaN    NaN    NaN   25.34    NaN    NaN     NaN\n",
        "1993-02-04     NaN    NaN    NaN   25.44    NaN    NaN     NaN\n",
        "...            ...    ...    ...     ...    ...    ...     ...\n",
        "2024-02-05  428.45  56.95  82.44  492.55  59.91  69.29  113.82\n",
        "2024-02-06  427.59  56.62  82.14  493.98  60.40  69.66  114.74\n",
        "2024-02-07  431.99  58.31  83.79  498.10  61.88  70.80  117.57\n",
        "2024-02-08  432.79  58.55  84.06  498.32  61.95  70.86  117.71\n",
        "2024-02-09  437.05  60.27  85.68  501.20  62.97  71.67  119.62\n",
        "\n",
        "May you help me to provide a script:\n",
        "1. find the highest price and corresponding date (called high_price_date) for each column\n",
        "2. find the lowest price and corresponding date (called maximum_drop_date) after the date (high_price_date) found\n",
        "   in the previous step for for each column\n",
        "\n",
        "Here is my modified instruction. May you help me to provide a script:\n",
        "1. find the  earlist date (inceptionDate) such that the price of that day is not NaN (should be valid price) for  each column\n",
        "2. find the price of inceptionDate () for  each column\n",
        "3. find the latest date (currentDate) for  each column\n",
        "4. find the price of that day (called CurPRice)  for each column\n",
        "5. calculate the price change percentage from the earlist date to the te latest date.\n",
        "6. add these five new columns to the combined_df\n",
        "\n",
        "\n",
        "The above droped the whole row that has a NaN such that droped the ticker that has earlier inception date.\n",
        "May you to find the  earlist date (inceptionDate) such that the price of that day is not NaN (should be valid price)\n",
        "for  each column without droping the whole row. Instead, seach each ticker idividually without changing output_dataframe congtent\n",
        "for keeping data of the other tickers?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bXlP-q-Fn96"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW7sNGBIFp1c",
        "outputId": "ebccecdf-32a9-42c3-f6cf-7e42355bdf13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     Ticker  High Price High Price Date\n",
            "QQQ     QQQ      437.05      2024-02-09\n",
            "TQQQ   TQQQ       60.27      2024-02-09\n",
            "QLD     QLD       85.68      2024-02-09\n",
            "SPY     SPY      501.20      2024-02-09\n",
            "UPRO   UPRO       62.97      2024-02-09\n",
            "SSO     SSO       71.67      2024-02-09\n",
            "SPXL   SPXL      119.62      2024-02-09\n",
            "  Ticker  Low Price Low Price Date\n",
            "0    QQQ     437.05     2024-02-09\n",
            "1   TQQQ      60.27     2024-02-09\n",
            "2    QLD      85.68     2024-02-09\n",
            "3    SPY     501.20     2024-02-09\n",
            "4   UPRO      62.97     2024-02-09\n",
            "5    SSO      71.67     2024-02-09\n",
            "6   SPXL     119.62     2024-02-09\n"
          ]
        }
      ],
      "source": [
        "# import pandas library\n",
        "import pandas as pd\n",
        "\n",
        "# create a DataFrame from the given data\n",
        "output_dataframe = pd.DataFrame(\n",
        "    {\n",
        "        \"QQQ\": [None, None, None, None, None, 428.45, 427.59, 431.99, 432.79, 437.05],\n",
        "        \"TQQQ\": [None, None, None, None, None, 56.95, 56.62, 58.31, 58.55, 60.27],\n",
        "        \"QLD\": [None, None, None, None, None, 82.44, 82.14, 83.79, 84.06, 85.68],\n",
        "        \"SPY\": [24.84, 25.02, 25.07, 25.34, 25.44, 492.55, 493.98, 498.10, 498.32, 501.20],\n",
        "        \"UPRO\": [None, None, None, None, None, 59.91, 60.40, 61.88, 61.95, 62.97],\n",
        "        \"SSO\": [None, None, None, None, None, 69.29, 69.66, 70.80, 70.86, 71.67],\n",
        "        \"SPXL\": [None, None, None, None, None, 113.82, 114.74, 117.57, 117.71, 119.62],\n",
        "    },\n",
        "    index=pd.to_datetime(\n",
        "        [\n",
        "            \"1993-01-29\",\n",
        "            \"1993-02-01\",\n",
        "            \"1993-02-02\",\n",
        "            \"1993-02-03\",\n",
        "            \"1993-02-04\",\n",
        "            \"2024-02-05\",\n",
        "            \"2024-02-06\",\n",
        "            \"2024-02-07\",\n",
        "            \"2024-02-08\",\n",
        "            \"2024-02-09\",\n",
        "        ]\n",
        "    ),\n",
        ")\n",
        "\n",
        "# find the highest price and corresponding date for each column\n",
        "high_price = output_dataframe.max() # get the maximum value for each column\n",
        "high_price_date = output_dataframe.idxmax() # get the index of the maximum value for each column\n",
        "\n",
        "# create a DataFrame to store the results\n",
        "high_price_df = pd.DataFrame(\n",
        "    {\n",
        "        \"Ticker\": output_dataframe.columns,\n",
        "        \"High Price\": high_price,\n",
        "        \"High Price Date\": high_price_date,\n",
        "    }\n",
        ")\n",
        "\n",
        "# display the DataFrame\n",
        "print(high_price_df)\n",
        "\n",
        "# find the lowest price and corresponding date after the high price date for each column\n",
        "# create an empty list to store the results\n",
        "low_price_list = []\n",
        "\n",
        "# loop through each column\n",
        "for ticker in output_dataframe.columns:\n",
        "    # get the high price date for the current column\n",
        "    high_date = high_price_date[ticker]\n",
        "    # get the subset of the output_dataframe after the high price date\n",
        "    sub_df = output_dataframe.loc[high_date:, ticker]\n",
        "    # get the minimum value and the index of the minimum value for the subset\n",
        "    low_price = sub_df.min()\n",
        "    low_price_date = sub_df.idxmin()\n",
        "    # append the results to the list\n",
        "    low_price_list.append([ticker, low_price, low_price_date])\n",
        "\n",
        "# create a DataFrame from the list\n",
        "low_price_df = pd.DataFrame(\n",
        "    low_price_list, columns=[\"Ticker\", \"Low Price\", \"Low Price Date\"]\n",
        ")\n",
        "\n",
        "# display the DataFrame\n",
        "print(low_price_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "h_awfrNb_Zpu",
        "outputId": "35348134-bac6-4129-c7c9-6efd606de154"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers (<ipython-input-5-1ac6a6f9bc9e>, line 4)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-1ac6a6f9bc9e>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    1993-01-29     NaN    NaN    NaN   24.84    NaN    NaN     NaN\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers\n"
          ]
        }
      ],
      "source": [
        "output_dataframe is a Pandas DataFrame in python, where the index is dates.  The names of Columns are stock tickers.\n",
        "Each column contains historic daily close prices for a ticker.\n",
        "print( output_dataframe) has the following result:\n",
        "\n",
        "Ticker         QQQ   TQQQ    QLD     SPY   UPRO    SSO    SPXL\n",
        "1993-01-29     NaN    NaN    NaN   24.84    NaN    NaN     NaN\n",
        "1993-02-01     NaN    NaN    NaN   25.02    NaN    NaN     NaN\n",
        "1993-02-02     NaN    NaN    NaN   25.07    NaN    NaN     NaN\n",
        "1993-02-03     NaN    NaN    NaN   25.34    NaN    NaN     NaN\n",
        "1993-02-04     NaN    NaN    NaN   25.44    NaN    NaN     NaN\n",
        "...            ...    ...    ...     ...    ...    ...     ...\n",
        "2024-02-05  428.45  56.95  82.44  492.55  59.91  69.29  113.82\n",
        "2024-02-06  427.59  56.62  82.14  493.98  60.40  69.66  114.74\n",
        "2024-02-07  431.99  58.31  83.79  498.10  61.88  70.80  117.57\n",
        "2024-02-08  432.79  58.55  84.06  498.32  61.95  70.86  117.71\n",
        "2024-02-09  437.05  60.27  85.68  501.20  62.97  71.67  119.62\n",
        "\n",
        "May you help me to provide a script:\n",
        "1. find the highest price and corresponding date (called high_price_date) for each column\n",
        "2. find the lowest price and corresponding date (called maximum_drop_date) after the date (high_price_date) found\n",
        "   in the previous step for for each column\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6LTmbne_544"
      },
      "source": [
        "# yahooquery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1kotZoTQwOh",
        "outputId": "7e4d6c6a-f679-4dc0-c3b8-7cf7511f38a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting yahooquery\n",
            "  Downloading yahooquery-2.3.7-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m603.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting beautifulsoup4<5.0.0,>=4.12.2 (from yahooquery)\n",
            "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml<5.0.0,>=4.9.3 in /usr/local/lib/python3.10/dist-packages (from yahooquery) (4.9.4)\n",
            "Collecting pandas<3.0.0,>=2.0.3 (from yahooquery)\n",
            "  Downloading pandas-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from yahooquery) (2.31.0)\n",
            "Collecting requests-futures<2.0.0,>=1.0.1 (from yahooquery)\n",
            "  Downloading requests_futures-1.0.1-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from yahooquery) (4.66.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.2->yahooquery) (2.5)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=2.0.3->yahooquery) (1.23.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=2.0.3->yahooquery) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=2.0.3->yahooquery) (2023.3.post1)\n",
            "Collecting tzdata>=2022.1 (from pandas<3.0.0,>=2.0.3->yahooquery)\n",
            "  Downloading tzdata-2023.4-py2.py3-none-any.whl (346 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->yahooquery) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->yahooquery) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->yahooquery) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->yahooquery) (2023.11.17)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.0.3->yahooquery) (1.16.0)\n",
            "Installing collected packages: tzdata, beautifulsoup4, requests-futures, pandas, yahooquery\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.11.2\n",
            "    Uninstalling beautifulsoup4-4.11.2:\n",
            "      Successfully uninstalled beautifulsoup4-4.11.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "bigframes 0.19.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.1.4 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.1.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed beautifulsoup4-4.12.2 pandas-2.1.4 requests-futures-1.0.1 tzdata-2023.4 yahooquery-2.3.7\n"
          ]
        }
      ],
      "source": [
        "!pip install yahooquery\n",
        "import pandas as pd\n",
        "import yahooquery as yq\n",
        "\n",
        "def get_symbol(query, preferred_exchange='AMS'):\n",
        "    try:\n",
        "        data = yq.search(query)\n",
        "    except ValueError: # Will catch JSONDecodeError\n",
        "        print(query)\n",
        "    else:\n",
        "        quotes = data['quotes']\n",
        "        if len(quotes) == 0:\n",
        "            return 'No Symbol Found'\n",
        "\n",
        "        symbol = quotes[0]['symbol']\n",
        "        for quote in quotes:\n",
        "            if quote['exchange'] == preferred_exchange:\n",
        "                symbol = quote['symbol']\n",
        "                break\n",
        "        return symbol\n",
        "\n",
        "companies = ['Abbott Laboratories', 'ABBVIE', 'Abercrombie', 'Abiomed', 'Accenture Plc']\n",
        "df = pd.DataFrame({'Company name': companies})\n",
        "df['Company symbol'] = df.apply(lambda x: get_symbol(x['Company name']), axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KCn1JM1BtQn"
      },
      "source": [
        "# test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "lJ8TlzF2By38",
        "outputId": "5ecca083-7d78-483e-94ac-bb6fd2cce3b4"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers (<ipython-input-5-ca93643a7020>, line 22)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-ca93643a7020>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    2024-01-24\t3.44\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers\n"
          ]
        }
      ],
      "source": [
        " CODE: ###\n",
        " yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']] = yearly_data[['DivRatio','Return', 'TotalReturn', 'CalReturn']].applymap(\"{:.2f}%\".format)\n",
        " ###\n",
        " In the above  CODE, yearly_data ia Pandas DataFrame variable. The code is to add % to every values in the columns of\n",
        " 'DivRatio','Return', 'TotalReturn', 'CalReturn'.   Even when the value is NaN,  % is still added resulting NaN%.\n",
        " Please modify the code to add % to all vaules except for NaN.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlH4boj8epMP"
      },
      "outputs": [],
      "source": [
        "It"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNQtkl6sOjpef0SK2k3aNba",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}